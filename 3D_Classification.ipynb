{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Yt50EayGY38jEb-yfDor6aqJvnrBEEDl",
      "authorship_tag": "ABX9TyNuc2uz6m5rTc7f55UCCv+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meddebma/pyradiomics/blob/master/3D_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiFnM05m6uL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab0a542-1bd6-4817-b730-208810bdcbae"
      },
      "source": [
        "%pip install -q \"monai-weekly[itk, pillow]\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 542kB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 50.1MB 103kB/s \n",
            "\u001b[K     |████████████████████████████████| 14.0MB 30.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3MB 26.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 36.3MB 114kB/s \n",
            "\u001b[K     |████████████████████████████████| 68.0MB 86kB/s \n",
            "\u001b[K     |████████████████████████████████| 14.4MB 32.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JIt-TFM-3ZL",
        "outputId": "692bfd21-d501-4c89-e8e2-44f6d9b95fe8"
      },
      "source": [
        "# Copyright 2020 MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "\n",
        "import monai\n",
        "from monai.networks.nets import DenseNet121, Classifier\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.utils import first\n",
        "from monai.visualize import GradCAM\n",
        "from monai.metrics import ConfusionMatrixMetric, get_confusion_matrix\n",
        "from monai.data import CacheDataset, DataLoader, ImageDataset, ITKReader, PILReader, Dataset, partition_dataset_classes\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix,\n",
        "    ConfusionMatrixDisplay, \n",
        ")\n",
        "from torch.utils.data import DataLoader \n",
        "from monai.transforms import Transform\n",
        "from monai.transforms import (\n",
        "    AddChannel,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandRotate90,\n",
        "    Invertd,\n",
        "    Resize,\n",
        "    Orientation,\n",
        "    Orientationd,\n",
        "    ScaleIntensity,\n",
        "    AsChannelFirst,\n",
        "    AsChannelLast,\n",
        "    Activations,\n",
        "    AddChannel,\n",
        "    AsDiscrete,\n",
        "    EnsureChannelFirst,\n",
        "    RepeatChannel,\n",
        "    RemoveRepeatedChannel,\n",
        "    SplitChannel,\n",
        "    SqueezeDim,\n",
        "    ToTensor,\n",
        "    Randomizable,\n",
        "    LoadImaged,\n",
        "    ToTensord,\n",
        "    Flip,\n",
        ")\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import seaborn as sns \n",
        "from glob import glob\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Any, Callable, Dict, Generator, Hashable, Iterable, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "from monai.transforms import Transform, AddChannel, AsChannelFirst\n",
        "\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "print_config()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MONAI version: 0.6.dev2124\n",
            "Numpy version: 1.19.5\n",
            "Pytorch version: 1.8.1+cu101\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
            "MONAI rev id: 35907c20d39845d8bb30bad08cf6cffa87f94389\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 3.0.2\n",
            "scikit-image version: 0.16.2\n",
            "Pillow version: 7.1.2\n",
            "Tensorboard version: 2.5.0\n",
            "gdown version: 3.6.4\n",
            "TorchVision version: 0.9.1+cu101\n",
            "ITK version: 5.1.2\n",
            "tqdm version: 4.41.1\n",
            "lmdb version: 0.99\n",
            "psutil version: 5.4.8\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvUL9l6t_tDM"
      },
      "source": [
        "**Data Direction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHeS8Rt6_zWD"
      },
      "source": [
        "data_dir= \"/content/drive/My Drive/Spleen_AI\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1S2v-B-AITM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bea71d-ae36-4540-e137-eefc1e00632f"
      },
      "source": [
        "labels_all = pd.read_excel (r'/content/drive/MyDrive/Spleen_AI/labels.xlsx')\n",
        "l=labels_all[\"label\"].to_numpy()\n",
        "print(l)\n",
        "#print(labels_all[\"label\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyjyR96rS0Bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b896b80-383e-48da-ae51-72910c20ea04"
      },
      "source": [
        "images = sorted(glob(os.path.join(data_dir, \"Projekt2f\", \"*.nii.gz\")))\n",
        "\n",
        "#for i in images:\n",
        "#  print(os.path.basename(i))\n",
        "\n",
        "labels= l\n",
        "#labels= np.array([0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1], dtype=np.int64)\n",
        "print(len(labels))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgOMkqS2-i4q"
      },
      "source": [
        "**Check Data Shape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "B6e1LbkoDgKM",
        "outputId": "4cd74fd6-687b-494b-8143-a8bff24765d8"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "#AddChannel(), Orientation(axcodes=\"PRI\"),Flip(spatial_axis=0),\n",
        "transforms=Compose([ Flip(spatial_axis=(0,-1)), ToTensor()])\n",
        "check = ImageDataset(image_files=images[:2], labels=labels[:2],\n",
        "                        transform=transforms)\n",
        "check_loader = DataLoader(check, batch_size=1,\n",
        "                          num_workers=1, pin_memory=torch.cuda.is_available())\n",
        "for data,i in check_loader:\n",
        "  inputs = data[0].to(device)\n",
        "  plt.imshow(data[0][:, :, 35], cmap=\"gray\")\n",
        "  print(inputs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([512, 512, 97])\n",
            "torch.Size([512, 512, 99])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJJwFbO47yGV"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAyoqwOX76UZ"
      },
      "source": [
        "# Define transforms\n",
        "train_transforms = Compose([ScaleIntensity(), AddChannel(), Resize(\n",
        "    (96, 96, 96)), ToTensor()])\n",
        "val_transforms = Compose(\n",
        "    [ScaleIntensity(), AddChannel(), Resize((96, 96, 96)), ToTensor()])\n",
        "\n",
        "\n",
        "\n",
        "# Define nifti dataset, data loader\n",
        "check_ds = ImageDataset(image_files=images, labels=labels,\n",
        "                        transform=train_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=2,\n",
        "                          num_workers=4, pin_memory=torch.cuda.is_available())\n",
        "im, label = monai.utils.misc.first(check_loader)\n",
        "#print(type(im), im.shape, label)\n",
        "\n",
        "# create a training data loader\n",
        "train_ds = ImageDataset(\n",
        "    image_files=images[:110], labels=labels[:110], transform=train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True,\n",
        "                          num_workers=4, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "# create a validation data loader\n",
        "val_ds = ImageDataset(\n",
        "    image_files=images[110:], labels=labels[110:], transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=2, num_workers=4,\n",
        "                        pin_memory=torch.cuda.is_available())\n",
        "\n",
        "\n",
        "to_onehot = AsDiscrete(to_onehot=True, n_classes=2)\n",
        "act = Activations(softmax=True)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o46nSnXueNbT"
      },
      "source": [
        "for idx, (images, labels) in enumerate(train_loader):\n",
        "      \n",
        "      print(idx,  im.shape, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtjR-k758HU7"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGT1akrQ-MKe"
      },
      "source": [
        "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
        "device = torch.device(\"cuda\")\n",
        "model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl3O9A11Zmpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdefa12-df6a-419f-b79c-c4e1d6be5f69"
      },
      "source": [
        "# start a typical PyTorch training\n",
        "val_interval = 3\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "writer = SummaryWriter()\n",
        "max_epochs = 100\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "    \n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            num_correct = 0.0\n",
        "            metric_count = 0\n",
        "            for val_data in val_loader:\n",
        "                val_images, val_labels = val_data[0].to(\n",
        "                    device), val_data[1].to(device)\n",
        "                val_outputs = model(val_images)\n",
        "                value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
        "                metric_count += len(value)\n",
        "                num_correct += value.sum().item()\n",
        "            metric = num_correct / metric_count\n",
        "            metric_values.append(metric)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(),\n",
        "                           \"/content/drive/My Drive/Spleen_AI/best_metric_model_classification3d_array.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                \"current epoch: {} current accuracy: {:.4f} \"\n",
        "                \"best accuracy: {:.4f} at epoch {}\".format(\n",
        "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
        "                )\n",
        "            )\n",
        "            writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n",
        "            \n",
        "print(\n",
        "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "    f\"at epoch: {best_metric_epoch}\")\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "100/110, train_loss: 0.0250\n",
            "101/110, train_loss: 0.0301\n",
            "102/110, train_loss: 0.0307\n",
            "103/110, train_loss: 0.0275\n",
            "104/110, train_loss: 0.0356\n",
            "105/110, train_loss: 0.0318\n",
            "106/110, train_loss: 0.0248\n",
            "107/110, train_loss: 0.0342\n",
            "108/110, train_loss: 0.0280\n",
            "109/110, train_loss: 0.0303\n",
            "110/110, train_loss: 0.0620\n",
            "epoch 56 average loss: 0.0349\n",
            "----------\n",
            "epoch 57/100\n",
            "1/110, train_loss: 0.0236\n",
            "2/110, train_loss: 0.0316\n",
            "3/110, train_loss: 0.0248\n",
            "4/110, train_loss: 0.0304\n",
            "5/110, train_loss: 0.0297\n",
            "6/110, train_loss: 0.0266\n",
            "7/110, train_loss: 0.0456\n",
            "8/110, train_loss: 0.0258\n",
            "9/110, train_loss: 0.0288\n",
            "10/110, train_loss: 0.0365\n",
            "11/110, train_loss: 0.0864\n",
            "12/110, train_loss: 0.0307\n",
            "13/110, train_loss: 0.0369\n",
            "14/110, train_loss: 0.0530\n",
            "15/110, train_loss: 0.0285\n",
            "16/110, train_loss: 0.0284\n",
            "17/110, train_loss: 0.0234\n",
            "18/110, train_loss: 0.0617\n",
            "19/110, train_loss: 0.0396\n",
            "20/110, train_loss: 0.0323\n",
            "21/110, train_loss: 0.0242\n",
            "22/110, train_loss: 0.0276\n",
            "23/110, train_loss: 0.0370\n",
            "24/110, train_loss: 0.0305\n",
            "25/110, train_loss: 0.0348\n",
            "26/110, train_loss: 0.0616\n",
            "27/110, train_loss: 0.0232\n",
            "28/110, train_loss: 0.0350\n",
            "29/110, train_loss: 0.0393\n",
            "30/110, train_loss: 0.0363\n",
            "31/110, train_loss: 0.0316\n",
            "32/110, train_loss: 0.0395\n",
            "33/110, train_loss: 0.0243\n",
            "34/110, train_loss: 0.0248\n",
            "35/110, train_loss: 0.0233\n",
            "36/110, train_loss: 0.0235\n",
            "37/110, train_loss: 0.0244\n",
            "38/110, train_loss: 0.0248\n",
            "39/110, train_loss: 0.0298\n",
            "40/110, train_loss: 0.0272\n",
            "41/110, train_loss: 0.0400\n",
            "42/110, train_loss: 0.0302\n",
            "43/110, train_loss: 0.0547\n",
            "44/110, train_loss: 0.0242\n",
            "45/110, train_loss: 0.0364\n",
            "46/110, train_loss: 0.0283\n",
            "47/110, train_loss: 0.0272\n",
            "48/110, train_loss: 0.0295\n",
            "49/110, train_loss: 0.0252\n",
            "50/110, train_loss: 0.0870\n",
            "51/110, train_loss: 0.0433\n",
            "52/110, train_loss: 0.0390\n",
            "53/110, train_loss: 0.0334\n",
            "54/110, train_loss: 0.0361\n",
            "55/110, train_loss: 0.0294\n",
            "56/110, train_loss: 0.0320\n",
            "57/110, train_loss: 0.0322\n",
            "58/110, train_loss: 0.0343\n",
            "59/110, train_loss: 0.0251\n",
            "60/110, train_loss: 0.0279\n",
            "61/110, train_loss: 0.0482\n",
            "62/110, train_loss: 0.0336\n",
            "63/110, train_loss: 0.0285\n",
            "64/110, train_loss: 0.0387\n",
            "65/110, train_loss: 0.0323\n",
            "66/110, train_loss: 0.0232\n",
            "67/110, train_loss: 0.0328\n",
            "68/110, train_loss: 0.0447\n",
            "69/110, train_loss: 0.0252\n",
            "70/110, train_loss: 0.0350\n",
            "71/110, train_loss: 0.0277\n",
            "72/110, train_loss: 0.0339\n",
            "73/110, train_loss: 0.0234\n",
            "74/110, train_loss: 0.0562\n",
            "75/110, train_loss: 0.0398\n",
            "76/110, train_loss: 0.0339\n",
            "77/110, train_loss: 0.0269\n",
            "78/110, train_loss: 0.0609\n",
            "79/110, train_loss: 0.0337\n",
            "80/110, train_loss: 0.0270\n",
            "81/110, train_loss: 0.0377\n",
            "82/110, train_loss: 0.0238\n",
            "83/110, train_loss: 0.0308\n",
            "84/110, train_loss: 0.0438\n",
            "85/110, train_loss: 0.0279\n",
            "86/110, train_loss: 0.0293\n",
            "87/110, train_loss: 0.0243\n",
            "88/110, train_loss: 0.0316\n",
            "89/110, train_loss: 0.0250\n",
            "90/110, train_loss: 0.0290\n",
            "91/110, train_loss: 0.0244\n",
            "92/110, train_loss: 0.0307\n",
            "93/110, train_loss: 0.0229\n",
            "94/110, train_loss: 0.0610\n",
            "95/110, train_loss: 0.0266\n",
            "96/110, train_loss: 0.0263\n",
            "97/110, train_loss: 0.0285\n",
            "98/110, train_loss: 0.0286\n",
            "99/110, train_loss: 0.0263\n",
            "100/110, train_loss: 0.0295\n",
            "101/110, train_loss: 0.0342\n",
            "102/110, train_loss: 0.0240\n",
            "103/110, train_loss: 0.0296\n",
            "104/110, train_loss: 0.0234\n",
            "105/110, train_loss: 0.0221\n",
            "106/110, train_loss: 0.0313\n",
            "107/110, train_loss: 0.0228\n",
            "108/110, train_loss: 0.0286\n",
            "109/110, train_loss: 0.0301\n",
            "110/110, train_loss: 0.0339\n",
            "epoch 57 average loss: 0.0332\n",
            "current epoch: 57 current accuracy: 0.7143 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 58/100\n",
            "1/110, train_loss: 0.0253\n",
            "2/110, train_loss: 0.0313\n",
            "3/110, train_loss: 0.0536\n",
            "4/110, train_loss: 0.0234\n",
            "5/110, train_loss: 0.0350\n",
            "6/110, train_loss: 0.0216\n",
            "7/110, train_loss: 0.0437\n",
            "8/110, train_loss: 0.0332\n",
            "9/110, train_loss: 0.0242\n",
            "10/110, train_loss: 0.0269\n",
            "11/110, train_loss: 0.0232\n",
            "12/110, train_loss: 0.0236\n",
            "13/110, train_loss: 0.0309\n",
            "14/110, train_loss: 0.0271\n",
            "15/110, train_loss: 0.0347\n",
            "16/110, train_loss: 0.0326\n",
            "17/110, train_loss: 0.0306\n",
            "18/110, train_loss: 0.0290\n",
            "19/110, train_loss: 0.0383\n",
            "20/110, train_loss: 0.0260\n",
            "21/110, train_loss: 0.0350\n",
            "22/110, train_loss: 0.0586\n",
            "23/110, train_loss: 0.0218\n",
            "24/110, train_loss: 0.0287\n",
            "25/110, train_loss: 0.0233\n",
            "26/110, train_loss: 0.0285\n",
            "27/110, train_loss: 0.0362\n",
            "28/110, train_loss: 0.0232\n",
            "29/110, train_loss: 0.0403\n",
            "30/110, train_loss: 0.0269\n",
            "31/110, train_loss: 0.0414\n",
            "32/110, train_loss: 0.0364\n",
            "33/110, train_loss: 0.0243\n",
            "34/110, train_loss: 0.0294\n",
            "35/110, train_loss: 0.0221\n",
            "36/110, train_loss: 0.0275\n",
            "37/110, train_loss: 0.0557\n",
            "38/110, train_loss: 0.0294\n",
            "39/110, train_loss: 0.0303\n",
            "40/110, train_loss: 0.0254\n",
            "41/110, train_loss: 0.0227\n",
            "42/110, train_loss: 0.0337\n",
            "43/110, train_loss: 0.0322\n",
            "44/110, train_loss: 0.0404\n",
            "45/110, train_loss: 0.0267\n",
            "46/110, train_loss: 0.0373\n",
            "47/110, train_loss: 0.0283\n",
            "48/110, train_loss: 0.0238\n",
            "49/110, train_loss: 0.0273\n",
            "50/110, train_loss: 0.0491\n",
            "51/110, train_loss: 0.0251\n",
            "52/110, train_loss: 0.0283\n",
            "53/110, train_loss: 0.0254\n",
            "54/110, train_loss: 0.0278\n",
            "55/110, train_loss: 0.0381\n",
            "56/110, train_loss: 0.0256\n",
            "57/110, train_loss: 0.0223\n",
            "58/110, train_loss: 0.0424\n",
            "59/110, train_loss: 0.0279\n",
            "60/110, train_loss: 0.0270\n",
            "61/110, train_loss: 0.0537\n",
            "62/110, train_loss: 0.0282\n",
            "63/110, train_loss: 0.0233\n",
            "64/110, train_loss: 0.0256\n",
            "65/110, train_loss: 0.0315\n",
            "66/110, train_loss: 0.0904\n",
            "67/110, train_loss: 0.0288\n",
            "68/110, train_loss: 0.0344\n",
            "69/110, train_loss: 0.0216\n",
            "70/110, train_loss: 0.0253\n",
            "71/110, train_loss: 0.0224\n",
            "72/110, train_loss: 0.0382\n",
            "73/110, train_loss: 0.0320\n",
            "74/110, train_loss: 0.0250\n",
            "75/110, train_loss: 0.0379\n",
            "76/110, train_loss: 0.0321\n",
            "77/110, train_loss: 0.0328\n",
            "78/110, train_loss: 0.0300\n",
            "79/110, train_loss: 0.0285\n",
            "80/110, train_loss: 0.0281\n",
            "81/110, train_loss: 0.0274\n",
            "82/110, train_loss: 0.0271\n",
            "83/110, train_loss: 0.0250\n",
            "84/110, train_loss: 0.0343\n",
            "85/110, train_loss: 0.0228\n",
            "86/110, train_loss: 0.0585\n",
            "87/110, train_loss: 0.0266\n",
            "88/110, train_loss: 0.0218\n",
            "89/110, train_loss: 0.0820\n",
            "90/110, train_loss: 0.0260\n",
            "91/110, train_loss: 0.0321\n",
            "92/110, train_loss: 0.0224\n",
            "93/110, train_loss: 0.0227\n",
            "94/110, train_loss: 0.0283\n",
            "95/110, train_loss: 0.0299\n",
            "96/110, train_loss: 0.0223\n",
            "97/110, train_loss: 0.0313\n",
            "98/110, train_loss: 0.0334\n",
            "99/110, train_loss: 0.0314\n",
            "100/110, train_loss: 0.0345\n",
            "101/110, train_loss: 0.0245\n",
            "102/110, train_loss: 0.0599\n",
            "103/110, train_loss: 0.0212\n",
            "104/110, train_loss: 0.0220\n",
            "105/110, train_loss: 0.0283\n",
            "106/110, train_loss: 0.0222\n",
            "107/110, train_loss: 0.0374\n",
            "108/110, train_loss: 0.0218\n",
            "109/110, train_loss: 0.0224\n",
            "110/110, train_loss: 0.0214\n",
            "epoch 58 average loss: 0.0315\n",
            "----------\n",
            "epoch 59/100\n",
            "1/110, train_loss: 0.0316\n",
            "2/110, train_loss: 0.0233\n",
            "3/110, train_loss: 0.0469\n",
            "4/110, train_loss: 0.0316\n",
            "5/110, train_loss: 0.0207\n",
            "6/110, train_loss: 0.0345\n",
            "7/110, train_loss: 0.0356\n",
            "8/110, train_loss: 0.0218\n",
            "9/110, train_loss: 0.0307\n",
            "10/110, train_loss: 0.0272\n",
            "11/110, train_loss: 0.0309\n",
            "12/110, train_loss: 0.0214\n",
            "13/110, train_loss: 0.0238\n",
            "14/110, train_loss: 0.0340\n",
            "15/110, train_loss: 0.0302\n",
            "16/110, train_loss: 0.0567\n",
            "17/110, train_loss: 0.0214\n",
            "18/110, train_loss: 0.0253\n",
            "19/110, train_loss: 0.0288\n",
            "20/110, train_loss: 0.0367\n",
            "21/110, train_loss: 0.0209\n",
            "22/110, train_loss: 0.0749\n",
            "23/110, train_loss: 0.0269\n",
            "24/110, train_loss: 0.0225\n",
            "25/110, train_loss: 0.0209\n",
            "26/110, train_loss: 0.0333\n",
            "27/110, train_loss: 0.0333\n",
            "28/110, train_loss: 0.0235\n",
            "29/110, train_loss: 0.0301\n",
            "30/110, train_loss: 0.0305\n",
            "31/110, train_loss: 0.0365\n",
            "32/110, train_loss: 0.0211\n",
            "33/110, train_loss: 0.0262\n",
            "34/110, train_loss: 0.0237\n",
            "35/110, train_loss: 0.0509\n",
            "36/110, train_loss: 0.0203\n",
            "37/110, train_loss: 0.0327\n",
            "38/110, train_loss: 0.0318\n",
            "39/110, train_loss: 0.0241\n",
            "40/110, train_loss: 0.0267\n",
            "41/110, train_loss: 0.0570\n",
            "42/110, train_loss: 0.0224\n",
            "43/110, train_loss: 0.0298\n",
            "44/110, train_loss: 0.0519\n",
            "45/110, train_loss: 0.0214\n",
            "46/110, train_loss: 0.0330\n",
            "47/110, train_loss: 0.0212\n",
            "48/110, train_loss: 0.0293\n",
            "49/110, train_loss: 0.0280\n",
            "50/110, train_loss: 0.0276\n",
            "51/110, train_loss: 0.0231\n",
            "52/110, train_loss: 0.0292\n",
            "53/110, train_loss: 0.0239\n",
            "54/110, train_loss: 0.0202\n",
            "55/110, train_loss: 0.0263\n",
            "56/110, train_loss: 0.0222\n",
            "57/110, train_loss: 0.0214\n",
            "58/110, train_loss: 0.0265\n",
            "59/110, train_loss: 0.0412\n",
            "60/110, train_loss: 0.0203\n",
            "61/110, train_loss: 0.0265\n",
            "62/110, train_loss: 0.0800\n",
            "63/110, train_loss: 0.0257\n",
            "64/110, train_loss: 0.0296\n",
            "65/110, train_loss: 0.0213\n",
            "66/110, train_loss: 0.0539\n",
            "67/110, train_loss: 0.0381\n",
            "68/110, train_loss: 0.0266\n",
            "69/110, train_loss: 0.0281\n",
            "70/110, train_loss: 0.0253\n",
            "71/110, train_loss: 0.0217\n",
            "72/110, train_loss: 0.0398\n",
            "73/110, train_loss: 0.0239\n",
            "74/110, train_loss: 0.0278\n",
            "75/110, train_loss: 0.0355\n",
            "76/110, train_loss: 0.0220\n",
            "77/110, train_loss: 0.0252\n",
            "78/110, train_loss: 0.0308\n",
            "79/110, train_loss: 0.0224\n",
            "80/110, train_loss: 0.0351\n",
            "81/110, train_loss: 0.0293\n",
            "82/110, train_loss: 0.0419\n",
            "83/110, train_loss: 0.0241\n",
            "84/110, train_loss: 0.0253\n",
            "85/110, train_loss: 0.0210\n",
            "86/110, train_loss: 0.0203\n",
            "87/110, train_loss: 0.0268\n",
            "88/110, train_loss: 0.0323\n",
            "89/110, train_loss: 0.0294\n",
            "90/110, train_loss: 0.0285\n",
            "91/110, train_loss: 0.0377\n",
            "92/110, train_loss: 0.0271\n",
            "93/110, train_loss: 0.0335\n",
            "94/110, train_loss: 0.0270\n",
            "95/110, train_loss: 0.0204\n",
            "96/110, train_loss: 0.0258\n",
            "97/110, train_loss: 0.0257\n",
            "98/110, train_loss: 0.0257\n",
            "99/110, train_loss: 0.0259\n",
            "100/110, train_loss: 0.0204\n",
            "101/110, train_loss: 0.0384\n",
            "102/110, train_loss: 0.0242\n",
            "103/110, train_loss: 0.0354\n",
            "104/110, train_loss: 0.0234\n",
            "105/110, train_loss: 0.0213\n",
            "106/110, train_loss: 0.0519\n",
            "107/110, train_loss: 0.0323\n",
            "108/110, train_loss: 0.0234\n",
            "109/110, train_loss: 0.0220\n",
            "110/110, train_loss: 0.0267\n",
            "epoch 59 average loss: 0.0299\n",
            "----------\n",
            "epoch 60/100\n",
            "1/110, train_loss: 0.0524\n",
            "2/110, train_loss: 0.0339\n",
            "3/110, train_loss: 0.0198\n",
            "4/110, train_loss: 0.0345\n",
            "5/110, train_loss: 0.0288\n",
            "6/110, train_loss: 0.0211\n",
            "7/110, train_loss: 0.0204\n",
            "8/110, train_loss: 0.0301\n",
            "9/110, train_loss: 0.0248\n",
            "10/110, train_loss: 0.0199\n",
            "11/110, train_loss: 0.0213\n",
            "12/110, train_loss: 0.0207\n",
            "13/110, train_loss: 0.0787\n",
            "14/110, train_loss: 0.0319\n",
            "15/110, train_loss: 0.0487\n",
            "16/110, train_loss: 0.0303\n",
            "17/110, train_loss: 0.0456\n",
            "18/110, train_loss: 0.0261\n",
            "19/110, train_loss: 0.0281\n",
            "20/110, train_loss: 0.0341\n",
            "21/110, train_loss: 0.0245\n",
            "22/110, train_loss: 0.0253\n",
            "23/110, train_loss: 0.0264\n",
            "24/110, train_loss: 0.0218\n",
            "25/110, train_loss: 0.0339\n",
            "26/110, train_loss: 0.0209\n",
            "27/110, train_loss: 0.0310\n",
            "28/110, train_loss: 0.0273\n",
            "29/110, train_loss: 0.0200\n",
            "30/110, train_loss: 0.0246\n",
            "31/110, train_loss: 0.0263\n",
            "32/110, train_loss: 0.0259\n",
            "33/110, train_loss: 0.0232\n",
            "34/110, train_loss: 0.0230\n",
            "35/110, train_loss: 0.0206\n",
            "36/110, train_loss: 0.0303\n",
            "37/110, train_loss: 0.0254\n",
            "38/110, train_loss: 0.0248\n",
            "39/110, train_loss: 0.0232\n",
            "40/110, train_loss: 0.0269\n",
            "41/110, train_loss: 0.0338\n",
            "42/110, train_loss: 0.0218\n",
            "43/110, train_loss: 0.0201\n",
            "44/110, train_loss: 0.0536\n",
            "45/110, train_loss: 0.0363\n",
            "46/110, train_loss: 0.0207\n",
            "47/110, train_loss: 0.0373\n",
            "48/110, train_loss: 0.0212\n",
            "49/110, train_loss: 0.0238\n",
            "50/110, train_loss: 0.0284\n",
            "51/110, train_loss: 0.0241\n",
            "52/110, train_loss: 0.0235\n",
            "53/110, train_loss: 0.0249\n",
            "54/110, train_loss: 0.0295\n",
            "55/110, train_loss: 0.0311\n",
            "56/110, train_loss: 0.0240\n",
            "57/110, train_loss: 0.0272\n",
            "58/110, train_loss: 0.0271\n",
            "59/110, train_loss: 0.0234\n",
            "60/110, train_loss: 0.0272\n",
            "61/110, train_loss: 0.0258\n",
            "62/110, train_loss: 0.0310\n",
            "63/110, train_loss: 0.0245\n",
            "64/110, train_loss: 0.0274\n",
            "65/110, train_loss: 0.0199\n",
            "66/110, train_loss: 0.0242\n",
            "67/110, train_loss: 0.0207\n",
            "68/110, train_loss: 0.0303\n",
            "69/110, train_loss: 0.0284\n",
            "70/110, train_loss: 0.0199\n",
            "71/110, train_loss: 0.0195\n",
            "72/110, train_loss: 0.0252\n",
            "73/110, train_loss: 0.0264\n",
            "74/110, train_loss: 0.0230\n",
            "75/110, train_loss: 0.0475\n",
            "76/110, train_loss: 0.0401\n",
            "77/110, train_loss: 0.0253\n",
            "78/110, train_loss: 0.0284\n",
            "79/110, train_loss: 0.0228\n",
            "80/110, train_loss: 0.0329\n",
            "81/110, train_loss: 0.0227\n",
            "82/110, train_loss: 0.0196\n",
            "83/110, train_loss: 0.0321\n",
            "84/110, train_loss: 0.0503\n",
            "85/110, train_loss: 0.0301\n",
            "86/110, train_loss: 0.0206\n",
            "87/110, train_loss: 0.0216\n",
            "88/110, train_loss: 0.0722\n",
            "89/110, train_loss: 0.0242\n",
            "90/110, train_loss: 0.0217\n",
            "91/110, train_loss: 0.0209\n",
            "92/110, train_loss: 0.0238\n",
            "93/110, train_loss: 0.0296\n",
            "94/110, train_loss: 0.0375\n",
            "95/110, train_loss: 0.0193\n",
            "96/110, train_loss: 0.0250\n",
            "97/110, train_loss: 0.0509\n",
            "98/110, train_loss: 0.0361\n",
            "99/110, train_loss: 0.0217\n",
            "100/110, train_loss: 0.0253\n",
            "101/110, train_loss: 0.0201\n",
            "102/110, train_loss: 0.0282\n",
            "103/110, train_loss: 0.0255\n",
            "104/110, train_loss: 0.0280\n",
            "105/110, train_loss: 0.0265\n",
            "106/110, train_loss: 0.0363\n",
            "107/110, train_loss: 0.0207\n",
            "108/110, train_loss: 0.0287\n",
            "109/110, train_loss: 0.0204\n",
            "110/110, train_loss: 0.0255\n",
            "epoch 60 average loss: 0.0284\n",
            "current epoch: 60 current accuracy: 0.7857 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 61/100\n",
            "1/110, train_loss: 0.0219\n",
            "2/110, train_loss: 0.0189\n",
            "3/110, train_loss: 0.0242\n",
            "4/110, train_loss: 0.0264\n",
            "5/110, train_loss: 0.0373\n",
            "6/110, train_loss: 0.0270\n",
            "7/110, train_loss: 0.0306\n",
            "8/110, train_loss: 0.0271\n",
            "9/110, train_loss: 0.0239\n",
            "10/110, train_loss: 0.0189\n",
            "11/110, train_loss: 0.0273\n",
            "12/110, train_loss: 0.0244\n",
            "13/110, train_loss: 0.0200\n",
            "14/110, train_loss: 0.0189\n",
            "15/110, train_loss: 0.0204\n",
            "16/110, train_loss: 0.0368\n",
            "17/110, train_loss: 0.0238\n",
            "18/110, train_loss: 0.0260\n",
            "19/110, train_loss: 0.0515\n",
            "20/110, train_loss: 0.0248\n",
            "21/110, train_loss: 0.0220\n",
            "22/110, train_loss: 0.0212\n",
            "23/110, train_loss: 0.0187\n",
            "24/110, train_loss: 0.0274\n",
            "25/110, train_loss: 0.0298\n",
            "26/110, train_loss: 0.0424\n",
            "27/110, train_loss: 0.0199\n",
            "28/110, train_loss: 0.0265\n",
            "29/110, train_loss: 0.0186\n",
            "30/110, train_loss: 0.0706\n",
            "31/110, train_loss: 0.0187\n",
            "32/110, train_loss: 0.0250\n",
            "33/110, train_loss: 0.0194\n",
            "34/110, train_loss: 0.0324\n",
            "35/110, train_loss: 0.0199\n",
            "36/110, train_loss: 0.0221\n",
            "37/110, train_loss: 0.0298\n",
            "38/110, train_loss: 0.0234\n",
            "39/110, train_loss: 0.0283\n",
            "40/110, train_loss: 0.0466\n",
            "41/110, train_loss: 0.0325\n",
            "42/110, train_loss: 0.0235\n",
            "43/110, train_loss: 0.0247\n",
            "44/110, train_loss: 0.0258\n",
            "45/110, train_loss: 0.0226\n",
            "46/110, train_loss: 0.0335\n",
            "47/110, train_loss: 0.0250\n",
            "48/110, train_loss: 0.0233\n",
            "49/110, train_loss: 0.0234\n",
            "50/110, train_loss: 0.0292\n",
            "51/110, train_loss: 0.0218\n",
            "52/110, train_loss: 0.0239\n",
            "53/110, train_loss: 0.0241\n",
            "54/110, train_loss: 0.0329\n",
            "55/110, train_loss: 0.0241\n",
            "56/110, train_loss: 0.0197\n",
            "57/110, train_loss: 0.0200\n",
            "58/110, train_loss: 0.0197\n",
            "59/110, train_loss: 0.0450\n",
            "60/110, train_loss: 0.0220\n",
            "61/110, train_loss: 0.0317\n",
            "62/110, train_loss: 0.0198\n",
            "63/110, train_loss: 0.0233\n",
            "64/110, train_loss: 0.0188\n",
            "65/110, train_loss: 0.0356\n",
            "66/110, train_loss: 0.0206\n",
            "67/110, train_loss: 0.0246\n",
            "68/110, train_loss: 0.0241\n",
            "69/110, train_loss: 0.0192\n",
            "70/110, train_loss: 0.0241\n",
            "71/110, train_loss: 0.0208\n",
            "72/110, train_loss: 0.0284\n",
            "73/110, train_loss: 0.0223\n",
            "74/110, train_loss: 0.0287\n",
            "75/110, train_loss: 0.0475\n",
            "76/110, train_loss: 0.0194\n",
            "77/110, train_loss: 0.0483\n",
            "78/110, train_loss: 0.0244\n",
            "79/110, train_loss: 0.0307\n",
            "80/110, train_loss: 0.0280\n",
            "81/110, train_loss: 0.0253\n",
            "82/110, train_loss: 0.0273\n",
            "83/110, train_loss: 0.0193\n",
            "84/110, train_loss: 0.0229\n",
            "85/110, train_loss: 0.0251\n",
            "86/110, train_loss: 0.0354\n",
            "87/110, train_loss: 0.0197\n",
            "88/110, train_loss: 0.0271\n",
            "89/110, train_loss: 0.0263\n",
            "90/110, train_loss: 0.0247\n",
            "91/110, train_loss: 0.0489\n",
            "92/110, train_loss: 0.0240\n",
            "93/110, train_loss: 0.0214\n",
            "94/110, train_loss: 0.0228\n",
            "95/110, train_loss: 0.0205\n",
            "96/110, train_loss: 0.0218\n",
            "97/110, train_loss: 0.0273\n",
            "98/110, train_loss: 0.0273\n",
            "99/110, train_loss: 0.0235\n",
            "100/110, train_loss: 0.0350\n",
            "101/110, train_loss: 0.0198\n",
            "102/110, train_loss: 0.0289\n",
            "103/110, train_loss: 0.0660\n",
            "104/110, train_loss: 0.0214\n",
            "105/110, train_loss: 0.0196\n",
            "106/110, train_loss: 0.0200\n",
            "107/110, train_loss: 0.0302\n",
            "108/110, train_loss: 0.0193\n",
            "109/110, train_loss: 0.0318\n",
            "110/110, train_loss: 0.0266\n",
            "epoch 61 average loss: 0.0269\n",
            "----------\n",
            "epoch 62/100\n",
            "1/110, train_loss: 0.0207\n",
            "2/110, train_loss: 0.0429\n",
            "3/110, train_loss: 0.0313\n",
            "4/110, train_loss: 0.0187\n",
            "5/110, train_loss: 0.0302\n",
            "6/110, train_loss: 0.0325\n",
            "7/110, train_loss: 0.0354\n",
            "8/110, train_loss: 0.0195\n",
            "9/110, train_loss: 0.0265\n",
            "10/110, train_loss: 0.0241\n",
            "11/110, train_loss: 0.0442\n",
            "12/110, train_loss: 0.0250\n",
            "13/110, train_loss: 0.0229\n",
            "14/110, train_loss: 0.0340\n",
            "15/110, train_loss: 0.0284\n",
            "16/110, train_loss: 0.0224\n",
            "17/110, train_loss: 0.0225\n",
            "18/110, train_loss: 0.0218\n",
            "19/110, train_loss: 0.0467\n",
            "20/110, train_loss: 0.0209\n",
            "21/110, train_loss: 0.0187\n",
            "22/110, train_loss: 0.0254\n",
            "23/110, train_loss: 0.0290\n",
            "24/110, train_loss: 0.0231\n",
            "25/110, train_loss: 0.0231\n",
            "26/110, train_loss: 0.0178\n",
            "27/110, train_loss: 0.0285\n",
            "28/110, train_loss: 0.0399\n",
            "29/110, train_loss: 0.0238\n",
            "30/110, train_loss: 0.0256\n",
            "31/110, train_loss: 0.0237\n",
            "32/110, train_loss: 0.0183\n",
            "33/110, train_loss: 0.0216\n",
            "34/110, train_loss: 0.0349\n",
            "35/110, train_loss: 0.0324\n",
            "36/110, train_loss: 0.0194\n",
            "37/110, train_loss: 0.0230\n",
            "38/110, train_loss: 0.0186\n",
            "39/110, train_loss: 0.0279\n",
            "40/110, train_loss: 0.0187\n",
            "41/110, train_loss: 0.0197\n",
            "42/110, train_loss: 0.0264\n",
            "43/110, train_loss: 0.0227\n",
            "44/110, train_loss: 0.0225\n",
            "45/110, train_loss: 0.0182\n",
            "46/110, train_loss: 0.0214\n",
            "47/110, train_loss: 0.0177\n",
            "48/110, train_loss: 0.0269\n",
            "49/110, train_loss: 0.0176\n",
            "50/110, train_loss: 0.0284\n",
            "51/110, train_loss: 0.0305\n",
            "52/110, train_loss: 0.0272\n",
            "53/110, train_loss: 0.0227\n",
            "54/110, train_loss: 0.0249\n",
            "55/110, train_loss: 0.0287\n",
            "56/110, train_loss: 0.0208\n",
            "57/110, train_loss: 0.0662\n",
            "58/110, train_loss: 0.0186\n",
            "59/110, train_loss: 0.0205\n",
            "60/110, train_loss: 0.0258\n",
            "61/110, train_loss: 0.0179\n",
            "62/110, train_loss: 0.0186\n",
            "63/110, train_loss: 0.0250\n",
            "64/110, train_loss: 0.0194\n",
            "65/110, train_loss: 0.0242\n",
            "66/110, train_loss: 0.0229\n",
            "67/110, train_loss: 0.0205\n",
            "68/110, train_loss: 0.0176\n",
            "69/110, train_loss: 0.0188\n",
            "70/110, train_loss: 0.0183\n",
            "71/110, train_loss: 0.0236\n",
            "72/110, train_loss: 0.0189\n",
            "73/110, train_loss: 0.0252\n",
            "74/110, train_loss: 0.0226\n",
            "75/110, train_loss: 0.0461\n",
            "76/110, train_loss: 0.0271\n",
            "77/110, train_loss: 0.0612\n",
            "78/110, train_loss: 0.0251\n",
            "79/110, train_loss: 0.0176\n",
            "80/110, train_loss: 0.0221\n",
            "81/110, train_loss: 0.0209\n",
            "82/110, train_loss: 0.0173\n",
            "83/110, train_loss: 0.0492\n",
            "84/110, train_loss: 0.0251\n",
            "85/110, train_loss: 0.0189\n",
            "86/110, train_loss: 0.0320\n",
            "87/110, train_loss: 0.0236\n",
            "88/110, train_loss: 0.0175\n",
            "89/110, train_loss: 0.0284\n",
            "90/110, train_loss: 0.0307\n",
            "91/110, train_loss: 0.0181\n",
            "92/110, train_loss: 0.0229\n",
            "93/110, train_loss: 0.0258\n",
            "94/110, train_loss: 0.0258\n",
            "95/110, train_loss: 0.0279\n",
            "96/110, train_loss: 0.0213\n",
            "97/110, train_loss: 0.0196\n",
            "98/110, train_loss: 0.0436\n",
            "99/110, train_loss: 0.0181\n",
            "100/110, train_loss: 0.0229\n",
            "101/110, train_loss: 0.0312\n",
            "102/110, train_loss: 0.0180\n",
            "103/110, train_loss: 0.0232\n",
            "104/110, train_loss: 0.0244\n",
            "105/110, train_loss: 0.0200\n",
            "106/110, train_loss: 0.0265\n",
            "107/110, train_loss: 0.0202\n",
            "108/110, train_loss: 0.0294\n",
            "109/110, train_loss: 0.0171\n",
            "110/110, train_loss: 0.0206\n",
            "epoch 62 average loss: 0.0255\n",
            "----------\n",
            "epoch 63/100\n",
            "1/110, train_loss: 0.0173\n",
            "2/110, train_loss: 0.0198\n",
            "3/110, train_loss: 0.0178\n",
            "4/110, train_loss: 0.0198\n",
            "5/110, train_loss: 0.0184\n",
            "6/110, train_loss: 0.0277\n",
            "7/110, train_loss: 0.0241\n",
            "8/110, train_loss: 0.0224\n",
            "9/110, train_loss: 0.0256\n",
            "10/110, train_loss: 0.0250\n",
            "11/110, train_loss: 0.0217\n",
            "12/110, train_loss: 0.0242\n",
            "13/110, train_loss: 0.0243\n",
            "14/110, train_loss: 0.0195\n",
            "15/110, train_loss: 0.0225\n",
            "16/110, train_loss: 0.0200\n",
            "17/110, train_loss: 0.0272\n",
            "18/110, train_loss: 0.0223\n",
            "19/110, train_loss: 0.0214\n",
            "20/110, train_loss: 0.0180\n",
            "21/110, train_loss: 0.0255\n",
            "22/110, train_loss: 0.0395\n",
            "23/110, train_loss: 0.0467\n",
            "24/110, train_loss: 0.0168\n",
            "25/110, train_loss: 0.0246\n",
            "26/110, train_loss: 0.0216\n",
            "27/110, train_loss: 0.0167\n",
            "28/110, train_loss: 0.0172\n",
            "29/110, train_loss: 0.0255\n",
            "30/110, train_loss: 0.0239\n",
            "31/110, train_loss: 0.0210\n",
            "32/110, train_loss: 0.0201\n",
            "33/110, train_loss: 0.0190\n",
            "34/110, train_loss: 0.0226\n",
            "35/110, train_loss: 0.0181\n",
            "36/110, train_loss: 0.0187\n",
            "37/110, train_loss: 0.0170\n",
            "38/110, train_loss: 0.0219\n",
            "39/110, train_loss: 0.0203\n",
            "40/110, train_loss: 0.0297\n",
            "41/110, train_loss: 0.0175\n",
            "42/110, train_loss: 0.0197\n",
            "43/110, train_loss: 0.0213\n",
            "44/110, train_loss: 0.0179\n",
            "45/110, train_loss: 0.0309\n",
            "46/110, train_loss: 0.0265\n",
            "47/110, train_loss: 0.0247\n",
            "48/110, train_loss: 0.0235\n",
            "49/110, train_loss: 0.0166\n",
            "50/110, train_loss: 0.0242\n",
            "51/110, train_loss: 0.0280\n",
            "52/110, train_loss: 0.0460\n",
            "53/110, train_loss: 0.0219\n",
            "54/110, train_loss: 0.0223\n",
            "55/110, train_loss: 0.0288\n",
            "56/110, train_loss: 0.0233\n",
            "57/110, train_loss: 0.0215\n",
            "58/110, train_loss: 0.0204\n",
            "59/110, train_loss: 0.0428\n",
            "60/110, train_loss: 0.0272\n",
            "61/110, train_loss: 0.0290\n",
            "62/110, train_loss: 0.0243\n",
            "63/110, train_loss: 0.0268\n",
            "64/110, train_loss: 0.0217\n",
            "65/110, train_loss: 0.0193\n",
            "66/110, train_loss: 0.0329\n",
            "67/110, train_loss: 0.0177\n",
            "68/110, train_loss: 0.0228\n",
            "69/110, train_loss: 0.0211\n",
            "70/110, train_loss: 0.0408\n",
            "71/110, train_loss: 0.0201\n",
            "72/110, train_loss: 0.0175\n",
            "73/110, train_loss: 0.0186\n",
            "74/110, train_loss: 0.0213\n",
            "75/110, train_loss: 0.0172\n",
            "76/110, train_loss: 0.0287\n",
            "77/110, train_loss: 0.0219\n",
            "78/110, train_loss: 0.0169\n",
            "79/110, train_loss: 0.0174\n",
            "80/110, train_loss: 0.0215\n",
            "81/110, train_loss: 0.0166\n",
            "82/110, train_loss: 0.0302\n",
            "83/110, train_loss: 0.0215\n",
            "84/110, train_loss: 0.0211\n",
            "85/110, train_loss: 0.0266\n",
            "86/110, train_loss: 0.0192\n",
            "87/110, train_loss: 0.0168\n",
            "88/110, train_loss: 0.0171\n",
            "89/110, train_loss: 0.0253\n",
            "90/110, train_loss: 0.0617\n",
            "91/110, train_loss: 0.0313\n",
            "92/110, train_loss: 0.0304\n",
            "93/110, train_loss: 0.0193\n",
            "94/110, train_loss: 0.0173\n",
            "95/110, train_loss: 0.0249\n",
            "96/110, train_loss: 0.0236\n",
            "97/110, train_loss: 0.0233\n",
            "98/110, train_loss: 0.0417\n",
            "99/110, train_loss: 0.0169\n",
            "100/110, train_loss: 0.0260\n",
            "101/110, train_loss: 0.0181\n",
            "102/110, train_loss: 0.0264\n",
            "103/110, train_loss: 0.0221\n",
            "104/110, train_loss: 0.0167\n",
            "105/110, train_loss: 0.0424\n",
            "106/110, train_loss: 0.0192\n",
            "107/110, train_loss: 0.0588\n",
            "108/110, train_loss: 0.0173\n",
            "109/110, train_loss: 0.0326\n",
            "110/110, train_loss: 0.0283\n",
            "epoch 63 average loss: 0.0242\n",
            "current epoch: 63 current accuracy: 0.7143 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 64/100\n",
            "1/110, train_loss: 0.0271\n",
            "2/110, train_loss: 0.0229\n",
            "3/110, train_loss: 0.0207\n",
            "4/110, train_loss: 0.0668\n",
            "5/110, train_loss: 0.0279\n",
            "6/110, train_loss: 0.0168\n",
            "7/110, train_loss: 0.0174\n",
            "8/110, train_loss: 0.0421\n",
            "9/110, train_loss: 0.0586\n",
            "10/110, train_loss: 0.0362\n",
            "11/110, train_loss: 0.0220\n",
            "12/110, train_loss: 0.0203\n",
            "13/110, train_loss: 0.0194\n",
            "14/110, train_loss: 0.0223\n",
            "15/110, train_loss: 0.0317\n",
            "16/110, train_loss: 0.0271\n",
            "17/110, train_loss: 0.0174\n",
            "18/110, train_loss: 0.0194\n",
            "19/110, train_loss: 0.0168\n",
            "20/110, train_loss: 0.0448\n",
            "21/110, train_loss: 0.0264\n",
            "22/110, train_loss: 0.0239\n",
            "23/110, train_loss: 0.0254\n",
            "24/110, train_loss: 0.0291\n",
            "25/110, train_loss: 0.0227\n",
            "26/110, train_loss: 0.0214\n",
            "27/110, train_loss: 0.0213\n",
            "28/110, train_loss: 0.0204\n",
            "29/110, train_loss: 0.0203\n",
            "30/110, train_loss: 0.0193\n",
            "31/110, train_loss: 0.0172\n",
            "32/110, train_loss: 0.0258\n",
            "33/110, train_loss: 0.0192\n",
            "34/110, train_loss: 0.0253\n",
            "35/110, train_loss: 0.0242\n",
            "36/110, train_loss: 0.0249\n",
            "37/110, train_loss: 0.0175\n",
            "38/110, train_loss: 0.0208\n",
            "39/110, train_loss: 0.0163\n",
            "40/110, train_loss: 0.0185\n",
            "41/110, train_loss: 0.0238\n",
            "42/110, train_loss: 0.0212\n",
            "43/110, train_loss: 0.0268\n",
            "44/110, train_loss: 0.0175\n",
            "45/110, train_loss: 0.0191\n",
            "46/110, train_loss: 0.0191\n",
            "47/110, train_loss: 0.0187\n",
            "48/110, train_loss: 0.0215\n",
            "49/110, train_loss: 0.0272\n",
            "50/110, train_loss: 0.0243\n",
            "51/110, train_loss: 0.0193\n",
            "52/110, train_loss: 0.0234\n",
            "53/110, train_loss: 0.0163\n",
            "54/110, train_loss: 0.0160\n",
            "55/110, train_loss: 0.0202\n",
            "56/110, train_loss: 0.0322\n",
            "57/110, train_loss: 0.0170\n",
            "58/110, train_loss: 0.0268\n",
            "59/110, train_loss: 0.0275\n",
            "60/110, train_loss: 0.0168\n",
            "61/110, train_loss: 0.0252\n",
            "62/110, train_loss: 0.0405\n",
            "63/110, train_loss: 0.0161\n",
            "64/110, train_loss: 0.0293\n",
            "65/110, train_loss: 0.0378\n",
            "66/110, train_loss: 0.0169\n",
            "67/110, train_loss: 0.0208\n",
            "68/110, train_loss: 0.0187\n",
            "69/110, train_loss: 0.0226\n",
            "70/110, train_loss: 0.0221\n",
            "71/110, train_loss: 0.0204\n",
            "72/110, train_loss: 0.0159\n",
            "73/110, train_loss: 0.0169\n",
            "74/110, train_loss: 0.0194\n",
            "75/110, train_loss: 0.0172\n",
            "76/110, train_loss: 0.0208\n",
            "77/110, train_loss: 0.0241\n",
            "78/110, train_loss: 0.0392\n",
            "79/110, train_loss: 0.0226\n",
            "80/110, train_loss: 0.0201\n",
            "81/110, train_loss: 0.0177\n",
            "82/110, train_loss: 0.0202\n",
            "83/110, train_loss: 0.0392\n",
            "84/110, train_loss: 0.0203\n",
            "85/110, train_loss: 0.0234\n",
            "86/110, train_loss: 0.0249\n",
            "87/110, train_loss: 0.0163\n",
            "88/110, train_loss: 0.0172\n",
            "89/110, train_loss: 0.0167\n",
            "90/110, train_loss: 0.0157\n",
            "91/110, train_loss: 0.0225\n",
            "92/110, train_loss: 0.0233\n",
            "93/110, train_loss: 0.0200\n",
            "94/110, train_loss: 0.0210\n",
            "95/110, train_loss: 0.0172\n",
            "96/110, train_loss: 0.0209\n",
            "97/110, train_loss: 0.0234\n",
            "98/110, train_loss: 0.0202\n",
            "99/110, train_loss: 0.0206\n",
            "100/110, train_loss: 0.0196\n",
            "101/110, train_loss: 0.0158\n",
            "102/110, train_loss: 0.0296\n",
            "103/110, train_loss: 0.0163\n",
            "104/110, train_loss: 0.0172\n",
            "105/110, train_loss: 0.0237\n",
            "106/110, train_loss: 0.0162\n",
            "107/110, train_loss: 0.0289\n",
            "108/110, train_loss: 0.0235\n",
            "109/110, train_loss: 0.0217\n",
            "110/110, train_loss: 0.0158\n",
            "epoch 64 average loss: 0.0232\n",
            "----------\n",
            "epoch 65/100\n",
            "1/110, train_loss: 0.0256\n",
            "2/110, train_loss: 0.0169\n",
            "3/110, train_loss: 0.0187\n",
            "4/110, train_loss: 0.0262\n",
            "5/110, train_loss: 0.0357\n",
            "6/110, train_loss: 0.0214\n",
            "7/110, train_loss: 0.0224\n",
            "8/110, train_loss: 0.0189\n",
            "9/110, train_loss: 0.0338\n",
            "10/110, train_loss: 0.0275\n",
            "11/110, train_loss: 0.0213\n",
            "12/110, train_loss: 0.0160\n",
            "13/110, train_loss: 0.0214\n",
            "14/110, train_loss: 0.0204\n",
            "15/110, train_loss: 0.0169\n",
            "16/110, train_loss: 0.0200\n",
            "17/110, train_loss: 0.0268\n",
            "18/110, train_loss: 0.0234\n",
            "19/110, train_loss: 0.0254\n",
            "20/110, train_loss: 0.0208\n",
            "21/110, train_loss: 0.0385\n",
            "22/110, train_loss: 0.0181\n",
            "23/110, train_loss: 0.0205\n",
            "24/110, train_loss: 0.0252\n",
            "25/110, train_loss: 0.0159\n",
            "26/110, train_loss: 0.0206\n",
            "27/110, train_loss: 0.0162\n",
            "28/110, train_loss: 0.0161\n",
            "29/110, train_loss: 0.0267\n",
            "30/110, train_loss: 0.0182\n",
            "31/110, train_loss: 0.0412\n",
            "32/110, train_loss: 0.0178\n",
            "33/110, train_loss: 0.0225\n",
            "34/110, train_loss: 0.0182\n",
            "35/110, train_loss: 0.0197\n",
            "36/110, train_loss: 0.0205\n",
            "37/110, train_loss: 0.0168\n",
            "38/110, train_loss: 0.0163\n",
            "39/110, train_loss: 0.0233\n",
            "40/110, train_loss: 0.0191\n",
            "41/110, train_loss: 0.0224\n",
            "42/110, train_loss: 0.0218\n",
            "43/110, train_loss: 0.0192\n",
            "44/110, train_loss: 0.0161\n",
            "45/110, train_loss: 0.0225\n",
            "46/110, train_loss: 0.0182\n",
            "47/110, train_loss: 0.0189\n",
            "48/110, train_loss: 0.0198\n",
            "49/110, train_loss: 0.0185\n",
            "50/110, train_loss: 0.0156\n",
            "51/110, train_loss: 0.0175\n",
            "52/110, train_loss: 0.0168\n",
            "53/110, train_loss: 0.0166\n",
            "54/110, train_loss: 0.0384\n",
            "55/110, train_loss: 0.0187\n",
            "56/110, train_loss: 0.0176\n",
            "57/110, train_loss: 0.0380\n",
            "58/110, train_loss: 0.0600\n",
            "59/110, train_loss: 0.0159\n",
            "60/110, train_loss: 0.0160\n",
            "61/110, train_loss: 0.0222\n",
            "62/110, train_loss: 0.0241\n",
            "63/110, train_loss: 0.0257\n",
            "64/110, train_loss: 0.0227\n",
            "65/110, train_loss: 0.0229\n",
            "66/110, train_loss: 0.0182\n",
            "67/110, train_loss: 0.0206\n",
            "68/110, train_loss: 0.0298\n",
            "69/110, train_loss: 0.0198\n",
            "70/110, train_loss: 0.0193\n",
            "71/110, train_loss: 0.0251\n",
            "72/110, train_loss: 0.0398\n",
            "73/110, train_loss: 0.0535\n",
            "74/110, train_loss: 0.0202\n",
            "75/110, train_loss: 0.0179\n",
            "76/110, train_loss: 0.0237\n",
            "77/110, train_loss: 0.0192\n",
            "78/110, train_loss: 0.0284\n",
            "79/110, train_loss: 0.0217\n",
            "80/110, train_loss: 0.0304\n",
            "81/110, train_loss: 0.0153\n",
            "82/110, train_loss: 0.0152\n",
            "83/110, train_loss: 0.0162\n",
            "84/110, train_loss: 0.0243\n",
            "85/110, train_loss: 0.0199\n",
            "86/110, train_loss: 0.0179\n",
            "87/110, train_loss: 0.0153\n",
            "88/110, train_loss: 0.0196\n",
            "89/110, train_loss: 0.0187\n",
            "90/110, train_loss: 0.0161\n",
            "91/110, train_loss: 0.0192\n",
            "92/110, train_loss: 0.0229\n",
            "93/110, train_loss: 0.0164\n",
            "94/110, train_loss: 0.0205\n",
            "95/110, train_loss: 0.0158\n",
            "96/110, train_loss: 0.0214\n",
            "97/110, train_loss: 0.0157\n",
            "98/110, train_loss: 0.0150\n",
            "99/110, train_loss: 0.0241\n",
            "100/110, train_loss: 0.0190\n",
            "101/110, train_loss: 0.0150\n",
            "102/110, train_loss: 0.0274\n",
            "103/110, train_loss: 0.0157\n",
            "104/110, train_loss: 0.0159\n",
            "105/110, train_loss: 0.0227\n",
            "106/110, train_loss: 0.0191\n",
            "107/110, train_loss: 0.0241\n",
            "108/110, train_loss: 0.0204\n",
            "109/110, train_loss: 0.0244\n",
            "110/110, train_loss: 0.0146\n",
            "epoch 65 average loss: 0.0219\n",
            "----------\n",
            "epoch 66/100\n",
            "1/110, train_loss: 0.0153\n",
            "2/110, train_loss: 0.0242\n",
            "3/110, train_loss: 0.0198\n",
            "4/110, train_loss: 0.0153\n",
            "5/110, train_loss: 0.0156\n",
            "6/110, train_loss: 0.0234\n",
            "7/110, train_loss: 0.0152\n",
            "8/110, train_loss: 0.0227\n",
            "9/110, train_loss: 0.0171\n",
            "10/110, train_loss: 0.0188\n",
            "11/110, train_loss: 0.0189\n",
            "12/110, train_loss: 0.0152\n",
            "13/110, train_loss: 0.0143\n",
            "14/110, train_loss: 0.0182\n",
            "15/110, train_loss: 0.0217\n",
            "16/110, train_loss: 0.0144\n",
            "17/110, train_loss: 0.0386\n",
            "18/110, train_loss: 0.0195\n",
            "19/110, train_loss: 0.0151\n",
            "20/110, train_loss: 0.0249\n",
            "21/110, train_loss: 0.0168\n",
            "22/110, train_loss: 0.0594\n",
            "23/110, train_loss: 0.0180\n",
            "24/110, train_loss: 0.0204\n",
            "25/110, train_loss: 0.0196\n",
            "26/110, train_loss: 0.0269\n",
            "27/110, train_loss: 0.0195\n",
            "28/110, train_loss: 0.0367\n",
            "29/110, train_loss: 0.0231\n",
            "30/110, train_loss: 0.0174\n",
            "31/110, train_loss: 0.0149\n",
            "32/110, train_loss: 0.0154\n",
            "33/110, train_loss: 0.0356\n",
            "34/110, train_loss: 0.0217\n",
            "35/110, train_loss: 0.0217\n",
            "36/110, train_loss: 0.0157\n",
            "37/110, train_loss: 0.0193\n",
            "38/110, train_loss: 0.0172\n",
            "39/110, train_loss: 0.0183\n",
            "40/110, train_loss: 0.0217\n",
            "41/110, train_loss: 0.0183\n",
            "42/110, train_loss: 0.0171\n",
            "43/110, train_loss: 0.0370\n",
            "44/110, train_loss: 0.0195\n",
            "45/110, train_loss: 0.0226\n",
            "46/110, train_loss: 0.0238\n",
            "47/110, train_loss: 0.0277\n",
            "48/110, train_loss: 0.0154\n",
            "49/110, train_loss: 0.0151\n",
            "50/110, train_loss: 0.0174\n",
            "51/110, train_loss: 0.0156\n",
            "52/110, train_loss: 0.0334\n",
            "53/110, train_loss: 0.0198\n",
            "54/110, train_loss: 0.0149\n",
            "55/110, train_loss: 0.0155\n",
            "56/110, train_loss: 0.0161\n",
            "57/110, train_loss: 0.0202\n",
            "58/110, train_loss: 0.0158\n",
            "59/110, train_loss: 0.0215\n",
            "60/110, train_loss: 0.0228\n",
            "61/110, train_loss: 0.0315\n",
            "62/110, train_loss: 0.0180\n",
            "63/110, train_loss: 0.0168\n",
            "64/110, train_loss: 0.0218\n",
            "65/110, train_loss: 0.0251\n",
            "66/110, train_loss: 0.0167\n",
            "67/110, train_loss: 0.0176\n",
            "68/110, train_loss: 0.0213\n",
            "69/110, train_loss: 0.0271\n",
            "70/110, train_loss: 0.0184\n",
            "71/110, train_loss: 0.0148\n",
            "72/110, train_loss: 0.0202\n",
            "73/110, train_loss: 0.0226\n",
            "74/110, train_loss: 0.0212\n",
            "75/110, train_loss: 0.0185\n",
            "76/110, train_loss: 0.0170\n",
            "77/110, train_loss: 0.0145\n",
            "78/110, train_loss: 0.0285\n",
            "79/110, train_loss: 0.0200\n",
            "80/110, train_loss: 0.0160\n",
            "81/110, train_loss: 0.0190\n",
            "82/110, train_loss: 0.0192\n",
            "83/110, train_loss: 0.0188\n",
            "84/110, train_loss: 0.0200\n",
            "85/110, train_loss: 0.0147\n",
            "86/110, train_loss: 0.0225\n",
            "87/110, train_loss: 0.0157\n",
            "88/110, train_loss: 0.0223\n",
            "89/110, train_loss: 0.0142\n",
            "90/110, train_loss: 0.0397\n",
            "91/110, train_loss: 0.0492\n",
            "92/110, train_loss: 0.0176\n",
            "93/110, train_loss: 0.0243\n",
            "94/110, train_loss: 0.0181\n",
            "95/110, train_loss: 0.0214\n",
            "96/110, train_loss: 0.0199\n",
            "97/110, train_loss: 0.0179\n",
            "98/110, train_loss: 0.0188\n",
            "99/110, train_loss: 0.0143\n",
            "100/110, train_loss: 0.0167\n",
            "101/110, train_loss: 0.0184\n",
            "102/110, train_loss: 0.0182\n",
            "103/110, train_loss: 0.0146\n",
            "104/110, train_loss: 0.0222\n",
            "105/110, train_loss: 0.0259\n",
            "106/110, train_loss: 0.0246\n",
            "107/110, train_loss: 0.0209\n",
            "108/110, train_loss: 0.0155\n",
            "109/110, train_loss: 0.0247\n",
            "110/110, train_loss: 0.0167\n",
            "epoch 66 average loss: 0.0208\n",
            "current epoch: 66 current accuracy: 0.7143 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 67/100\n",
            "1/110, train_loss: 0.0145\n",
            "2/110, train_loss: 0.0274\n",
            "3/110, train_loss: 0.0175\n",
            "4/110, train_loss: 0.0148\n",
            "5/110, train_loss: 0.0186\n",
            "6/110, train_loss: 0.0248\n",
            "7/110, train_loss: 0.0177\n",
            "8/110, train_loss: 0.0188\n",
            "9/110, train_loss: 0.0143\n",
            "10/110, train_loss: 0.0180\n",
            "11/110, train_loss: 0.0217\n",
            "12/110, train_loss: 0.0208\n",
            "13/110, train_loss: 0.0459\n",
            "14/110, train_loss: 0.0177\n",
            "15/110, train_loss: 0.0204\n",
            "16/110, train_loss: 0.0147\n",
            "17/110, train_loss: 0.0160\n",
            "18/110, train_loss: 0.0140\n",
            "19/110, train_loss: 0.0179\n",
            "20/110, train_loss: 0.0235\n",
            "21/110, train_loss: 0.0151\n",
            "22/110, train_loss: 0.0180\n",
            "23/110, train_loss: 0.0138\n",
            "24/110, train_loss: 0.0146\n",
            "25/110, train_loss: 0.0222\n",
            "26/110, train_loss: 0.0252\n",
            "27/110, train_loss: 0.0173\n",
            "28/110, train_loss: 0.0220\n",
            "29/110, train_loss: 0.0143\n",
            "30/110, train_loss: 0.0204\n",
            "31/110, train_loss: 0.0225\n",
            "32/110, train_loss: 0.0144\n",
            "33/110, train_loss: 0.0270\n",
            "34/110, train_loss: 0.0257\n",
            "35/110, train_loss: 0.0222\n",
            "36/110, train_loss: 0.0174\n",
            "37/110, train_loss: 0.0144\n",
            "38/110, train_loss: 0.0167\n",
            "39/110, train_loss: 0.0334\n",
            "40/110, train_loss: 0.0142\n",
            "41/110, train_loss: 0.0199\n",
            "42/110, train_loss: 0.0158\n",
            "43/110, train_loss: 0.0532\n",
            "44/110, train_loss: 0.0158\n",
            "45/110, train_loss: 0.0136\n",
            "46/110, train_loss: 0.0138\n",
            "47/110, train_loss: 0.0147\n",
            "48/110, train_loss: 0.0148\n",
            "49/110, train_loss: 0.0138\n",
            "50/110, train_loss: 0.0179\n",
            "51/110, train_loss: 0.0245\n",
            "52/110, train_loss: 0.0181\n",
            "53/110, train_loss: 0.0137\n",
            "54/110, train_loss: 0.0201\n",
            "55/110, train_loss: 0.0229\n",
            "56/110, train_loss: 0.0167\n",
            "57/110, train_loss: 0.0202\n",
            "58/110, train_loss: 0.0177\n",
            "59/110, train_loss: 0.0197\n",
            "60/110, train_loss: 0.0142\n",
            "61/110, train_loss: 0.0147\n",
            "62/110, train_loss: 0.0185\n",
            "63/110, train_loss: 0.0133\n",
            "64/110, train_loss: 0.0152\n",
            "65/110, train_loss: 0.0245\n",
            "66/110, train_loss: 0.0140\n",
            "67/110, train_loss: 0.0189\n",
            "68/110, train_loss: 0.0355\n",
            "69/110, train_loss: 0.0174\n",
            "70/110, train_loss: 0.0210\n",
            "71/110, train_loss: 0.0179\n",
            "72/110, train_loss: 0.0196\n",
            "73/110, train_loss: 0.0165\n",
            "74/110, train_loss: 0.0213\n",
            "75/110, train_loss: 0.0161\n",
            "76/110, train_loss: 0.0152\n",
            "77/110, train_loss: 0.0210\n",
            "78/110, train_loss: 0.0241\n",
            "79/110, train_loss: 0.0329\n",
            "80/110, train_loss: 0.0195\n",
            "81/110, train_loss: 0.0187\n",
            "82/110, train_loss: 0.0183\n",
            "83/110, train_loss: 0.0147\n",
            "84/110, train_loss: 0.0144\n",
            "85/110, train_loss: 0.0133\n",
            "86/110, train_loss: 0.0195\n",
            "87/110, train_loss: 0.0307\n",
            "88/110, train_loss: 0.0192\n",
            "89/110, train_loss: 0.0182\n",
            "90/110, train_loss: 0.0159\n",
            "91/110, train_loss: 0.0383\n",
            "92/110, train_loss: 0.0210\n",
            "93/110, train_loss: 0.0159\n",
            "94/110, train_loss: 0.0158\n",
            "95/110, train_loss: 0.0139\n",
            "96/110, train_loss: 0.0135\n",
            "97/110, train_loss: 0.0198\n",
            "98/110, train_loss: 0.0202\n",
            "99/110, train_loss: 0.0170\n",
            "100/110, train_loss: 0.0229\n",
            "101/110, train_loss: 0.0251\n",
            "102/110, train_loss: 0.0215\n",
            "103/110, train_loss: 0.0156\n",
            "104/110, train_loss: 0.0349\n",
            "105/110, train_loss: 0.0165\n",
            "106/110, train_loss: 0.0188\n",
            "107/110, train_loss: 0.0213\n",
            "108/110, train_loss: 0.0154\n",
            "109/110, train_loss: 0.0337\n",
            "110/110, train_loss: 0.0187\n",
            "epoch 67 average loss: 0.0197\n",
            "----------\n",
            "epoch 68/100\n",
            "1/110, train_loss: 0.0142\n",
            "2/110, train_loss: 0.0176\n",
            "3/110, train_loss: 0.0216\n",
            "4/110, train_loss: 0.0153\n",
            "5/110, train_loss: 0.0194\n",
            "6/110, train_loss: 0.0177\n",
            "7/110, train_loss: 0.0169\n",
            "8/110, train_loss: 0.0131\n",
            "9/110, train_loss: 0.0201\n",
            "10/110, train_loss: 0.0502\n",
            "11/110, train_loss: 0.0168\n",
            "12/110, train_loss: 0.0134\n",
            "13/110, train_loss: 0.0174\n",
            "14/110, train_loss: 0.0134\n",
            "15/110, train_loss: 0.0192\n",
            "16/110, train_loss: 0.0199\n",
            "17/110, train_loss: 0.0311\n",
            "18/110, train_loss: 0.0156\n",
            "19/110, train_loss: 0.0146\n",
            "20/110, train_loss: 0.0152\n",
            "21/110, train_loss: 0.0171\n",
            "22/110, train_loss: 0.0377\n",
            "23/110, train_loss: 0.0180\n",
            "24/110, train_loss: 0.0174\n",
            "25/110, train_loss: 0.0164\n",
            "26/110, train_loss: 0.0139\n",
            "27/110, train_loss: 0.0263\n",
            "28/110, train_loss: 0.0184\n",
            "29/110, train_loss: 0.0161\n",
            "30/110, train_loss: 0.0254\n",
            "31/110, train_loss: 0.0323\n",
            "32/110, train_loss: 0.0172\n",
            "33/110, train_loss: 0.0141\n",
            "34/110, train_loss: 0.0216\n",
            "35/110, train_loss: 0.0143\n",
            "36/110, train_loss: 0.0209\n",
            "37/110, train_loss: 0.0203\n",
            "38/110, train_loss: 0.0140\n",
            "39/110, train_loss: 0.0136\n",
            "40/110, train_loss: 0.0138\n",
            "41/110, train_loss: 0.0138\n",
            "42/110, train_loss: 0.0141\n",
            "43/110, train_loss: 0.0161\n",
            "44/110, train_loss: 0.0136\n",
            "45/110, train_loss: 0.0164\n",
            "46/110, train_loss: 0.0144\n",
            "47/110, train_loss: 0.0184\n",
            "48/110, train_loss: 0.0150\n",
            "49/110, train_loss: 0.0199\n",
            "50/110, train_loss: 0.0176\n",
            "51/110, train_loss: 0.0216\n",
            "52/110, train_loss: 0.0170\n",
            "53/110, train_loss: 0.0178\n",
            "54/110, train_loss: 0.0206\n",
            "55/110, train_loss: 0.0164\n",
            "56/110, train_loss: 0.0128\n",
            "57/110, train_loss: 0.0149\n",
            "58/110, train_loss: 0.0133\n",
            "59/110, train_loss: 0.0180\n",
            "60/110, train_loss: 0.0299\n",
            "61/110, train_loss: 0.0209\n",
            "62/110, train_loss: 0.0167\n",
            "63/110, train_loss: 0.0227\n",
            "64/110, train_loss: 0.0185\n",
            "65/110, train_loss: 0.0207\n",
            "66/110, train_loss: 0.0148\n",
            "67/110, train_loss: 0.0184\n",
            "68/110, train_loss: 0.0191\n",
            "69/110, train_loss: 0.0234\n",
            "70/110, train_loss: 0.0169\n",
            "71/110, train_loss: 0.0221\n",
            "72/110, train_loss: 0.0133\n",
            "73/110, train_loss: 0.0137\n",
            "74/110, train_loss: 0.0320\n",
            "75/110, train_loss: 0.0238\n",
            "76/110, train_loss: 0.0215\n",
            "77/110, train_loss: 0.0140\n",
            "78/110, train_loss: 0.0236\n",
            "79/110, train_loss: 0.0132\n",
            "80/110, train_loss: 0.0138\n",
            "81/110, train_loss: 0.0141\n",
            "82/110, train_loss: 0.0164\n",
            "83/110, train_loss: 0.0312\n",
            "84/110, train_loss: 0.0170\n",
            "85/110, train_loss: 0.0193\n",
            "86/110, train_loss: 0.0131\n",
            "87/110, train_loss: 0.0188\n",
            "88/110, train_loss: 0.0153\n",
            "89/110, train_loss: 0.0130\n",
            "90/110, train_loss: 0.0151\n",
            "91/110, train_loss: 0.0129\n",
            "92/110, train_loss: 0.0220\n",
            "93/110, train_loss: 0.0170\n",
            "94/110, train_loss: 0.0187\n",
            "95/110, train_loss: 0.0203\n",
            "96/110, train_loss: 0.0435\n",
            "97/110, train_loss: 0.0203\n",
            "98/110, train_loss: 0.0237\n",
            "99/110, train_loss: 0.0187\n",
            "100/110, train_loss: 0.0154\n",
            "101/110, train_loss: 0.0148\n",
            "102/110, train_loss: 0.0185\n",
            "103/110, train_loss: 0.0179\n",
            "104/110, train_loss: 0.0153\n",
            "105/110, train_loss: 0.0134\n",
            "106/110, train_loss: 0.0338\n",
            "107/110, train_loss: 0.0217\n",
            "108/110, train_loss: 0.0184\n",
            "109/110, train_loss: 0.0159\n",
            "110/110, train_loss: 0.0146\n",
            "epoch 68 average loss: 0.0188\n",
            "----------\n",
            "epoch 69/100\n",
            "1/110, train_loss: 0.0161\n",
            "2/110, train_loss: 0.0155\n",
            "3/110, train_loss: 0.0130\n",
            "4/110, train_loss: 0.0165\n",
            "5/110, train_loss: 0.0168\n",
            "6/110, train_loss: 0.0159\n",
            "7/110, train_loss: 0.0136\n",
            "8/110, train_loss: 0.0160\n",
            "9/110, train_loss: 0.0144\n",
            "10/110, train_loss: 0.0162\n",
            "11/110, train_loss: 0.0134\n",
            "12/110, train_loss: 0.0277\n",
            "13/110, train_loss: 0.0227\n",
            "14/110, train_loss: 0.0199\n",
            "15/110, train_loss: 0.0169\n",
            "16/110, train_loss: 0.0127\n",
            "17/110, train_loss: 0.0182\n",
            "18/110, train_loss: 0.0133\n",
            "19/110, train_loss: 0.0127\n",
            "20/110, train_loss: 0.0209\n",
            "21/110, train_loss: 0.0145\n",
            "22/110, train_loss: 0.0195\n",
            "23/110, train_loss: 0.0182\n",
            "24/110, train_loss: 0.0185\n",
            "25/110, train_loss: 0.0180\n",
            "26/110, train_loss: 0.0208\n",
            "27/110, train_loss: 0.0137\n",
            "28/110, train_loss: 0.0134\n",
            "29/110, train_loss: 0.0175\n",
            "30/110, train_loss: 0.0244\n",
            "31/110, train_loss: 0.0145\n",
            "32/110, train_loss: 0.0198\n",
            "33/110, train_loss: 0.0160\n",
            "34/110, train_loss: 0.0215\n",
            "35/110, train_loss: 0.0160\n",
            "36/110, train_loss: 0.0158\n",
            "37/110, train_loss: 0.0129\n",
            "38/110, train_loss: 0.0227\n",
            "39/110, train_loss: 0.0144\n",
            "40/110, train_loss: 0.0141\n",
            "41/110, train_loss: 0.0152\n",
            "42/110, train_loss: 0.0187\n",
            "43/110, train_loss: 0.0223\n",
            "44/110, train_loss: 0.0169\n",
            "45/110, train_loss: 0.0203\n",
            "46/110, train_loss: 0.0173\n",
            "47/110, train_loss: 0.0169\n",
            "48/110, train_loss: 0.0124\n",
            "49/110, train_loss: 0.0137\n",
            "50/110, train_loss: 0.0178\n",
            "51/110, train_loss: 0.0166\n",
            "52/110, train_loss: 0.0126\n",
            "53/110, train_loss: 0.0161\n",
            "54/110, train_loss: 0.0193\n",
            "55/110, train_loss: 0.0407\n",
            "56/110, train_loss: 0.0130\n",
            "57/110, train_loss: 0.0299\n",
            "58/110, train_loss: 0.0197\n",
            "59/110, train_loss: 0.0298\n",
            "60/110, train_loss: 0.0127\n",
            "61/110, train_loss: 0.0141\n",
            "62/110, train_loss: 0.0130\n",
            "63/110, train_loss: 0.0177\n",
            "64/110, train_loss: 0.0189\n",
            "65/110, train_loss: 0.0141\n",
            "66/110, train_loss: 0.0178\n",
            "67/110, train_loss: 0.0165\n",
            "68/110, train_loss: 0.0161\n",
            "69/110, train_loss: 0.0134\n",
            "70/110, train_loss: 0.0189\n",
            "71/110, train_loss: 0.0128\n",
            "72/110, train_loss: 0.0142\n",
            "73/110, train_loss: 0.0122\n",
            "74/110, train_loss: 0.0149\n",
            "75/110, train_loss: 0.0121\n",
            "76/110, train_loss: 0.0215\n",
            "77/110, train_loss: 0.0173\n",
            "78/110, train_loss: 0.0159\n",
            "79/110, train_loss: 0.0120\n",
            "80/110, train_loss: 0.0473\n",
            "81/110, train_loss: 0.0130\n",
            "82/110, train_loss: 0.0176\n",
            "83/110, train_loss: 0.0121\n",
            "84/110, train_loss: 0.0130\n",
            "85/110, train_loss: 0.0227\n",
            "86/110, train_loss: 0.0301\n",
            "87/110, train_loss: 0.0179\n",
            "88/110, train_loss: 0.0143\n",
            "89/110, train_loss: 0.0126\n",
            "90/110, train_loss: 0.0208\n",
            "91/110, train_loss: 0.0199\n",
            "92/110, train_loss: 0.0304\n",
            "93/110, train_loss: 0.0216\n",
            "94/110, train_loss: 0.0149\n",
            "95/110, train_loss: 0.0138\n",
            "96/110, train_loss: 0.0189\n",
            "97/110, train_loss: 0.0316\n",
            "98/110, train_loss: 0.0159\n",
            "99/110, train_loss: 0.0145\n",
            "100/110, train_loss: 0.0127\n",
            "101/110, train_loss: 0.0183\n",
            "102/110, train_loss: 0.0154\n",
            "103/110, train_loss: 0.0178\n",
            "104/110, train_loss: 0.0358\n",
            "105/110, train_loss: 0.0165\n",
            "106/110, train_loss: 0.0239\n",
            "107/110, train_loss: 0.0129\n",
            "108/110, train_loss: 0.0161\n",
            "109/110, train_loss: 0.0126\n",
            "110/110, train_loss: 0.0195\n",
            "epoch 69 average loss: 0.0178\n",
            "current epoch: 69 current accuracy: 0.8571 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 70/100\n",
            "1/110, train_loss: 0.0126\n",
            "2/110, train_loss: 0.0121\n",
            "3/110, train_loss: 0.0167\n",
            "4/110, train_loss: 0.0134\n",
            "5/110, train_loss: 0.0168\n",
            "6/110, train_loss: 0.0168\n",
            "7/110, train_loss: 0.0190\n",
            "8/110, train_loss: 0.0187\n",
            "9/110, train_loss: 0.0177\n",
            "10/110, train_loss: 0.0146\n",
            "11/110, train_loss: 0.0201\n",
            "12/110, train_loss: 0.0399\n",
            "13/110, train_loss: 0.0172\n",
            "14/110, train_loss: 0.0140\n",
            "15/110, train_loss: 0.0167\n",
            "16/110, train_loss: 0.0182\n",
            "17/110, train_loss: 0.0270\n",
            "18/110, train_loss: 0.0141\n",
            "19/110, train_loss: 0.0176\n",
            "20/110, train_loss: 0.0124\n",
            "21/110, train_loss: 0.0158\n",
            "22/110, train_loss: 0.0130\n",
            "23/110, train_loss: 0.0124\n",
            "24/110, train_loss: 0.0160\n",
            "25/110, train_loss: 0.0224\n",
            "26/110, train_loss: 0.0127\n",
            "27/110, train_loss: 0.0123\n",
            "28/110, train_loss: 0.0164\n",
            "29/110, train_loss: 0.0120\n",
            "30/110, train_loss: 0.0120\n",
            "31/110, train_loss: 0.0142\n",
            "32/110, train_loss: 0.0148\n",
            "33/110, train_loss: 0.0158\n",
            "34/110, train_loss: 0.0141\n",
            "35/110, train_loss: 0.0161\n",
            "36/110, train_loss: 0.0283\n",
            "37/110, train_loss: 0.0471\n",
            "38/110, train_loss: 0.0177\n",
            "39/110, train_loss: 0.0175\n",
            "40/110, train_loss: 0.0126\n",
            "41/110, train_loss: 0.0203\n",
            "42/110, train_loss: 0.0153\n",
            "43/110, train_loss: 0.0122\n",
            "44/110, train_loss: 0.0166\n",
            "45/110, train_loss: 0.0144\n",
            "46/110, train_loss: 0.0130\n",
            "47/110, train_loss: 0.0130\n",
            "48/110, train_loss: 0.0196\n",
            "49/110, train_loss: 0.0150\n",
            "50/110, train_loss: 0.0185\n",
            "51/110, train_loss: 0.0142\n",
            "52/110, train_loss: 0.0157\n",
            "53/110, train_loss: 0.0242\n",
            "54/110, train_loss: 0.0126\n",
            "55/110, train_loss: 0.0177\n",
            "56/110, train_loss: 0.0197\n",
            "57/110, train_loss: 0.0175\n",
            "58/110, train_loss: 0.0201\n",
            "59/110, train_loss: 0.0185\n",
            "60/110, train_loss: 0.0174\n",
            "61/110, train_loss: 0.0137\n",
            "62/110, train_loss: 0.0207\n",
            "63/110, train_loss: 0.0132\n",
            "64/110, train_loss: 0.0121\n",
            "65/110, train_loss: 0.0207\n",
            "66/110, train_loss: 0.0123\n",
            "67/110, train_loss: 0.0157\n",
            "68/110, train_loss: 0.0337\n",
            "69/110, train_loss: 0.0130\n",
            "70/110, train_loss: 0.0154\n",
            "71/110, train_loss: 0.0179\n",
            "72/110, train_loss: 0.0148\n",
            "73/110, train_loss: 0.0219\n",
            "74/110, train_loss: 0.0131\n",
            "75/110, train_loss: 0.0146\n",
            "76/110, train_loss: 0.0151\n",
            "77/110, train_loss: 0.0159\n",
            "78/110, train_loss: 0.0152\n",
            "79/110, train_loss: 0.0128\n",
            "80/110, train_loss: 0.0151\n",
            "81/110, train_loss: 0.0125\n",
            "82/110, train_loss: 0.0201\n",
            "83/110, train_loss: 0.0126\n",
            "84/110, train_loss: 0.0126\n",
            "85/110, train_loss: 0.0296\n",
            "86/110, train_loss: 0.0295\n",
            "87/110, train_loss: 0.0138\n",
            "88/110, train_loss: 0.0163\n",
            "89/110, train_loss: 0.0143\n",
            "90/110, train_loss: 0.0218\n",
            "91/110, train_loss: 0.0135\n",
            "92/110, train_loss: 0.0292\n",
            "93/110, train_loss: 0.0184\n",
            "94/110, train_loss: 0.0166\n",
            "95/110, train_loss: 0.0145\n",
            "96/110, train_loss: 0.0147\n",
            "97/110, train_loss: 0.0123\n",
            "98/110, train_loss: 0.0152\n",
            "99/110, train_loss: 0.0139\n",
            "100/110, train_loss: 0.0174\n",
            "101/110, train_loss: 0.0147\n",
            "102/110, train_loss: 0.0152\n",
            "103/110, train_loss: 0.0156\n",
            "104/110, train_loss: 0.0130\n",
            "105/110, train_loss: 0.0147\n",
            "106/110, train_loss: 0.0139\n",
            "107/110, train_loss: 0.0257\n",
            "108/110, train_loss: 0.0190\n",
            "109/110, train_loss: 0.0126\n",
            "110/110, train_loss: 0.0175\n",
            "epoch 70 average loss: 0.0170\n",
            "----------\n",
            "epoch 71/100\n",
            "1/110, train_loss: 0.0205\n",
            "2/110, train_loss: 0.0179\n",
            "3/110, train_loss: 0.0151\n",
            "4/110, train_loss: 0.0122\n",
            "5/110, train_loss: 0.0128\n",
            "6/110, train_loss: 0.0160\n",
            "7/110, train_loss: 0.0143\n",
            "8/110, train_loss: 0.0192\n",
            "9/110, train_loss: 0.0152\n",
            "10/110, train_loss: 0.0157\n",
            "11/110, train_loss: 0.0141\n",
            "12/110, train_loss: 0.0117\n",
            "13/110, train_loss: 0.0126\n",
            "14/110, train_loss: 0.0135\n",
            "15/110, train_loss: 0.0146\n",
            "16/110, train_loss: 0.0151\n",
            "17/110, train_loss: 0.0148\n",
            "18/110, train_loss: 0.0151\n",
            "19/110, train_loss: 0.0156\n",
            "20/110, train_loss: 0.0116\n",
            "21/110, train_loss: 0.0117\n",
            "22/110, train_loss: 0.0124\n",
            "23/110, train_loss: 0.0266\n",
            "24/110, train_loss: 0.0118\n",
            "25/110, train_loss: 0.0122\n",
            "26/110, train_loss: 0.0141\n",
            "27/110, train_loss: 0.0178\n",
            "28/110, train_loss: 0.0161\n",
            "29/110, train_loss: 0.0140\n",
            "30/110, train_loss: 0.0146\n",
            "31/110, train_loss: 0.0145\n",
            "32/110, train_loss: 0.0123\n",
            "33/110, train_loss: 0.0146\n",
            "34/110, train_loss: 0.0165\n",
            "35/110, train_loss: 0.0189\n",
            "36/110, train_loss: 0.0139\n",
            "37/110, train_loss: 0.0186\n",
            "38/110, train_loss: 0.0157\n",
            "39/110, train_loss: 0.0154\n",
            "40/110, train_loss: 0.0121\n",
            "41/110, train_loss: 0.0121\n",
            "42/110, train_loss: 0.0181\n",
            "43/110, train_loss: 0.0211\n",
            "44/110, train_loss: 0.0276\n",
            "45/110, train_loss: 0.0127\n",
            "46/110, train_loss: 0.0117\n",
            "47/110, train_loss: 0.0148\n",
            "48/110, train_loss: 0.0114\n",
            "49/110, train_loss: 0.0206\n",
            "50/110, train_loss: 0.0166\n",
            "51/110, train_loss: 0.0132\n",
            "52/110, train_loss: 0.0134\n",
            "53/110, train_loss: 0.0154\n",
            "54/110, train_loss: 0.0120\n",
            "55/110, train_loss: 0.0118\n",
            "56/110, train_loss: 0.0163\n",
            "57/110, train_loss: 0.0126\n",
            "58/110, train_loss: 0.0178\n",
            "59/110, train_loss: 0.0148\n",
            "60/110, train_loss: 0.0113\n",
            "61/110, train_loss: 0.0257\n",
            "62/110, train_loss: 0.0165\n",
            "63/110, train_loss: 0.0316\n",
            "64/110, train_loss: 0.0174\n",
            "65/110, train_loss: 0.0372\n",
            "66/110, train_loss: 0.0188\n",
            "67/110, train_loss: 0.0124\n",
            "68/110, train_loss: 0.0197\n",
            "69/110, train_loss: 0.0133\n",
            "70/110, train_loss: 0.0142\n",
            "71/110, train_loss: 0.0145\n",
            "72/110, train_loss: 0.0120\n",
            "73/110, train_loss: 0.0167\n",
            "74/110, train_loss: 0.0212\n",
            "75/110, train_loss: 0.0113\n",
            "76/110, train_loss: 0.0451\n",
            "77/110, train_loss: 0.0143\n",
            "78/110, train_loss: 0.0166\n",
            "79/110, train_loss: 0.0143\n",
            "80/110, train_loss: 0.0166\n",
            "81/110, train_loss: 0.0117\n",
            "82/110, train_loss: 0.0278\n",
            "83/110, train_loss: 0.0166\n",
            "84/110, train_loss: 0.0138\n",
            "85/110, train_loss: 0.0115\n",
            "86/110, train_loss: 0.0120\n",
            "87/110, train_loss: 0.0193\n",
            "88/110, train_loss: 0.0148\n",
            "89/110, train_loss: 0.0135\n",
            "90/110, train_loss: 0.0120\n",
            "91/110, train_loss: 0.0226\n",
            "92/110, train_loss: 0.0117\n",
            "93/110, train_loss: 0.0132\n",
            "94/110, train_loss: 0.0201\n",
            "95/110, train_loss: 0.0131\n",
            "96/110, train_loss: 0.0148\n",
            "97/110, train_loss: 0.0138\n",
            "98/110, train_loss: 0.0138\n",
            "99/110, train_loss: 0.0174\n",
            "100/110, train_loss: 0.0243\n",
            "101/110, train_loss: 0.0130\n",
            "102/110, train_loss: 0.0133\n",
            "103/110, train_loss: 0.0177\n",
            "104/110, train_loss: 0.0163\n",
            "105/110, train_loss: 0.0282\n",
            "106/110, train_loss: 0.0156\n",
            "107/110, train_loss: 0.0122\n",
            "108/110, train_loss: 0.0171\n",
            "109/110, train_loss: 0.0162\n",
            "110/110, train_loss: 0.0126\n",
            "epoch 71 average loss: 0.0161\n",
            "----------\n",
            "epoch 72/100\n",
            "1/110, train_loss: 0.0168\n",
            "2/110, train_loss: 0.0127\n",
            "3/110, train_loss: 0.0154\n",
            "4/110, train_loss: 0.0143\n",
            "5/110, train_loss: 0.0123\n",
            "6/110, train_loss: 0.0115\n",
            "7/110, train_loss: 0.0265\n",
            "8/110, train_loss: 0.0139\n",
            "9/110, train_loss: 0.0124\n",
            "10/110, train_loss: 0.0145\n",
            "11/110, train_loss: 0.0160\n",
            "12/110, train_loss: 0.0142\n",
            "13/110, train_loss: 0.0148\n",
            "14/110, train_loss: 0.0180\n",
            "15/110, train_loss: 0.0137\n",
            "16/110, train_loss: 0.0115\n",
            "17/110, train_loss: 0.0183\n",
            "18/110, train_loss: 0.0154\n",
            "19/110, train_loss: 0.0111\n",
            "20/110, train_loss: 0.0169\n",
            "21/110, train_loss: 0.0132\n",
            "22/110, train_loss: 0.0138\n",
            "23/110, train_loss: 0.0244\n",
            "24/110, train_loss: 0.0150\n",
            "25/110, train_loss: 0.0117\n",
            "26/110, train_loss: 0.0166\n",
            "27/110, train_loss: 0.0135\n",
            "28/110, train_loss: 0.0119\n",
            "29/110, train_loss: 0.0120\n",
            "30/110, train_loss: 0.0115\n",
            "31/110, train_loss: 0.0157\n",
            "32/110, train_loss: 0.0357\n",
            "33/110, train_loss: 0.0112\n",
            "34/110, train_loss: 0.0133\n",
            "35/110, train_loss: 0.0191\n",
            "36/110, train_loss: 0.0110\n",
            "37/110, train_loss: 0.0173\n",
            "38/110, train_loss: 0.0126\n",
            "39/110, train_loss: 0.0148\n",
            "40/110, train_loss: 0.0153\n",
            "41/110, train_loss: 0.0155\n",
            "42/110, train_loss: 0.0113\n",
            "43/110, train_loss: 0.0125\n",
            "44/110, train_loss: 0.0156\n",
            "45/110, train_loss: 0.0107\n",
            "46/110, train_loss: 0.0124\n",
            "47/110, train_loss: 0.0112\n",
            "48/110, train_loss: 0.0139\n",
            "49/110, train_loss: 0.0234\n",
            "50/110, train_loss: 0.0123\n",
            "51/110, train_loss: 0.0126\n",
            "52/110, train_loss: 0.0113\n",
            "53/110, train_loss: 0.0132\n",
            "54/110, train_loss: 0.0162\n",
            "55/110, train_loss: 0.0124\n",
            "56/110, train_loss: 0.0151\n",
            "57/110, train_loss: 0.0154\n",
            "58/110, train_loss: 0.0118\n",
            "59/110, train_loss: 0.0124\n",
            "60/110, train_loss: 0.0142\n",
            "61/110, train_loss: 0.0106\n",
            "62/110, train_loss: 0.0116\n",
            "63/110, train_loss: 0.0109\n",
            "64/110, train_loss: 0.0273\n",
            "65/110, train_loss: 0.0198\n",
            "66/110, train_loss: 0.0123\n",
            "67/110, train_loss: 0.0115\n",
            "68/110, train_loss: 0.0109\n",
            "69/110, train_loss: 0.0256\n",
            "70/110, train_loss: 0.0479\n",
            "71/110, train_loss: 0.0257\n",
            "72/110, train_loss: 0.0193\n",
            "73/110, train_loss: 0.0204\n",
            "74/110, train_loss: 0.0168\n",
            "75/110, train_loss: 0.0310\n",
            "76/110, train_loss: 0.0143\n",
            "77/110, train_loss: 0.0164\n",
            "78/110, train_loss: 0.0159\n",
            "79/110, train_loss: 0.0182\n",
            "80/110, train_loss: 0.0116\n",
            "81/110, train_loss: 0.0113\n",
            "82/110, train_loss: 0.0106\n",
            "83/110, train_loss: 0.0115\n",
            "84/110, train_loss: 0.0194\n",
            "85/110, train_loss: 0.0157\n",
            "86/110, train_loss: 0.0109\n",
            "87/110, train_loss: 0.0212\n",
            "88/110, train_loss: 0.0140\n",
            "89/110, train_loss: 0.0136\n",
            "90/110, train_loss: 0.0199\n",
            "91/110, train_loss: 0.0138\n",
            "92/110, train_loss: 0.0173\n",
            "93/110, train_loss: 0.0144\n",
            "94/110, train_loss: 0.0184\n",
            "95/110, train_loss: 0.0140\n",
            "96/110, train_loss: 0.0175\n",
            "97/110, train_loss: 0.0170\n",
            "98/110, train_loss: 0.0140\n",
            "99/110, train_loss: 0.0144\n",
            "100/110, train_loss: 0.0107\n",
            "101/110, train_loss: 0.0109\n",
            "102/110, train_loss: 0.0159\n",
            "103/110, train_loss: 0.0139\n",
            "104/110, train_loss: 0.0109\n",
            "105/110, train_loss: 0.0112\n",
            "106/110, train_loss: 0.0137\n",
            "107/110, train_loss: 0.0173\n",
            "108/110, train_loss: 0.0135\n",
            "109/110, train_loss: 0.0159\n",
            "110/110, train_loss: 0.0148\n",
            "epoch 72 average loss: 0.0154\n",
            "current epoch: 72 current accuracy: 0.7143 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 73/100\n",
            "1/110, train_loss: 0.0237\n",
            "2/110, train_loss: 0.0150\n",
            "3/110, train_loss: 0.0201\n",
            "4/110, train_loss: 0.0115\n",
            "5/110, train_loss: 0.0137\n",
            "6/110, train_loss: 0.0135\n",
            "7/110, train_loss: 0.0167\n",
            "8/110, train_loss: 0.0294\n",
            "9/110, train_loss: 0.0149\n",
            "10/110, train_loss: 0.0108\n",
            "11/110, train_loss: 0.0128\n",
            "12/110, train_loss: 0.0108\n",
            "13/110, train_loss: 0.0131\n",
            "14/110, train_loss: 0.0111\n",
            "15/110, train_loss: 0.0254\n",
            "16/110, train_loss: 0.0153\n",
            "17/110, train_loss: 0.0161\n",
            "18/110, train_loss: 0.0135\n",
            "19/110, train_loss: 0.0110\n",
            "20/110, train_loss: 0.0167\n",
            "21/110, train_loss: 0.0110\n",
            "22/110, train_loss: 0.0107\n",
            "23/110, train_loss: 0.0122\n",
            "24/110, train_loss: 0.0146\n",
            "25/110, train_loss: 0.0109\n",
            "26/110, train_loss: 0.0129\n",
            "27/110, train_loss: 0.0149\n",
            "28/110, train_loss: 0.0159\n",
            "29/110, train_loss: 0.0172\n",
            "30/110, train_loss: 0.0150\n",
            "31/110, train_loss: 0.0121\n",
            "32/110, train_loss: 0.0163\n",
            "33/110, train_loss: 0.0149\n",
            "34/110, train_loss: 0.0248\n",
            "35/110, train_loss: 0.0136\n",
            "36/110, train_loss: 0.0116\n",
            "37/110, train_loss: 0.0501\n",
            "38/110, train_loss: 0.0105\n",
            "39/110, train_loss: 0.0217\n",
            "40/110, train_loss: 0.0122\n",
            "41/110, train_loss: 0.0135\n",
            "42/110, train_loss: 0.0159\n",
            "43/110, train_loss: 0.0131\n",
            "44/110, train_loss: 0.0122\n",
            "45/110, train_loss: 0.0192\n",
            "46/110, train_loss: 0.0153\n",
            "47/110, train_loss: 0.0174\n",
            "48/110, train_loss: 0.0142\n",
            "49/110, train_loss: 0.0109\n",
            "50/110, train_loss: 0.0156\n",
            "51/110, train_loss: 0.0134\n",
            "52/110, train_loss: 0.0124\n",
            "53/110, train_loss: 0.0113\n",
            "54/110, train_loss: 0.0134\n",
            "55/110, train_loss: 0.0136\n",
            "56/110, train_loss: 0.0130\n",
            "57/110, train_loss: 0.0110\n",
            "58/110, train_loss: 0.0259\n",
            "59/110, train_loss: 0.0109\n",
            "60/110, train_loss: 0.0137\n",
            "61/110, train_loss: 0.0122\n",
            "62/110, train_loss: 0.0110\n",
            "63/110, train_loss: 0.0137\n",
            "64/110, train_loss: 0.0343\n",
            "65/110, train_loss: 0.0162\n",
            "66/110, train_loss: 0.0125\n",
            "67/110, train_loss: 0.0144\n",
            "68/110, train_loss: 0.0135\n",
            "69/110, train_loss: 0.0142\n",
            "70/110, train_loss: 0.0122\n",
            "71/110, train_loss: 0.0198\n",
            "72/110, train_loss: 0.0143\n",
            "73/110, train_loss: 0.0244\n",
            "74/110, train_loss: 0.0131\n",
            "75/110, train_loss: 0.0181\n",
            "76/110, train_loss: 0.0110\n",
            "77/110, train_loss: 0.0130\n",
            "78/110, train_loss: 0.0121\n",
            "79/110, train_loss: 0.0150\n",
            "80/110, train_loss: 0.0102\n",
            "81/110, train_loss: 0.0103\n",
            "82/110, train_loss: 0.0125\n",
            "83/110, train_loss: 0.0106\n",
            "84/110, train_loss: 0.0102\n",
            "85/110, train_loss: 0.0110\n",
            "86/110, train_loss: 0.0128\n",
            "87/110, train_loss: 0.0168\n",
            "88/110, train_loss: 0.0160\n",
            "89/110, train_loss: 0.0103\n",
            "90/110, train_loss: 0.0142\n",
            "91/110, train_loss: 0.0111\n",
            "92/110, train_loss: 0.0129\n",
            "93/110, train_loss: 0.0112\n",
            "94/110, train_loss: 0.0100\n",
            "95/110, train_loss: 0.0135\n",
            "96/110, train_loss: 0.0109\n",
            "97/110, train_loss: 0.0113\n",
            "98/110, train_loss: 0.0102\n",
            "99/110, train_loss: 0.0133\n",
            "100/110, train_loss: 0.0174\n",
            "101/110, train_loss: 0.0150\n",
            "102/110, train_loss: 0.0163\n",
            "103/110, train_loss: 0.0117\n",
            "104/110, train_loss: 0.0158\n",
            "105/110, train_loss: 0.0143\n",
            "106/110, train_loss: 0.0186\n",
            "107/110, train_loss: 0.0118\n",
            "108/110, train_loss: 0.0181\n",
            "109/110, train_loss: 0.0099\n",
            "110/110, train_loss: 0.0150\n",
            "epoch 73 average loss: 0.0148\n",
            "----------\n",
            "epoch 74/100\n",
            "1/110, train_loss: 0.0185\n",
            "2/110, train_loss: 0.0116\n",
            "3/110, train_loss: 0.0150\n",
            "4/110, train_loss: 0.0101\n",
            "5/110, train_loss: 0.0159\n",
            "6/110, train_loss: 0.0121\n",
            "7/110, train_loss: 0.0101\n",
            "8/110, train_loss: 0.0112\n",
            "9/110, train_loss: 0.0135\n",
            "10/110, train_loss: 0.0135\n",
            "11/110, train_loss: 0.0144\n",
            "12/110, train_loss: 0.0104\n",
            "13/110, train_loss: 0.0098\n",
            "14/110, train_loss: 0.0141\n",
            "15/110, train_loss: 0.0131\n",
            "16/110, train_loss: 0.0227\n",
            "17/110, train_loss: 0.0103\n",
            "18/110, train_loss: 0.0100\n",
            "19/110, train_loss: 0.0194\n",
            "20/110, train_loss: 0.0106\n",
            "21/110, train_loss: 0.0101\n",
            "22/110, train_loss: 0.0114\n",
            "23/110, train_loss: 0.0131\n",
            "24/110, train_loss: 0.0112\n",
            "25/110, train_loss: 0.0100\n",
            "26/110, train_loss: 0.0123\n",
            "27/110, train_loss: 0.0138\n",
            "28/110, train_loss: 0.0099\n",
            "29/110, train_loss: 0.0426\n",
            "30/110, train_loss: 0.0098\n",
            "31/110, train_loss: 0.0160\n",
            "32/110, train_loss: 0.0105\n",
            "33/110, train_loss: 0.0130\n",
            "34/110, train_loss: 0.0165\n",
            "35/110, train_loss: 0.0114\n",
            "36/110, train_loss: 0.0238\n",
            "37/110, train_loss: 0.0119\n",
            "38/110, train_loss: 0.0213\n",
            "39/110, train_loss: 0.0124\n",
            "40/110, train_loss: 0.0123\n",
            "41/110, train_loss: 0.0130\n",
            "42/110, train_loss: 0.0157\n",
            "43/110, train_loss: 0.0144\n",
            "44/110, train_loss: 0.0244\n",
            "45/110, train_loss: 0.0106\n",
            "46/110, train_loss: 0.0125\n",
            "47/110, train_loss: 0.0115\n",
            "48/110, train_loss: 0.0331\n",
            "49/110, train_loss: 0.0114\n",
            "50/110, train_loss: 0.0099\n",
            "51/110, train_loss: 0.0177\n",
            "52/110, train_loss: 0.0124\n",
            "53/110, train_loss: 0.0103\n",
            "54/110, train_loss: 0.0121\n",
            "55/110, train_loss: 0.0101\n",
            "56/110, train_loss: 0.0244\n",
            "57/110, train_loss: 0.0141\n",
            "58/110, train_loss: 0.0096\n",
            "59/110, train_loss: 0.0137\n",
            "60/110, train_loss: 0.0161\n",
            "61/110, train_loss: 0.0219\n",
            "62/110, train_loss: 0.0154\n",
            "63/110, train_loss: 0.0123\n",
            "64/110, train_loss: 0.0144\n",
            "65/110, train_loss: 0.0129\n",
            "66/110, train_loss: 0.0123\n",
            "67/110, train_loss: 0.0113\n",
            "68/110, train_loss: 0.0127\n",
            "69/110, train_loss: 0.0140\n",
            "70/110, train_loss: 0.0136\n",
            "71/110, train_loss: 0.0164\n",
            "72/110, train_loss: 0.0113\n",
            "73/110, train_loss: 0.0117\n",
            "74/110, train_loss: 0.0105\n",
            "75/110, train_loss: 0.0140\n",
            "76/110, train_loss: 0.0174\n",
            "77/110, train_loss: 0.0101\n",
            "78/110, train_loss: 0.0126\n",
            "79/110, train_loss: 0.0105\n",
            "80/110, train_loss: 0.0166\n",
            "81/110, train_loss: 0.0113\n",
            "82/110, train_loss: 0.0128\n",
            "83/110, train_loss: 0.0151\n",
            "84/110, train_loss: 0.0144\n",
            "85/110, train_loss: 0.0153\n",
            "86/110, train_loss: 0.0123\n",
            "87/110, train_loss: 0.0125\n",
            "88/110, train_loss: 0.0107\n",
            "89/110, train_loss: 0.0116\n",
            "90/110, train_loss: 0.0145\n",
            "91/110, train_loss: 0.0172\n",
            "92/110, train_loss: 0.0100\n",
            "93/110, train_loss: 0.0141\n",
            "94/110, train_loss: 0.0276\n",
            "95/110, train_loss: 0.0153\n",
            "96/110, train_loss: 0.0128\n",
            "97/110, train_loss: 0.0098\n",
            "98/110, train_loss: 0.0098\n",
            "99/110, train_loss: 0.0127\n",
            "100/110, train_loss: 0.0144\n",
            "101/110, train_loss: 0.0153\n",
            "102/110, train_loss: 0.0149\n",
            "103/110, train_loss: 0.0104\n",
            "104/110, train_loss: 0.0134\n",
            "105/110, train_loss: 0.0122\n",
            "106/110, train_loss: 0.0102\n",
            "107/110, train_loss: 0.0101\n",
            "108/110, train_loss: 0.0100\n",
            "109/110, train_loss: 0.0169\n",
            "110/110, train_loss: 0.0139\n",
            "epoch 74 average loss: 0.0139\n",
            "----------\n",
            "epoch 75/100\n",
            "1/110, train_loss: 0.0138\n",
            "2/110, train_loss: 0.0099\n",
            "3/110, train_loss: 0.0102\n",
            "4/110, train_loss: 0.0129\n",
            "5/110, train_loss: 0.0217\n",
            "6/110, train_loss: 0.0257\n",
            "7/110, train_loss: 0.0146\n",
            "8/110, train_loss: 0.0116\n",
            "9/110, train_loss: 0.0110\n",
            "10/110, train_loss: 0.0137\n",
            "11/110, train_loss: 0.0150\n",
            "12/110, train_loss: 0.0123\n",
            "13/110, train_loss: 0.0123\n",
            "14/110, train_loss: 0.0101\n",
            "15/110, train_loss: 0.0098\n",
            "16/110, train_loss: 0.0122\n",
            "17/110, train_loss: 0.0134\n",
            "18/110, train_loss: 0.0131\n",
            "19/110, train_loss: 0.0132\n",
            "20/110, train_loss: 0.0150\n",
            "21/110, train_loss: 0.0108\n",
            "22/110, train_loss: 0.0142\n",
            "23/110, train_loss: 0.0117\n",
            "24/110, train_loss: 0.0120\n",
            "25/110, train_loss: 0.0147\n",
            "26/110, train_loss: 0.0151\n",
            "27/110, train_loss: 0.0224\n",
            "28/110, train_loss: 0.0124\n",
            "29/110, train_loss: 0.0099\n",
            "30/110, train_loss: 0.0134\n",
            "31/110, train_loss: 0.0222\n",
            "32/110, train_loss: 0.0159\n",
            "33/110, train_loss: 0.0115\n",
            "34/110, train_loss: 0.0113\n",
            "35/110, train_loss: 0.0096\n",
            "36/110, train_loss: 0.0101\n",
            "37/110, train_loss: 0.0095\n",
            "38/110, train_loss: 0.0169\n",
            "39/110, train_loss: 0.0111\n",
            "40/110, train_loss: 0.0097\n",
            "41/110, train_loss: 0.0134\n",
            "42/110, train_loss: 0.0136\n",
            "43/110, train_loss: 0.0093\n",
            "44/110, train_loss: 0.0175\n",
            "45/110, train_loss: 0.0166\n",
            "46/110, train_loss: 0.0152\n",
            "47/110, train_loss: 0.0094\n",
            "48/110, train_loss: 0.0101\n",
            "49/110, train_loss: 0.0379\n",
            "50/110, train_loss: 0.0096\n",
            "51/110, train_loss: 0.0118\n",
            "52/110, train_loss: 0.0145\n",
            "53/110, train_loss: 0.0108\n",
            "54/110, train_loss: 0.0183\n",
            "55/110, train_loss: 0.0124\n",
            "56/110, train_loss: 0.0125\n",
            "57/110, train_loss: 0.0199\n",
            "58/110, train_loss: 0.0227\n",
            "59/110, train_loss: 0.0156\n",
            "60/110, train_loss: 0.0134\n",
            "61/110, train_loss: 0.0109\n",
            "62/110, train_loss: 0.0144\n",
            "63/110, train_loss: 0.0093\n",
            "64/110, train_loss: 0.0109\n",
            "65/110, train_loss: 0.0128\n",
            "66/110, train_loss: 0.0096\n",
            "67/110, train_loss: 0.0123\n",
            "68/110, train_loss: 0.0118\n",
            "69/110, train_loss: 0.0155\n",
            "70/110, train_loss: 0.0119\n",
            "71/110, train_loss: 0.0109\n",
            "72/110, train_loss: 0.0093\n",
            "73/110, train_loss: 0.0126\n",
            "74/110, train_loss: 0.0103\n",
            "75/110, train_loss: 0.0098\n",
            "76/110, train_loss: 0.0207\n",
            "77/110, train_loss: 0.0105\n",
            "78/110, train_loss: 0.0126\n",
            "79/110, train_loss: 0.0120\n",
            "80/110, train_loss: 0.0119\n",
            "81/110, train_loss: 0.0095\n",
            "82/110, train_loss: 0.0099\n",
            "83/110, train_loss: 0.0136\n",
            "84/110, train_loss: 0.0109\n",
            "85/110, train_loss: 0.0113\n",
            "86/110, train_loss: 0.0139\n",
            "87/110, train_loss: 0.0116\n",
            "88/110, train_loss: 0.0112\n",
            "89/110, train_loss: 0.0097\n",
            "90/110, train_loss: 0.0105\n",
            "91/110, train_loss: 0.0107\n",
            "92/110, train_loss: 0.0096\n",
            "93/110, train_loss: 0.0119\n",
            "94/110, train_loss: 0.0115\n",
            "95/110, train_loss: 0.0132\n",
            "96/110, train_loss: 0.0100\n",
            "97/110, train_loss: 0.0094\n",
            "98/110, train_loss: 0.0158\n",
            "99/110, train_loss: 0.0094\n",
            "100/110, train_loss: 0.0137\n",
            "101/110, train_loss: 0.0100\n",
            "102/110, train_loss: 0.0096\n",
            "103/110, train_loss: 0.0135\n",
            "104/110, train_loss: 0.0161\n",
            "105/110, train_loss: 0.0116\n",
            "106/110, train_loss: 0.0139\n",
            "107/110, train_loss: 0.0126\n",
            "108/110, train_loss: 0.0115\n",
            "109/110, train_loss: 0.0299\n",
            "110/110, train_loss: 0.0092\n",
            "epoch 75 average loss: 0.0131\n",
            "current epoch: 75 current accuracy: 0.7143 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 76/100\n",
            "1/110, train_loss: 0.0117\n",
            "2/110, train_loss: 0.0149\n",
            "3/110, train_loss: 0.0117\n",
            "4/110, train_loss: 0.0129\n",
            "5/110, train_loss: 0.0094\n",
            "6/110, train_loss: 0.0131\n",
            "7/110, train_loss: 0.0094\n",
            "8/110, train_loss: 0.0090\n",
            "9/110, train_loss: 0.0197\n",
            "10/110, train_loss: 0.0090\n",
            "11/110, train_loss: 0.0093\n",
            "12/110, train_loss: 0.0092\n",
            "13/110, train_loss: 0.0114\n",
            "14/110, train_loss: 0.0094\n",
            "15/110, train_loss: 0.0104\n",
            "16/110, train_loss: 0.0117\n",
            "17/110, train_loss: 0.0289\n",
            "18/110, train_loss: 0.0116\n",
            "19/110, train_loss: 0.0127\n",
            "20/110, train_loss: 0.0247\n",
            "21/110, train_loss: 0.0097\n",
            "22/110, train_loss: 0.0167\n",
            "23/110, train_loss: 0.0358\n",
            "24/110, train_loss: 0.0106\n",
            "25/110, train_loss: 0.0113\n",
            "26/110, train_loss: 0.0110\n",
            "27/110, train_loss: 0.0141\n",
            "28/110, train_loss: 0.0112\n",
            "29/110, train_loss: 0.0158\n",
            "30/110, train_loss: 0.0131\n",
            "31/110, train_loss: 0.0117\n",
            "32/110, train_loss: 0.0147\n",
            "33/110, train_loss: 0.0100\n",
            "34/110, train_loss: 0.0186\n",
            "35/110, train_loss: 0.0092\n",
            "36/110, train_loss: 0.0180\n",
            "37/110, train_loss: 0.0105\n",
            "38/110, train_loss: 0.0092\n",
            "39/110, train_loss: 0.0124\n",
            "40/110, train_loss: 0.0115\n",
            "41/110, train_loss: 0.0130\n",
            "42/110, train_loss: 0.0105\n",
            "43/110, train_loss: 0.0091\n",
            "44/110, train_loss: 0.0114\n",
            "45/110, train_loss: 0.0121\n",
            "46/110, train_loss: 0.0132\n",
            "47/110, train_loss: 0.0146\n",
            "48/110, train_loss: 0.0102\n",
            "49/110, train_loss: 0.0095\n",
            "50/110, train_loss: 0.0121\n",
            "51/110, train_loss: 0.0089\n",
            "52/110, train_loss: 0.0139\n",
            "53/110, train_loss: 0.0100\n",
            "54/110, train_loss: 0.0156\n",
            "55/110, train_loss: 0.0094\n",
            "56/110, train_loss: 0.0159\n",
            "57/110, train_loss: 0.0133\n",
            "58/110, train_loss: 0.0135\n",
            "59/110, train_loss: 0.0090\n",
            "60/110, train_loss: 0.0212\n",
            "61/110, train_loss: 0.0115\n",
            "62/110, train_loss: 0.0120\n",
            "63/110, train_loss: 0.0109\n",
            "64/110, train_loss: 0.0092\n",
            "65/110, train_loss: 0.0139\n",
            "66/110, train_loss: 0.0091\n",
            "67/110, train_loss: 0.0210\n",
            "68/110, train_loss: 0.0113\n",
            "69/110, train_loss: 0.0146\n",
            "70/110, train_loss: 0.0095\n",
            "71/110, train_loss: 0.0102\n",
            "72/110, train_loss: 0.0110\n",
            "73/110, train_loss: 0.0203\n",
            "74/110, train_loss: 0.0117\n",
            "75/110, train_loss: 0.0102\n",
            "76/110, train_loss: 0.0088\n",
            "77/110, train_loss: 0.0120\n",
            "78/110, train_loss: 0.0115\n",
            "79/110, train_loss: 0.0098\n",
            "80/110, train_loss: 0.0131\n",
            "81/110, train_loss: 0.0095\n",
            "82/110, train_loss: 0.0138\n",
            "83/110, train_loss: 0.0128\n",
            "84/110, train_loss: 0.0119\n",
            "85/110, train_loss: 0.0093\n",
            "86/110, train_loss: 0.0125\n",
            "87/110, train_loss: 0.0162\n",
            "88/110, train_loss: 0.0114\n",
            "89/110, train_loss: 0.0096\n",
            "90/110, train_loss: 0.0117\n",
            "91/110, train_loss: 0.0104\n",
            "92/110, train_loss: 0.0107\n",
            "93/110, train_loss: 0.0108\n",
            "94/110, train_loss: 0.0094\n",
            "95/110, train_loss: 0.0121\n",
            "96/110, train_loss: 0.0111\n",
            "97/110, train_loss: 0.0097\n",
            "98/110, train_loss: 0.0127\n",
            "99/110, train_loss: 0.0087\n",
            "100/110, train_loss: 0.0126\n",
            "101/110, train_loss: 0.0108\n",
            "102/110, train_loss: 0.0206\n",
            "103/110, train_loss: 0.0102\n",
            "104/110, train_loss: 0.0140\n",
            "105/110, train_loss: 0.0125\n",
            "106/110, train_loss: 0.0091\n",
            "107/110, train_loss: 0.0140\n",
            "108/110, train_loss: 0.0112\n",
            "109/110, train_loss: 0.0134\n",
            "110/110, train_loss: 0.0101\n",
            "epoch 76 average loss: 0.0125\n",
            "----------\n",
            "epoch 77/100\n",
            "1/110, train_loss: 0.0200\n",
            "2/110, train_loss: 0.0100\n",
            "3/110, train_loss: 0.0121\n",
            "4/110, train_loss: 0.0085\n",
            "5/110, train_loss: 0.0112\n",
            "6/110, train_loss: 0.0148\n",
            "7/110, train_loss: 0.0128\n",
            "8/110, train_loss: 0.0111\n",
            "9/110, train_loss: 0.0110\n",
            "10/110, train_loss: 0.0087\n",
            "11/110, train_loss: 0.0090\n",
            "12/110, train_loss: 0.0106\n",
            "13/110, train_loss: 0.0098\n",
            "14/110, train_loss: 0.0107\n",
            "15/110, train_loss: 0.0135\n",
            "16/110, train_loss: 0.0084\n",
            "17/110, train_loss: 0.0117\n",
            "18/110, train_loss: 0.0194\n",
            "19/110, train_loss: 0.0098\n",
            "20/110, train_loss: 0.0086\n",
            "21/110, train_loss: 0.0151\n",
            "22/110, train_loss: 0.0100\n",
            "23/110, train_loss: 0.0104\n",
            "24/110, train_loss: 0.0118\n",
            "25/110, train_loss: 0.0143\n",
            "26/110, train_loss: 0.0101\n",
            "27/110, train_loss: 0.0159\n",
            "28/110, train_loss: 0.0087\n",
            "29/110, train_loss: 0.0118\n",
            "30/110, train_loss: 0.0100\n",
            "31/110, train_loss: 0.0095\n",
            "32/110, train_loss: 0.0179\n",
            "33/110, train_loss: 0.0097\n",
            "34/110, train_loss: 0.0133\n",
            "35/110, train_loss: 0.0117\n",
            "36/110, train_loss: 0.0136\n",
            "37/110, train_loss: 0.0106\n",
            "38/110, train_loss: 0.0106\n",
            "39/110, train_loss: 0.0117\n",
            "40/110, train_loss: 0.0119\n",
            "41/110, train_loss: 0.0140\n",
            "42/110, train_loss: 0.0136\n",
            "43/110, train_loss: 0.0090\n",
            "44/110, train_loss: 0.0112\n",
            "45/110, train_loss: 0.0194\n",
            "46/110, train_loss: 0.0116\n",
            "47/110, train_loss: 0.0084\n",
            "48/110, train_loss: 0.0119\n",
            "49/110, train_loss: 0.0138\n",
            "50/110, train_loss: 0.0084\n",
            "51/110, train_loss: 0.0109\n",
            "52/110, train_loss: 0.0089\n",
            "53/110, train_loss: 0.0104\n",
            "54/110, train_loss: 0.0086\n",
            "55/110, train_loss: 0.0090\n",
            "56/110, train_loss: 0.0143\n",
            "57/110, train_loss: 0.0091\n",
            "58/110, train_loss: 0.0110\n",
            "59/110, train_loss: 0.0132\n",
            "60/110, train_loss: 0.0123\n",
            "61/110, train_loss: 0.0117\n",
            "62/110, train_loss: 0.0093\n",
            "63/110, train_loss: 0.0087\n",
            "64/110, train_loss: 0.0110\n",
            "65/110, train_loss: 0.0121\n",
            "66/110, train_loss: 0.0087\n",
            "67/110, train_loss: 0.0088\n",
            "68/110, train_loss: 0.0104\n",
            "69/110, train_loss: 0.0130\n",
            "70/110, train_loss: 0.0228\n",
            "71/110, train_loss: 0.0096\n",
            "72/110, train_loss: 0.0121\n",
            "73/110, train_loss: 0.0088\n",
            "74/110, train_loss: 0.0096\n",
            "75/110, train_loss: 0.0134\n",
            "76/110, train_loss: 0.0104\n",
            "77/110, train_loss: 0.0105\n",
            "78/110, train_loss: 0.0272\n",
            "79/110, train_loss: 0.0111\n",
            "80/110, train_loss: 0.0088\n",
            "81/110, train_loss: 0.0108\n",
            "82/110, train_loss: 0.0090\n",
            "83/110, train_loss: 0.0129\n",
            "84/110, train_loss: 0.0123\n",
            "85/110, train_loss: 0.0185\n",
            "86/110, train_loss: 0.0120\n",
            "87/110, train_loss: 0.0149\n",
            "88/110, train_loss: 0.0093\n",
            "89/110, train_loss: 0.0094\n",
            "90/110, train_loss: 0.0086\n",
            "91/110, train_loss: 0.0122\n",
            "92/110, train_loss: 0.0087\n",
            "93/110, train_loss: 0.0102\n",
            "94/110, train_loss: 0.0095\n",
            "95/110, train_loss: 0.0162\n",
            "96/110, train_loss: 0.0108\n",
            "97/110, train_loss: 0.0084\n",
            "98/110, train_loss: 0.0129\n",
            "99/110, train_loss: 0.0195\n",
            "100/110, train_loss: 0.0120\n",
            "101/110, train_loss: 0.0104\n",
            "102/110, train_loss: 0.0083\n",
            "103/110, train_loss: 0.0109\n",
            "104/110, train_loss: 0.0090\n",
            "105/110, train_loss: 0.0325\n",
            "106/110, train_loss: 0.0126\n",
            "107/110, train_loss: 0.0084\n",
            "108/110, train_loss: 0.0087\n",
            "109/110, train_loss: 0.0122\n",
            "110/110, train_loss: 0.0097\n",
            "epoch 77 average loss: 0.0118\n",
            "----------\n",
            "epoch 78/100\n",
            "1/110, train_loss: 0.0084\n",
            "2/110, train_loss: 0.0120\n",
            "3/110, train_loss: 0.0306\n",
            "4/110, train_loss: 0.0226\n",
            "5/110, train_loss: 0.0131\n",
            "6/110, train_loss: 0.0104\n",
            "7/110, train_loss: 0.0088\n",
            "8/110, train_loss: 0.0086\n",
            "9/110, train_loss: 0.0150\n",
            "10/110, train_loss: 0.0177\n",
            "11/110, train_loss: 0.0095\n",
            "12/110, train_loss: 0.0085\n",
            "13/110, train_loss: 0.0129\n",
            "14/110, train_loss: 0.0192\n",
            "15/110, train_loss: 0.0130\n",
            "16/110, train_loss: 0.0107\n",
            "17/110, train_loss: 0.0103\n",
            "18/110, train_loss: 0.0150\n",
            "19/110, train_loss: 0.0112\n",
            "20/110, train_loss: 0.0099\n",
            "21/110, train_loss: 0.0189\n",
            "22/110, train_loss: 0.0190\n",
            "23/110, train_loss: 0.0106\n",
            "24/110, train_loss: 0.0082\n",
            "25/110, train_loss: 0.0085\n",
            "26/110, train_loss: 0.0104\n",
            "27/110, train_loss: 0.0108\n",
            "28/110, train_loss: 0.0114\n",
            "29/110, train_loss: 0.0084\n",
            "30/110, train_loss: 0.0086\n",
            "31/110, train_loss: 0.0087\n",
            "32/110, train_loss: 0.0145\n",
            "33/110, train_loss: 0.0083\n",
            "34/110, train_loss: 0.0258\n",
            "35/110, train_loss: 0.0117\n",
            "36/110, train_loss: 0.0101\n",
            "37/110, train_loss: 0.0142\n",
            "38/110, train_loss: 0.0082\n",
            "39/110, train_loss: 0.0089\n",
            "40/110, train_loss: 0.0085\n",
            "41/110, train_loss: 0.0105\n",
            "42/110, train_loss: 0.0128\n",
            "43/110, train_loss: 0.0112\n",
            "44/110, train_loss: 0.0094\n",
            "45/110, train_loss: 0.0082\n",
            "46/110, train_loss: 0.0082\n",
            "47/110, train_loss: 0.0118\n",
            "48/110, train_loss: 0.0084\n",
            "49/110, train_loss: 0.0088\n",
            "50/110, train_loss: 0.0130\n",
            "51/110, train_loss: 0.0115\n",
            "52/110, train_loss: 0.0090\n",
            "53/110, train_loss: 0.0116\n",
            "54/110, train_loss: 0.0143\n",
            "55/110, train_loss: 0.0101\n",
            "56/110, train_loss: 0.0100\n",
            "57/110, train_loss: 0.0108\n",
            "58/110, train_loss: 0.0170\n",
            "59/110, train_loss: 0.0078\n",
            "60/110, train_loss: 0.0126\n",
            "61/110, train_loss: 0.0096\n",
            "62/110, train_loss: 0.0092\n",
            "63/110, train_loss: 0.0106\n",
            "64/110, train_loss: 0.0090\n",
            "65/110, train_loss: 0.0124\n",
            "66/110, train_loss: 0.0083\n",
            "67/110, train_loss: 0.0111\n",
            "68/110, train_loss: 0.0090\n",
            "69/110, train_loss: 0.0080\n",
            "70/110, train_loss: 0.0093\n",
            "71/110, train_loss: 0.0110\n",
            "72/110, train_loss: 0.0089\n",
            "73/110, train_loss: 0.0151\n",
            "74/110, train_loss: 0.0113\n",
            "75/110, train_loss: 0.0094\n",
            "76/110, train_loss: 0.0078\n",
            "77/110, train_loss: 0.0077\n",
            "78/110, train_loss: 0.0123\n",
            "79/110, train_loss: 0.0111\n",
            "80/110, train_loss: 0.0114\n",
            "81/110, train_loss: 0.0080\n",
            "82/110, train_loss: 0.0085\n",
            "83/110, train_loss: 0.0085\n",
            "84/110, train_loss: 0.0105\n",
            "85/110, train_loss: 0.0124\n",
            "86/110, train_loss: 0.0188\n",
            "87/110, train_loss: 0.0134\n",
            "88/110, train_loss: 0.0116\n",
            "89/110, train_loss: 0.0101\n",
            "90/110, train_loss: 0.0081\n",
            "91/110, train_loss: 0.0125\n",
            "92/110, train_loss: 0.0092\n",
            "93/110, train_loss: 0.0100\n",
            "94/110, train_loss: 0.0090\n",
            "95/110, train_loss: 0.0104\n",
            "96/110, train_loss: 0.0097\n",
            "97/110, train_loss: 0.0133\n",
            "98/110, train_loss: 0.0111\n",
            "99/110, train_loss: 0.0110\n",
            "100/110, train_loss: 0.0082\n",
            "101/110, train_loss: 0.0083\n",
            "102/110, train_loss: 0.0118\n",
            "103/110, train_loss: 0.0117\n",
            "104/110, train_loss: 0.0120\n",
            "105/110, train_loss: 0.0099\n",
            "106/110, train_loss: 0.0099\n",
            "107/110, train_loss: 0.0087\n",
            "108/110, train_loss: 0.0106\n",
            "109/110, train_loss: 0.0129\n",
            "110/110, train_loss: 0.0095\n",
            "epoch 78 average loss: 0.0113\n",
            "current epoch: 78 current accuracy: 0.7857 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 79/100\n",
            "1/110, train_loss: 0.0077\n",
            "2/110, train_loss: 0.0096\n",
            "3/110, train_loss: 0.0096\n",
            "4/110, train_loss: 0.0121\n",
            "5/110, train_loss: 0.0080\n",
            "6/110, train_loss: 0.0110\n",
            "7/110, train_loss: 0.0213\n",
            "8/110, train_loss: 0.0122\n",
            "9/110, train_loss: 0.0084\n",
            "10/110, train_loss: 0.0084\n",
            "11/110, train_loss: 0.0096\n",
            "12/110, train_loss: 0.0175\n",
            "13/110, train_loss: 0.0093\n",
            "14/110, train_loss: 0.0138\n",
            "15/110, train_loss: 0.0126\n",
            "16/110, train_loss: 0.0097\n",
            "17/110, train_loss: 0.0087\n",
            "18/110, train_loss: 0.0182\n",
            "19/110, train_loss: 0.0077\n",
            "20/110, train_loss: 0.0088\n",
            "21/110, train_loss: 0.0081\n",
            "22/110, train_loss: 0.0076\n",
            "23/110, train_loss: 0.0088\n",
            "24/110, train_loss: 0.0085\n",
            "25/110, train_loss: 0.0110\n",
            "26/110, train_loss: 0.0100\n",
            "27/110, train_loss: 0.0080\n",
            "28/110, train_loss: 0.0091\n",
            "29/110, train_loss: 0.0145\n",
            "30/110, train_loss: 0.0302\n",
            "31/110, train_loss: 0.0082\n",
            "32/110, train_loss: 0.0107\n",
            "33/110, train_loss: 0.0080\n",
            "34/110, train_loss: 0.0164\n",
            "35/110, train_loss: 0.0078\n",
            "36/110, train_loss: 0.0174\n",
            "37/110, train_loss: 0.0089\n",
            "38/110, train_loss: 0.0097\n",
            "39/110, train_loss: 0.0114\n",
            "40/110, train_loss: 0.0100\n",
            "41/110, train_loss: 0.0083\n",
            "42/110, train_loss: 0.0087\n",
            "43/110, train_loss: 0.0122\n",
            "44/110, train_loss: 0.0137\n",
            "45/110, train_loss: 0.0120\n",
            "46/110, train_loss: 0.0117\n",
            "47/110, train_loss: 0.0080\n",
            "48/110, train_loss: 0.0135\n",
            "49/110, train_loss: 0.0100\n",
            "50/110, train_loss: 0.0110\n",
            "51/110, train_loss: 0.0121\n",
            "52/110, train_loss: 0.0127\n",
            "53/110, train_loss: 0.0115\n",
            "54/110, train_loss: 0.0076\n",
            "55/110, train_loss: 0.0076\n",
            "56/110, train_loss: 0.0240\n",
            "57/110, train_loss: 0.0104\n",
            "58/110, train_loss: 0.0088\n",
            "59/110, train_loss: 0.0079\n",
            "60/110, train_loss: 0.0081\n",
            "61/110, train_loss: 0.0172\n",
            "62/110, train_loss: 0.0146\n",
            "63/110, train_loss: 0.0085\n",
            "64/110, train_loss: 0.0175\n",
            "65/110, train_loss: 0.0109\n",
            "66/110, train_loss: 0.0097\n",
            "67/110, train_loss: 0.0114\n",
            "68/110, train_loss: 0.0084\n",
            "69/110, train_loss: 0.0098\n",
            "70/110, train_loss: 0.0096\n",
            "71/110, train_loss: 0.0101\n",
            "72/110, train_loss: 0.0076\n",
            "73/110, train_loss: 0.0087\n",
            "74/110, train_loss: 0.0103\n",
            "75/110, train_loss: 0.0073\n",
            "76/110, train_loss: 0.0102\n",
            "77/110, train_loss: 0.0119\n",
            "78/110, train_loss: 0.0090\n",
            "79/110, train_loss: 0.0085\n",
            "80/110, train_loss: 0.0103\n",
            "81/110, train_loss: 0.0098\n",
            "82/110, train_loss: 0.0077\n",
            "83/110, train_loss: 0.0109\n",
            "84/110, train_loss: 0.0074\n",
            "85/110, train_loss: 0.0077\n",
            "86/110, train_loss: 0.0093\n",
            "87/110, train_loss: 0.0112\n",
            "88/110, train_loss: 0.0121\n",
            "89/110, train_loss: 0.0120\n",
            "90/110, train_loss: 0.0103\n",
            "91/110, train_loss: 0.0075\n",
            "92/110, train_loss: 0.0076\n",
            "93/110, train_loss: 0.0105\n",
            "94/110, train_loss: 0.0106\n",
            "95/110, train_loss: 0.0097\n",
            "96/110, train_loss: 0.0124\n",
            "97/110, train_loss: 0.0126\n",
            "98/110, train_loss: 0.0073\n",
            "99/110, train_loss: 0.0105\n",
            "100/110, train_loss: 0.0087\n",
            "101/110, train_loss: 0.0109\n",
            "102/110, train_loss: 0.0078\n",
            "103/110, train_loss: 0.0106\n",
            "104/110, train_loss: 0.0110\n",
            "105/110, train_loss: 0.0093\n",
            "106/110, train_loss: 0.0126\n",
            "107/110, train_loss: 0.0111\n",
            "108/110, train_loss: 0.0075\n",
            "109/110, train_loss: 0.0103\n",
            "110/110, train_loss: 0.0130\n",
            "epoch 79 average loss: 0.0107\n",
            "----------\n",
            "epoch 80/100\n",
            "1/110, train_loss: 0.0076\n",
            "2/110, train_loss: 0.0117\n",
            "3/110, train_loss: 0.0075\n",
            "4/110, train_loss: 0.0072\n",
            "5/110, train_loss: 0.0076\n",
            "6/110, train_loss: 0.0073\n",
            "7/110, train_loss: 0.0096\n",
            "8/110, train_loss: 0.0114\n",
            "9/110, train_loss: 0.0084\n",
            "10/110, train_loss: 0.0074\n",
            "11/110, train_loss: 0.0117\n",
            "12/110, train_loss: 0.0098\n",
            "13/110, train_loss: 0.0124\n",
            "14/110, train_loss: 0.0089\n",
            "15/110, train_loss: 0.0104\n",
            "16/110, train_loss: 0.0083\n",
            "17/110, train_loss: 0.0092\n",
            "18/110, train_loss: 0.0099\n",
            "19/110, train_loss: 0.0077\n",
            "20/110, train_loss: 0.0072\n",
            "21/110, train_loss: 0.0110\n",
            "22/110, train_loss: 0.0078\n",
            "23/110, train_loss: 0.0075\n",
            "24/110, train_loss: 0.0128\n",
            "25/110, train_loss: 0.0077\n",
            "26/110, train_loss: 0.0084\n",
            "27/110, train_loss: 0.0094\n",
            "28/110, train_loss: 0.0090\n",
            "29/110, train_loss: 0.0095\n",
            "30/110, train_loss: 0.0094\n",
            "31/110, train_loss: 0.0102\n",
            "32/110, train_loss: 0.0106\n",
            "33/110, train_loss: 0.0092\n",
            "34/110, train_loss: 0.0104\n",
            "35/110, train_loss: 0.0073\n",
            "36/110, train_loss: 0.0101\n",
            "37/110, train_loss: 0.0107\n",
            "38/110, train_loss: 0.0152\n",
            "39/110, train_loss: 0.0104\n",
            "40/110, train_loss: 0.0096\n",
            "41/110, train_loss: 0.0091\n",
            "42/110, train_loss: 0.0082\n",
            "43/110, train_loss: 0.0076\n",
            "44/110, train_loss: 0.0099\n",
            "45/110, train_loss: 0.0121\n",
            "46/110, train_loss: 0.0071\n",
            "47/110, train_loss: 0.0104\n",
            "48/110, train_loss: 0.0169\n",
            "49/110, train_loss: 0.0077\n",
            "50/110, train_loss: 0.0083\n",
            "51/110, train_loss: 0.0100\n",
            "52/110, train_loss: 0.0077\n",
            "53/110, train_loss: 0.0088\n",
            "54/110, train_loss: 0.0117\n",
            "55/110, train_loss: 0.0078\n",
            "56/110, train_loss: 0.0074\n",
            "57/110, train_loss: 0.0081\n",
            "58/110, train_loss: 0.0086\n",
            "59/110, train_loss: 0.0082\n",
            "60/110, train_loss: 0.0101\n",
            "61/110, train_loss: 0.0110\n",
            "62/110, train_loss: 0.0102\n",
            "63/110, train_loss: 0.0106\n",
            "64/110, train_loss: 0.0137\n",
            "65/110, train_loss: 0.0226\n",
            "66/110, train_loss: 0.0126\n",
            "67/110, train_loss: 0.0163\n",
            "68/110, train_loss: 0.0171\n",
            "69/110, train_loss: 0.0176\n",
            "70/110, train_loss: 0.0116\n",
            "71/110, train_loss: 0.0104\n",
            "72/110, train_loss: 0.0083\n",
            "73/110, train_loss: 0.0093\n",
            "74/110, train_loss: 0.0121\n",
            "75/110, train_loss: 0.0074\n",
            "76/110, train_loss: 0.0160\n",
            "77/110, train_loss: 0.0106\n",
            "78/110, train_loss: 0.0091\n",
            "79/110, train_loss: 0.0112\n",
            "80/110, train_loss: 0.0201\n",
            "81/110, train_loss: 0.0129\n",
            "82/110, train_loss: 0.0077\n",
            "83/110, train_loss: 0.0091\n",
            "84/110, train_loss: 0.0080\n",
            "85/110, train_loss: 0.0100\n",
            "86/110, train_loss: 0.0114\n",
            "87/110, train_loss: 0.0114\n",
            "88/110, train_loss: 0.0134\n",
            "89/110, train_loss: 0.0095\n",
            "90/110, train_loss: 0.0094\n",
            "91/110, train_loss: 0.0079\n",
            "92/110, train_loss: 0.0109\n",
            "93/110, train_loss: 0.0090\n",
            "94/110, train_loss: 0.0089\n",
            "95/110, train_loss: 0.0092\n",
            "96/110, train_loss: 0.0286\n",
            "97/110, train_loss: 0.0089\n",
            "98/110, train_loss: 0.0075\n",
            "99/110, train_loss: 0.0074\n",
            "100/110, train_loss: 0.0074\n",
            "101/110, train_loss: 0.0081\n",
            "102/110, train_loss: 0.0105\n",
            "103/110, train_loss: 0.0119\n",
            "104/110, train_loss: 0.0096\n",
            "105/110, train_loss: 0.0087\n",
            "106/110, train_loss: 0.0077\n",
            "107/110, train_loss: 0.0076\n",
            "108/110, train_loss: 0.0092\n",
            "109/110, train_loss: 0.0085\n",
            "110/110, train_loss: 0.0082\n",
            "epoch 80 average loss: 0.0102\n",
            "----------\n",
            "epoch 81/100\n",
            "1/110, train_loss: 0.0079\n",
            "2/110, train_loss: 0.0071\n",
            "3/110, train_loss: 0.0112\n",
            "4/110, train_loss: 0.0116\n",
            "5/110, train_loss: 0.0107\n",
            "6/110, train_loss: 0.0103\n",
            "7/110, train_loss: 0.0077\n",
            "8/110, train_loss: 0.0070\n",
            "9/110, train_loss: 0.0151\n",
            "10/110, train_loss: 0.0090\n",
            "11/110, train_loss: 0.0075\n",
            "12/110, train_loss: 0.0072\n",
            "13/110, train_loss: 0.0077\n",
            "14/110, train_loss: 0.0128\n",
            "15/110, train_loss: 0.0084\n",
            "16/110, train_loss: 0.0088\n",
            "17/110, train_loss: 0.0097\n",
            "18/110, train_loss: 0.0096\n",
            "19/110, train_loss: 0.0087\n",
            "20/110, train_loss: 0.0081\n",
            "21/110, train_loss: 0.0114\n",
            "22/110, train_loss: 0.0116\n",
            "23/110, train_loss: 0.0096\n",
            "24/110, train_loss: 0.0071\n",
            "25/110, train_loss: 0.0074\n",
            "26/110, train_loss: 0.0077\n",
            "27/110, train_loss: 0.0120\n",
            "28/110, train_loss: 0.0087\n",
            "29/110, train_loss: 0.0126\n",
            "30/110, train_loss: 0.0081\n",
            "31/110, train_loss: 0.0088\n",
            "32/110, train_loss: 0.0081\n",
            "33/110, train_loss: 0.0085\n",
            "34/110, train_loss: 0.0101\n",
            "35/110, train_loss: 0.0156\n",
            "36/110, train_loss: 0.0088\n",
            "37/110, train_loss: 0.0088\n",
            "38/110, train_loss: 0.0099\n",
            "39/110, train_loss: 0.0099\n",
            "40/110, train_loss: 0.0110\n",
            "41/110, train_loss: 0.0091\n",
            "42/110, train_loss: 0.0077\n",
            "43/110, train_loss: 0.0114\n",
            "44/110, train_loss: 0.0100\n",
            "45/110, train_loss: 0.0192\n",
            "46/110, train_loss: 0.0091\n",
            "47/110, train_loss: 0.0082\n",
            "48/110, train_loss: 0.0072\n",
            "49/110, train_loss: 0.0074\n",
            "50/110, train_loss: 0.0111\n",
            "51/110, train_loss: 0.0158\n",
            "52/110, train_loss: 0.0094\n",
            "53/110, train_loss: 0.0072\n",
            "54/110, train_loss: 0.0073\n",
            "55/110, train_loss: 0.0081\n",
            "56/110, train_loss: 0.0107\n",
            "57/110, train_loss: 0.0072\n",
            "58/110, train_loss: 0.0159\n",
            "59/110, train_loss: 0.0094\n",
            "60/110, train_loss: 0.0095\n",
            "61/110, train_loss: 0.0132\n",
            "62/110, train_loss: 0.0125\n",
            "63/110, train_loss: 0.0078\n",
            "64/110, train_loss: 0.0098\n",
            "65/110, train_loss: 0.0072\n",
            "66/110, train_loss: 0.0102\n",
            "67/110, train_loss: 0.0096\n",
            "68/110, train_loss: 0.0088\n",
            "69/110, train_loss: 0.0118\n",
            "70/110, train_loss: 0.0089\n",
            "71/110, train_loss: 0.0160\n",
            "72/110, train_loss: 0.0107\n",
            "73/110, train_loss: 0.0087\n",
            "74/110, train_loss: 0.0069\n",
            "75/110, train_loss: 0.0077\n",
            "76/110, train_loss: 0.0096\n",
            "77/110, train_loss: 0.0084\n",
            "78/110, train_loss: 0.0083\n",
            "79/110, train_loss: 0.0088\n",
            "80/110, train_loss: 0.0070\n",
            "81/110, train_loss: 0.0090\n",
            "82/110, train_loss: 0.0080\n",
            "83/110, train_loss: 0.0099\n",
            "84/110, train_loss: 0.0098\n",
            "85/110, train_loss: 0.0070\n",
            "86/110, train_loss: 0.0097\n",
            "87/110, train_loss: 0.0069\n",
            "88/110, train_loss: 0.0072\n",
            "89/110, train_loss: 0.0301\n",
            "90/110, train_loss: 0.0078\n",
            "91/110, train_loss: 0.0071\n",
            "92/110, train_loss: 0.0069\n",
            "93/110, train_loss: 0.0085\n",
            "94/110, train_loss: 0.0085\n",
            "95/110, train_loss: 0.0111\n",
            "96/110, train_loss: 0.0073\n",
            "97/110, train_loss: 0.0072\n",
            "98/110, train_loss: 0.0093\n",
            "99/110, train_loss: 0.0091\n",
            "100/110, train_loss: 0.0091\n",
            "101/110, train_loss: 0.0145\n",
            "102/110, train_loss: 0.0080\n",
            "103/110, train_loss: 0.0106\n",
            "104/110, train_loss: 0.0103\n",
            "105/110, train_loss: 0.0092\n",
            "106/110, train_loss: 0.0091\n",
            "107/110, train_loss: 0.0074\n",
            "108/110, train_loss: 0.0099\n",
            "109/110, train_loss: 0.0069\n",
            "110/110, train_loss: 0.0219\n",
            "epoch 81 average loss: 0.0097\n",
            "current epoch: 81 current accuracy: 0.7143 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 82/100\n",
            "1/110, train_loss: 0.0095\n",
            "2/110, train_loss: 0.0086\n",
            "3/110, train_loss: 0.0067\n",
            "4/110, train_loss: 0.0078\n",
            "5/110, train_loss: 0.0067\n",
            "6/110, train_loss: 0.0101\n",
            "7/110, train_loss: 0.0085\n",
            "8/110, train_loss: 0.0070\n",
            "9/110, train_loss: 0.0096\n",
            "10/110, train_loss: 0.0154\n",
            "11/110, train_loss: 0.0077\n",
            "12/110, train_loss: 0.0081\n",
            "13/110, train_loss: 0.0075\n",
            "14/110, train_loss: 0.0093\n",
            "15/110, train_loss: 0.0074\n",
            "16/110, train_loss: 0.0119\n",
            "17/110, train_loss: 0.0071\n",
            "18/110, train_loss: 0.0102\n",
            "19/110, train_loss: 0.0106\n",
            "20/110, train_loss: 0.0113\n",
            "21/110, train_loss: 0.0164\n",
            "22/110, train_loss: 0.0076\n",
            "23/110, train_loss: 0.0086\n",
            "24/110, train_loss: 0.0085\n",
            "25/110, train_loss: 0.0082\n",
            "26/110, train_loss: 0.0085\n",
            "27/110, train_loss: 0.0155\n",
            "28/110, train_loss: 0.0109\n",
            "29/110, train_loss: 0.0345\n",
            "30/110, train_loss: 0.0071\n",
            "31/110, train_loss: 0.0073\n",
            "32/110, train_loss: 0.0073\n",
            "33/110, train_loss: 0.0102\n",
            "34/110, train_loss: 0.0078\n",
            "35/110, train_loss: 0.0114\n",
            "36/110, train_loss: 0.0192\n",
            "37/110, train_loss: 0.0086\n",
            "38/110, train_loss: 0.0122\n",
            "39/110, train_loss: 0.0071\n",
            "40/110, train_loss: 0.0066\n",
            "41/110, train_loss: 0.0106\n",
            "42/110, train_loss: 0.0109\n",
            "43/110, train_loss: 0.0087\n",
            "44/110, train_loss: 0.0087\n",
            "45/110, train_loss: 0.0089\n",
            "46/110, train_loss: 0.0106\n",
            "47/110, train_loss: 0.0107\n",
            "48/110, train_loss: 0.0097\n",
            "49/110, train_loss: 0.0090\n",
            "50/110, train_loss: 0.0084\n",
            "51/110, train_loss: 0.0095\n",
            "52/110, train_loss: 0.0092\n",
            "53/110, train_loss: 0.0069\n",
            "54/110, train_loss: 0.0116\n",
            "55/110, train_loss: 0.0068\n",
            "56/110, train_loss: 0.0083\n",
            "57/110, train_loss: 0.0082\n",
            "58/110, train_loss: 0.0094\n",
            "59/110, train_loss: 0.0067\n",
            "60/110, train_loss: 0.0068\n",
            "61/110, train_loss: 0.0066\n",
            "62/110, train_loss: 0.0067\n",
            "63/110, train_loss: 0.0104\n",
            "64/110, train_loss: 0.0086\n",
            "65/110, train_loss: 0.0095\n",
            "66/110, train_loss: 0.0121\n",
            "67/110, train_loss: 0.0108\n",
            "68/110, train_loss: 0.0090\n",
            "69/110, train_loss: 0.0070\n",
            "70/110, train_loss: 0.0069\n",
            "71/110, train_loss: 0.0090\n",
            "72/110, train_loss: 0.0082\n",
            "73/110, train_loss: 0.0070\n",
            "74/110, train_loss: 0.0086\n",
            "75/110, train_loss: 0.0094\n",
            "76/110, train_loss: 0.0139\n",
            "77/110, train_loss: 0.0083\n",
            "78/110, train_loss: 0.0072\n",
            "79/110, train_loss: 0.0087\n",
            "80/110, train_loss: 0.0079\n",
            "81/110, train_loss: 0.0131\n",
            "82/110, train_loss: 0.0067\n",
            "83/110, train_loss: 0.0091\n",
            "84/110, train_loss: 0.0108\n",
            "85/110, train_loss: 0.0088\n",
            "86/110, train_loss: 0.0076\n",
            "87/110, train_loss: 0.0086\n",
            "88/110, train_loss: 0.0211\n",
            "89/110, train_loss: 0.0069\n",
            "90/110, train_loss: 0.0082\n",
            "91/110, train_loss: 0.0070\n",
            "92/110, train_loss: 0.0077\n",
            "93/110, train_loss: 0.0075\n",
            "94/110, train_loss: 0.0068\n",
            "95/110, train_loss: 0.0070\n",
            "96/110, train_loss: 0.0073\n",
            "97/110, train_loss: 0.0084\n",
            "98/110, train_loss: 0.0071\n",
            "99/110, train_loss: 0.0085\n",
            "100/110, train_loss: 0.0069\n",
            "101/110, train_loss: 0.0105\n",
            "102/110, train_loss: 0.0094\n",
            "103/110, train_loss: 0.0132\n",
            "104/110, train_loss: 0.0107\n",
            "105/110, train_loss: 0.0087\n",
            "106/110, train_loss: 0.0068\n",
            "107/110, train_loss: 0.0075\n",
            "108/110, train_loss: 0.0092\n",
            "109/110, train_loss: 0.0082\n",
            "110/110, train_loss: 0.0152\n",
            "epoch 82 average loss: 0.0094\n",
            "----------\n",
            "epoch 83/100\n",
            "1/110, train_loss: 0.0065\n",
            "2/110, train_loss: 0.0096\n",
            "3/110, train_loss: 0.0070\n",
            "4/110, train_loss: 0.0141\n",
            "5/110, train_loss: 0.0079\n",
            "6/110, train_loss: 0.0083\n",
            "7/110, train_loss: 0.0091\n",
            "8/110, train_loss: 0.0197\n",
            "9/110, train_loss: 0.0329\n",
            "10/110, train_loss: 0.0080\n",
            "11/110, train_loss: 0.0084\n",
            "12/110, train_loss: 0.0064\n",
            "13/110, train_loss: 0.0073\n",
            "14/110, train_loss: 0.0067\n",
            "15/110, train_loss: 0.0103\n",
            "16/110, train_loss: 0.0109\n",
            "17/110, train_loss: 0.0130\n",
            "18/110, train_loss: 0.0067\n",
            "19/110, train_loss: 0.0070\n",
            "20/110, train_loss: 0.0064\n",
            "21/110, train_loss: 0.0066\n",
            "22/110, train_loss: 0.0111\n",
            "23/110, train_loss: 0.0069\n",
            "24/110, train_loss: 0.0076\n",
            "25/110, train_loss: 0.0089\n",
            "26/110, train_loss: 0.0103\n",
            "27/110, train_loss: 0.0074\n",
            "28/110, train_loss: 0.0092\n",
            "29/110, train_loss: 0.0092\n",
            "30/110, train_loss: 0.0088\n",
            "31/110, train_loss: 0.0099\n",
            "32/110, train_loss: 0.0093\n",
            "33/110, train_loss: 0.0103\n",
            "34/110, train_loss: 0.0087\n",
            "35/110, train_loss: 0.0099\n",
            "36/110, train_loss: 0.0094\n",
            "37/110, train_loss: 0.0064\n",
            "38/110, train_loss: 0.0067\n",
            "39/110, train_loss: 0.0089\n",
            "40/110, train_loss: 0.0067\n",
            "41/110, train_loss: 0.0105\n",
            "42/110, train_loss: 0.0084\n",
            "43/110, train_loss: 0.0064\n",
            "44/110, train_loss: 0.0082\n",
            "45/110, train_loss: 0.0081\n",
            "46/110, train_loss: 0.0085\n",
            "47/110, train_loss: 0.0068\n",
            "48/110, train_loss: 0.0074\n",
            "49/110, train_loss: 0.0072\n",
            "50/110, train_loss: 0.0070\n",
            "51/110, train_loss: 0.0077\n",
            "52/110, train_loss: 0.0082\n",
            "53/110, train_loss: 0.0115\n",
            "54/110, train_loss: 0.0115\n",
            "55/110, train_loss: 0.0090\n",
            "56/110, train_loss: 0.0078\n",
            "57/110, train_loss: 0.0075\n",
            "58/110, train_loss: 0.0082\n",
            "59/110, train_loss: 0.0080\n",
            "60/110, train_loss: 0.0090\n",
            "61/110, train_loss: 0.0132\n",
            "62/110, train_loss: 0.0072\n",
            "63/110, train_loss: 0.0080\n",
            "64/110, train_loss: 0.0067\n",
            "65/110, train_loss: 0.0076\n",
            "66/110, train_loss: 0.0067\n",
            "67/110, train_loss: 0.0067\n",
            "68/110, train_loss: 0.0090\n",
            "69/110, train_loss: 0.0142\n",
            "70/110, train_loss: 0.0101\n",
            "71/110, train_loss: 0.0072\n",
            "72/110, train_loss: 0.0079\n",
            "73/110, train_loss: 0.0081\n",
            "74/110, train_loss: 0.0073\n",
            "75/110, train_loss: 0.0074\n",
            "76/110, train_loss: 0.0104\n",
            "77/110, train_loss: 0.0085\n",
            "78/110, train_loss: 0.0065\n",
            "79/110, train_loss: 0.0145\n",
            "80/110, train_loss: 0.0087\n",
            "81/110, train_loss: 0.0077\n",
            "82/110, train_loss: 0.0120\n",
            "83/110, train_loss: 0.0065\n",
            "84/110, train_loss: 0.0079\n",
            "85/110, train_loss: 0.0171\n",
            "86/110, train_loss: 0.0063\n",
            "87/110, train_loss: 0.0089\n",
            "88/110, train_loss: 0.0067\n",
            "89/110, train_loss: 0.0089\n",
            "90/110, train_loss: 0.0065\n",
            "91/110, train_loss: 0.0069\n",
            "92/110, train_loss: 0.0097\n",
            "93/110, train_loss: 0.0075\n",
            "94/110, train_loss: 0.0062\n",
            "95/110, train_loss: 0.0110\n",
            "96/110, train_loss: 0.0075\n",
            "97/110, train_loss: 0.0062\n",
            "98/110, train_loss: 0.0092\n",
            "99/110, train_loss: 0.0079\n",
            "100/110, train_loss: 0.0080\n",
            "101/110, train_loss: 0.0093\n",
            "102/110, train_loss: 0.0064\n",
            "103/110, train_loss: 0.0077\n",
            "104/110, train_loss: 0.0084\n",
            "105/110, train_loss: 0.0140\n",
            "106/110, train_loss: 0.0062\n",
            "107/110, train_loss: 0.0087\n",
            "108/110, train_loss: 0.0098\n",
            "109/110, train_loss: 0.0077\n",
            "110/110, train_loss: 0.0071\n",
            "epoch 83 average loss: 0.0089\n",
            "----------\n",
            "epoch 84/100\n",
            "1/110, train_loss: 0.0087\n",
            "2/110, train_loss: 0.0078\n",
            "3/110, train_loss: 0.0067\n",
            "4/110, train_loss: 0.0085\n",
            "5/110, train_loss: 0.0085\n",
            "6/110, train_loss: 0.0068\n",
            "7/110, train_loss: 0.0082\n",
            "8/110, train_loss: 0.0069\n",
            "9/110, train_loss: 0.0089\n",
            "10/110, train_loss: 0.0102\n",
            "11/110, train_loss: 0.0061\n",
            "12/110, train_loss: 0.0062\n",
            "13/110, train_loss: 0.0085\n",
            "14/110, train_loss: 0.0104\n",
            "15/110, train_loss: 0.0165\n",
            "16/110, train_loss: 0.0083\n",
            "17/110, train_loss: 0.0073\n",
            "18/110, train_loss: 0.0084\n",
            "19/110, train_loss: 0.0067\n",
            "20/110, train_loss: 0.0263\n",
            "21/110, train_loss: 0.0083\n",
            "22/110, train_loss: 0.0098\n",
            "23/110, train_loss: 0.0069\n",
            "24/110, train_loss: 0.0094\n",
            "25/110, train_loss: 0.0081\n",
            "26/110, train_loss: 0.0065\n",
            "27/110, train_loss: 0.0067\n",
            "28/110, train_loss: 0.0065\n",
            "29/110, train_loss: 0.0072\n",
            "30/110, train_loss: 0.0080\n",
            "31/110, train_loss: 0.0142\n",
            "32/110, train_loss: 0.0065\n",
            "33/110, train_loss: 0.0064\n",
            "34/110, train_loss: 0.0140\n",
            "35/110, train_loss: 0.0061\n",
            "36/110, train_loss: 0.0099\n",
            "37/110, train_loss: 0.0077\n",
            "38/110, train_loss: 0.0083\n",
            "39/110, train_loss: 0.0086\n",
            "40/110, train_loss: 0.0121\n",
            "41/110, train_loss: 0.0066\n",
            "42/110, train_loss: 0.0076\n",
            "43/110, train_loss: 0.0082\n",
            "44/110, train_loss: 0.0061\n",
            "45/110, train_loss: 0.0064\n",
            "46/110, train_loss: 0.0070\n",
            "47/110, train_loss: 0.0115\n",
            "48/110, train_loss: 0.0078\n",
            "49/110, train_loss: 0.0126\n",
            "50/110, train_loss: 0.0079\n",
            "51/110, train_loss: 0.0070\n",
            "52/110, train_loss: 0.0062\n",
            "53/110, train_loss: 0.0074\n",
            "54/110, train_loss: 0.0074\n",
            "55/110, train_loss: 0.0085\n",
            "56/110, train_loss: 0.0072\n",
            "57/110, train_loss: 0.0077\n",
            "58/110, train_loss: 0.0062\n",
            "59/110, train_loss: 0.0059\n",
            "60/110, train_loss: 0.0078\n",
            "61/110, train_loss: 0.0074\n",
            "62/110, train_loss: 0.0135\n",
            "63/110, train_loss: 0.0092\n",
            "64/110, train_loss: 0.0101\n",
            "65/110, train_loss: 0.0077\n",
            "66/110, train_loss: 0.0082\n",
            "67/110, train_loss: 0.0062\n",
            "68/110, train_loss: 0.0090\n",
            "69/110, train_loss: 0.0094\n",
            "70/110, train_loss: 0.0085\n",
            "71/110, train_loss: 0.0182\n",
            "72/110, train_loss: 0.0062\n",
            "73/110, train_loss: 0.0067\n",
            "74/110, train_loss: 0.0069\n",
            "75/110, train_loss: 0.0071\n",
            "76/110, train_loss: 0.0092\n",
            "77/110, train_loss: 0.0068\n",
            "78/110, train_loss: 0.0089\n",
            "79/110, train_loss: 0.0074\n",
            "80/110, train_loss: 0.0088\n",
            "81/110, train_loss: 0.0059\n",
            "82/110, train_loss: 0.0086\n",
            "83/110, train_loss: 0.0060\n",
            "84/110, train_loss: 0.0134\n",
            "85/110, train_loss: 0.0063\n",
            "86/110, train_loss: 0.0074\n",
            "87/110, train_loss: 0.0065\n",
            "88/110, train_loss: 0.0075\n",
            "89/110, train_loss: 0.0095\n",
            "90/110, train_loss: 0.0074\n",
            "91/110, train_loss: 0.0076\n",
            "92/110, train_loss: 0.0072\n",
            "93/110, train_loss: 0.0107\n",
            "94/110, train_loss: 0.0061\n",
            "95/110, train_loss: 0.0092\n",
            "96/110, train_loss: 0.0092\n",
            "97/110, train_loss: 0.0077\n",
            "98/110, train_loss: 0.0059\n",
            "99/110, train_loss: 0.0061\n",
            "100/110, train_loss: 0.0059\n",
            "101/110, train_loss: 0.0074\n",
            "102/110, train_loss: 0.0061\n",
            "103/110, train_loss: 0.0080\n",
            "104/110, train_loss: 0.0058\n",
            "105/110, train_loss: 0.0092\n",
            "106/110, train_loss: 0.0108\n",
            "107/110, train_loss: 0.0086\n",
            "108/110, train_loss: 0.0084\n",
            "109/110, train_loss: 0.0057\n",
            "110/110, train_loss: 0.0068\n",
            "epoch 84 average loss: 0.0083\n",
            "current epoch: 84 current accuracy: 0.7857 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 85/100\n",
            "1/110, train_loss: 0.0078\n",
            "2/110, train_loss: 0.0128\n",
            "3/110, train_loss: 0.0062\n",
            "4/110, train_loss: 0.0071\n",
            "5/110, train_loss: 0.0066\n",
            "6/110, train_loss: 0.0104\n",
            "7/110, train_loss: 0.0102\n",
            "8/110, train_loss: 0.0089\n",
            "9/110, train_loss: 0.0058\n",
            "10/110, train_loss: 0.0070\n",
            "11/110, train_loss: 0.0059\n",
            "12/110, train_loss: 0.0097\n",
            "13/110, train_loss: 0.0060\n",
            "14/110, train_loss: 0.0082\n",
            "15/110, train_loss: 0.0059\n",
            "16/110, train_loss: 0.0079\n",
            "17/110, train_loss: 0.0081\n",
            "18/110, train_loss: 0.0131\n",
            "19/110, train_loss: 0.0082\n",
            "20/110, train_loss: 0.0085\n",
            "21/110, train_loss: 0.0060\n",
            "22/110, train_loss: 0.0092\n",
            "23/110, train_loss: 0.0060\n",
            "24/110, train_loss: 0.0064\n",
            "25/110, train_loss: 0.0066\n",
            "26/110, train_loss: 0.0058\n",
            "27/110, train_loss: 0.0071\n",
            "28/110, train_loss: 0.0071\n",
            "29/110, train_loss: 0.0080\n",
            "30/110, train_loss: 0.0072\n",
            "31/110, train_loss: 0.0074\n",
            "32/110, train_loss: 0.0080\n",
            "33/110, train_loss: 0.0066\n",
            "34/110, train_loss: 0.0074\n",
            "35/110, train_loss: 0.0087\n",
            "36/110, train_loss: 0.0062\n",
            "37/110, train_loss: 0.0084\n",
            "38/110, train_loss: 0.0070\n",
            "39/110, train_loss: 0.0071\n",
            "40/110, train_loss: 0.0066\n",
            "41/110, train_loss: 0.0079\n",
            "42/110, train_loss: 0.0098\n",
            "43/110, train_loss: 0.0077\n",
            "44/110, train_loss: 0.0062\n",
            "45/110, train_loss: 0.0091\n",
            "46/110, train_loss: 0.0060\n",
            "47/110, train_loss: 0.0076\n",
            "48/110, train_loss: 0.0081\n",
            "49/110, train_loss: 0.0059\n",
            "50/110, train_loss: 0.0069\n",
            "51/110, train_loss: 0.0088\n",
            "52/110, train_loss: 0.0057\n",
            "53/110, train_loss: 0.0082\n",
            "54/110, train_loss: 0.0059\n",
            "55/110, train_loss: 0.0107\n",
            "56/110, train_loss: 0.0071\n",
            "57/110, train_loss: 0.0070\n",
            "58/110, train_loss: 0.0071\n",
            "59/110, train_loss: 0.0059\n",
            "60/110, train_loss: 0.0124\n",
            "61/110, train_loss: 0.0099\n",
            "62/110, train_loss: 0.0064\n",
            "63/110, train_loss: 0.0156\n",
            "64/110, train_loss: 0.0113\n",
            "65/110, train_loss: 0.0080\n",
            "66/110, train_loss: 0.0081\n",
            "67/110, train_loss: 0.0059\n",
            "68/110, train_loss: 0.0072\n",
            "69/110, train_loss: 0.0068\n",
            "70/110, train_loss: 0.0065\n",
            "71/110, train_loss: 0.0086\n",
            "72/110, train_loss: 0.0064\n",
            "73/110, train_loss: 0.0059\n",
            "74/110, train_loss: 0.0082\n",
            "75/110, train_loss: 0.0077\n",
            "76/110, train_loss: 0.0073\n",
            "77/110, train_loss: 0.0064\n",
            "78/110, train_loss: 0.0083\n",
            "79/110, train_loss: 0.0125\n",
            "80/110, train_loss: 0.0056\n",
            "81/110, train_loss: 0.0073\n",
            "82/110, train_loss: 0.0057\n",
            "83/110, train_loss: 0.0127\n",
            "84/110, train_loss: 0.0065\n",
            "85/110, train_loss: 0.0078\n",
            "86/110, train_loss: 0.0060\n",
            "87/110, train_loss: 0.0055\n",
            "88/110, train_loss: 0.0066\n",
            "89/110, train_loss: 0.0064\n",
            "90/110, train_loss: 0.0092\n",
            "91/110, train_loss: 0.0057\n",
            "92/110, train_loss: 0.0085\n",
            "93/110, train_loss: 0.0241\n",
            "94/110, train_loss: 0.0059\n",
            "95/110, train_loss: 0.0087\n",
            "96/110, train_loss: 0.0073\n",
            "97/110, train_loss: 0.0055\n",
            "98/110, train_loss: 0.0087\n",
            "99/110, train_loss: 0.0089\n",
            "100/110, train_loss: 0.0056\n",
            "101/110, train_loss: 0.0057\n",
            "102/110, train_loss: 0.0074\n",
            "103/110, train_loss: 0.0062\n",
            "104/110, train_loss: 0.0079\n",
            "105/110, train_loss: 0.0090\n",
            "106/110, train_loss: 0.0056\n",
            "107/110, train_loss: 0.0173\n",
            "108/110, train_loss: 0.0073\n",
            "109/110, train_loss: 0.0073\n",
            "110/110, train_loss: 0.0073\n",
            "epoch 85 average loss: 0.0079\n",
            "----------\n",
            "epoch 86/100\n",
            "1/110, train_loss: 0.0087\n",
            "2/110, train_loss: 0.0109\n",
            "3/110, train_loss: 0.0079\n",
            "4/110, train_loss: 0.0065\n",
            "5/110, train_loss: 0.0087\n",
            "6/110, train_loss: 0.0077\n",
            "7/110, train_loss: 0.0086\n",
            "8/110, train_loss: 0.0069\n",
            "9/110, train_loss: 0.0063\n",
            "10/110, train_loss: 0.0070\n",
            "11/110, train_loss: 0.0080\n",
            "12/110, train_loss: 0.0076\n",
            "13/110, train_loss: 0.0057\n",
            "14/110, train_loss: 0.0077\n",
            "15/110, train_loss: 0.0069\n",
            "16/110, train_loss: 0.0059\n",
            "17/110, train_loss: 0.0127\n",
            "18/110, train_loss: 0.0069\n",
            "19/110, train_loss: 0.0068\n",
            "20/110, train_loss: 0.0070\n",
            "21/110, train_loss: 0.0099\n",
            "22/110, train_loss: 0.0069\n",
            "23/110, train_loss: 0.0062\n",
            "24/110, train_loss: 0.0084\n",
            "25/110, train_loss: 0.0064\n",
            "26/110, train_loss: 0.0088\n",
            "27/110, train_loss: 0.0069\n",
            "28/110, train_loss: 0.0054\n",
            "29/110, train_loss: 0.0058\n",
            "30/110, train_loss: 0.0075\n",
            "31/110, train_loss: 0.0113\n",
            "32/110, train_loss: 0.0060\n",
            "33/110, train_loss: 0.0071\n",
            "34/110, train_loss: 0.0121\n",
            "35/110, train_loss: 0.0064\n",
            "36/110, train_loss: 0.0066\n",
            "37/110, train_loss: 0.0057\n",
            "38/110, train_loss: 0.0089\n",
            "39/110, train_loss: 0.0073\n",
            "40/110, train_loss: 0.0082\n",
            "41/110, train_loss: 0.0062\n",
            "42/110, train_loss: 0.0057\n",
            "43/110, train_loss: 0.0061\n",
            "44/110, train_loss: 0.0063\n",
            "45/110, train_loss: 0.0074\n",
            "46/110, train_loss: 0.0070\n",
            "47/110, train_loss: 0.0096\n",
            "48/110, train_loss: 0.0066\n",
            "49/110, train_loss: 0.0054\n",
            "50/110, train_loss: 0.0055\n",
            "51/110, train_loss: 0.0059\n",
            "52/110, train_loss: 0.0077\n",
            "53/110, train_loss: 0.0073\n",
            "54/110, train_loss: 0.0244\n",
            "55/110, train_loss: 0.0058\n",
            "56/110, train_loss: 0.0148\n",
            "57/110, train_loss: 0.0069\n",
            "58/110, train_loss: 0.0079\n",
            "59/110, train_loss: 0.0056\n",
            "60/110, train_loss: 0.0069\n",
            "61/110, train_loss: 0.0074\n",
            "62/110, train_loss: 0.0057\n",
            "63/110, train_loss: 0.0057\n",
            "64/110, train_loss: 0.0058\n",
            "65/110, train_loss: 0.0055\n",
            "66/110, train_loss: 0.0087\n",
            "67/110, train_loss: 0.0085\n",
            "68/110, train_loss: 0.0073\n",
            "69/110, train_loss: 0.0057\n",
            "70/110, train_loss: 0.0064\n",
            "71/110, train_loss: 0.0086\n",
            "72/110, train_loss: 0.0089\n",
            "73/110, train_loss: 0.0105\n",
            "74/110, train_loss: 0.0172\n",
            "75/110, train_loss: 0.0059\n",
            "76/110, train_loss: 0.0081\n",
            "77/110, train_loss: 0.0072\n",
            "78/110, train_loss: 0.0056\n",
            "79/110, train_loss: 0.0067\n",
            "80/110, train_loss: 0.0071\n",
            "81/110, train_loss: 0.0077\n",
            "82/110, train_loss: 0.0055\n",
            "83/110, train_loss: 0.0057\n",
            "84/110, train_loss: 0.0067\n",
            "85/110, train_loss: 0.0080\n",
            "86/110, train_loss: 0.0077\n",
            "87/110, train_loss: 0.0098\n",
            "88/110, train_loss: 0.0066\n",
            "89/110, train_loss: 0.0077\n",
            "90/110, train_loss: 0.0055\n",
            "91/110, train_loss: 0.0061\n",
            "92/110, train_loss: 0.0057\n",
            "93/110, train_loss: 0.0054\n",
            "94/110, train_loss: 0.0052\n",
            "95/110, train_loss: 0.0056\n",
            "96/110, train_loss: 0.0077\n",
            "97/110, train_loss: 0.0061\n",
            "98/110, train_loss: 0.0123\n",
            "99/110, train_loss: 0.0053\n",
            "100/110, train_loss: 0.0055\n",
            "101/110, train_loss: 0.0071\n",
            "102/110, train_loss: 0.0059\n",
            "103/110, train_loss: 0.0066\n",
            "104/110, train_loss: 0.0079\n",
            "105/110, train_loss: 0.0068\n",
            "106/110, train_loss: 0.0075\n",
            "107/110, train_loss: 0.0090\n",
            "108/110, train_loss: 0.0077\n",
            "109/110, train_loss: 0.0091\n",
            "110/110, train_loss: 0.0122\n",
            "epoch 86 average loss: 0.0076\n",
            "----------\n",
            "epoch 87/100\n",
            "1/110, train_loss: 0.0054\n",
            "2/110, train_loss: 0.0062\n",
            "3/110, train_loss: 0.0065\n",
            "4/110, train_loss: 0.0143\n",
            "5/110, train_loss: 0.0068\n",
            "6/110, train_loss: 0.0059\n",
            "7/110, train_loss: 0.0117\n",
            "8/110, train_loss: 0.0066\n",
            "9/110, train_loss: 0.0066\n",
            "10/110, train_loss: 0.0074\n",
            "11/110, train_loss: 0.0052\n",
            "12/110, train_loss: 0.0073\n",
            "13/110, train_loss: 0.0074\n",
            "14/110, train_loss: 0.0055\n",
            "15/110, train_loss: 0.0067\n",
            "16/110, train_loss: 0.0078\n",
            "17/110, train_loss: 0.0051\n",
            "18/110, train_loss: 0.0104\n",
            "19/110, train_loss: 0.0076\n",
            "20/110, train_loss: 0.0082\n",
            "21/110, train_loss: 0.0067\n",
            "22/110, train_loss: 0.0068\n",
            "23/110, train_loss: 0.0055\n",
            "24/110, train_loss: 0.0092\n",
            "25/110, train_loss: 0.0057\n",
            "26/110, train_loss: 0.0064\n",
            "27/110, train_loss: 0.0109\n",
            "28/110, train_loss: 0.0053\n",
            "29/110, train_loss: 0.0081\n",
            "30/110, train_loss: 0.0067\n",
            "31/110, train_loss: 0.0059\n",
            "32/110, train_loss: 0.0063\n",
            "33/110, train_loss: 0.0052\n",
            "34/110, train_loss: 0.0053\n",
            "35/110, train_loss: 0.0067\n",
            "36/110, train_loss: 0.0266\n",
            "37/110, train_loss: 0.0058\n",
            "38/110, train_loss: 0.0064\n",
            "39/110, train_loss: 0.0073\n",
            "40/110, train_loss: 0.0060\n",
            "41/110, train_loss: 0.0053\n",
            "42/110, train_loss: 0.0064\n",
            "43/110, train_loss: 0.0058\n",
            "44/110, train_loss: 0.0052\n",
            "45/110, train_loss: 0.0080\n",
            "46/110, train_loss: 0.0059\n",
            "47/110, train_loss: 0.0056\n",
            "48/110, train_loss: 0.0098\n",
            "49/110, train_loss: 0.0063\n",
            "50/110, train_loss: 0.0088\n",
            "51/110, train_loss: 0.0065\n",
            "52/110, train_loss: 0.0075\n",
            "53/110, train_loss: 0.0056\n",
            "54/110, train_loss: 0.0163\n",
            "55/110, train_loss: 0.0055\n",
            "56/110, train_loss: 0.0071\n",
            "57/110, train_loss: 0.0074\n",
            "58/110, train_loss: 0.0067\n",
            "59/110, train_loss: 0.0060\n",
            "60/110, train_loss: 0.0065\n",
            "61/110, train_loss: 0.0053\n",
            "62/110, train_loss: 0.0073\n",
            "63/110, train_loss: 0.0085\n",
            "64/110, train_loss: 0.0091\n",
            "65/110, train_loss: 0.0075\n",
            "66/110, train_loss: 0.0081\n",
            "67/110, train_loss: 0.0051\n",
            "68/110, train_loss: 0.0053\n",
            "69/110, train_loss: 0.0070\n",
            "70/110, train_loss: 0.0052\n",
            "71/110, train_loss: 0.0069\n",
            "72/110, train_loss: 0.0078\n",
            "73/110, train_loss: 0.0062\n",
            "74/110, train_loss: 0.0116\n",
            "75/110, train_loss: 0.0054\n",
            "76/110, train_loss: 0.0074\n",
            "77/110, train_loss: 0.0079\n",
            "78/110, train_loss: 0.0070\n",
            "79/110, train_loss: 0.0056\n",
            "80/110, train_loss: 0.0059\n",
            "81/110, train_loss: 0.0080\n",
            "82/110, train_loss: 0.0072\n",
            "83/110, train_loss: 0.0071\n",
            "84/110, train_loss: 0.0072\n",
            "85/110, train_loss: 0.0051\n",
            "86/110, train_loss: 0.0074\n",
            "87/110, train_loss: 0.0073\n",
            "88/110, train_loss: 0.0057\n",
            "89/110, train_loss: 0.0053\n",
            "90/110, train_loss: 0.0052\n",
            "91/110, train_loss: 0.0114\n",
            "92/110, train_loss: 0.0115\n",
            "93/110, train_loss: 0.0053\n",
            "94/110, train_loss: 0.0097\n",
            "95/110, train_loss: 0.0065\n",
            "96/110, train_loss: 0.0080\n",
            "97/110, train_loss: 0.0051\n",
            "98/110, train_loss: 0.0079\n",
            "99/110, train_loss: 0.0063\n",
            "100/110, train_loss: 0.0049\n",
            "101/110, train_loss: 0.0063\n",
            "102/110, train_loss: 0.0058\n",
            "103/110, train_loss: 0.0051\n",
            "104/110, train_loss: 0.0069\n",
            "105/110, train_loss: 0.0082\n",
            "106/110, train_loss: 0.0067\n",
            "107/110, train_loss: 0.0078\n",
            "108/110, train_loss: 0.0086\n",
            "109/110, train_loss: 0.0088\n",
            "110/110, train_loss: 0.0057\n",
            "epoch 87 average loss: 0.0072\n",
            "current epoch: 87 current accuracy: 0.8571 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 88/100\n",
            "1/110, train_loss: 0.0062\n",
            "2/110, train_loss: 0.0049\n",
            "3/110, train_loss: 0.0068\n",
            "4/110, train_loss: 0.0056\n",
            "5/110, train_loss: 0.0053\n",
            "6/110, train_loss: 0.0076\n",
            "7/110, train_loss: 0.0097\n",
            "8/110, train_loss: 0.0074\n",
            "9/110, train_loss: 0.0050\n",
            "10/110, train_loss: 0.0053\n",
            "11/110, train_loss: 0.0071\n",
            "12/110, train_loss: 0.0064\n",
            "13/110, train_loss: 0.0102\n",
            "14/110, train_loss: 0.0062\n",
            "15/110, train_loss: 0.0074\n",
            "16/110, train_loss: 0.0089\n",
            "17/110, train_loss: 0.0058\n",
            "18/110, train_loss: 0.0073\n",
            "19/110, train_loss: 0.0087\n",
            "20/110, train_loss: 0.0079\n",
            "21/110, train_loss: 0.0066\n",
            "22/110, train_loss: 0.0105\n",
            "23/110, train_loss: 0.0063\n",
            "24/110, train_loss: 0.0053\n",
            "25/110, train_loss: 0.0060\n",
            "26/110, train_loss: 0.0063\n",
            "27/110, train_loss: 0.0065\n",
            "28/110, train_loss: 0.0051\n",
            "29/110, train_loss: 0.0071\n",
            "30/110, train_loss: 0.0071\n",
            "31/110, train_loss: 0.0071\n",
            "32/110, train_loss: 0.0060\n",
            "33/110, train_loss: 0.0074\n",
            "34/110, train_loss: 0.0223\n",
            "35/110, train_loss: 0.0053\n",
            "36/110, train_loss: 0.0058\n",
            "37/110, train_loss: 0.0057\n",
            "38/110, train_loss: 0.0065\n",
            "39/110, train_loss: 0.0098\n",
            "40/110, train_loss: 0.0062\n",
            "41/110, train_loss: 0.0054\n",
            "42/110, train_loss: 0.0066\n",
            "43/110, train_loss: 0.0073\n",
            "44/110, train_loss: 0.0068\n",
            "45/110, train_loss: 0.0077\n",
            "46/110, train_loss: 0.0055\n",
            "47/110, train_loss: 0.0053\n",
            "48/110, train_loss: 0.0058\n",
            "49/110, train_loss: 0.0078\n",
            "50/110, train_loss: 0.0066\n",
            "51/110, train_loss: 0.0059\n",
            "52/110, train_loss: 0.0063\n",
            "53/110, train_loss: 0.0066\n",
            "54/110, train_loss: 0.0050\n",
            "55/110, train_loss: 0.0070\n",
            "56/110, train_loss: 0.0080\n",
            "57/110, train_loss: 0.0052\n",
            "58/110, train_loss: 0.0069\n",
            "59/110, train_loss: 0.0059\n",
            "60/110, train_loss: 0.0117\n",
            "61/110, train_loss: 0.0055\n",
            "62/110, train_loss: 0.0067\n",
            "63/110, train_loss: 0.0063\n",
            "64/110, train_loss: 0.0050\n",
            "65/110, train_loss: 0.0057\n",
            "66/110, train_loss: 0.0079\n",
            "67/110, train_loss: 0.0050\n",
            "68/110, train_loss: 0.0056\n",
            "69/110, train_loss: 0.0058\n",
            "70/110, train_loss: 0.0049\n",
            "71/110, train_loss: 0.0049\n",
            "72/110, train_loss: 0.0063\n",
            "73/110, train_loss: 0.0060\n",
            "74/110, train_loss: 0.0058\n",
            "75/110, train_loss: 0.0052\n",
            "76/110, train_loss: 0.0070\n",
            "77/110, train_loss: 0.0050\n",
            "78/110, train_loss: 0.0069\n",
            "79/110, train_loss: 0.0053\n",
            "80/110, train_loss: 0.0110\n",
            "81/110, train_loss: 0.0060\n",
            "82/110, train_loss: 0.0051\n",
            "83/110, train_loss: 0.0108\n",
            "84/110, train_loss: 0.0066\n",
            "85/110, train_loss: 0.0050\n",
            "86/110, train_loss: 0.0081\n",
            "87/110, train_loss: 0.0062\n",
            "88/110, train_loss: 0.0070\n",
            "89/110, train_loss: 0.0056\n",
            "90/110, train_loss: 0.0060\n",
            "91/110, train_loss: 0.0059\n",
            "92/110, train_loss: 0.0066\n",
            "93/110, train_loss: 0.0050\n",
            "94/110, train_loss: 0.0049\n",
            "95/110, train_loss: 0.0053\n",
            "96/110, train_loss: 0.0075\n",
            "97/110, train_loss: 0.0076\n",
            "98/110, train_loss: 0.0054\n",
            "99/110, train_loss: 0.0068\n",
            "100/110, train_loss: 0.0050\n",
            "101/110, train_loss: 0.0048\n",
            "102/110, train_loss: 0.0063\n",
            "103/110, train_loss: 0.0085\n",
            "104/110, train_loss: 0.0144\n",
            "105/110, train_loss: 0.0064\n",
            "106/110, train_loss: 0.0079\n",
            "107/110, train_loss: 0.0073\n",
            "108/110, train_loss: 0.0136\n",
            "109/110, train_loss: 0.0069\n",
            "110/110, train_loss: 0.0051\n",
            "epoch 88 average loss: 0.0068\n",
            "----------\n",
            "epoch 89/100\n",
            "1/110, train_loss: 0.0063\n",
            "2/110, train_loss: 0.0057\n",
            "3/110, train_loss: 0.0086\n",
            "4/110, train_loss: 0.0093\n",
            "5/110, train_loss: 0.0047\n",
            "6/110, train_loss: 0.0072\n",
            "7/110, train_loss: 0.0053\n",
            "8/110, train_loss: 0.0054\n",
            "9/110, train_loss: 0.0055\n",
            "10/110, train_loss: 0.0074\n",
            "11/110, train_loss: 0.0061\n",
            "12/110, train_loss: 0.0059\n",
            "13/110, train_loss: 0.0048\n",
            "14/110, train_loss: 0.0049\n",
            "15/110, train_loss: 0.0062\n",
            "16/110, train_loss: 0.0065\n",
            "17/110, train_loss: 0.0065\n",
            "18/110, train_loss: 0.0130\n",
            "19/110, train_loss: 0.0059\n",
            "20/110, train_loss: 0.0048\n",
            "21/110, train_loss: 0.0050\n",
            "22/110, train_loss: 0.0104\n",
            "23/110, train_loss: 0.0048\n",
            "24/110, train_loss: 0.0048\n",
            "25/110, train_loss: 0.0053\n",
            "26/110, train_loss: 0.0058\n",
            "27/110, train_loss: 0.0046\n",
            "28/110, train_loss: 0.0059\n",
            "29/110, train_loss: 0.0057\n",
            "30/110, train_loss: 0.0047\n",
            "31/110, train_loss: 0.0088\n",
            "32/110, train_loss: 0.0051\n",
            "33/110, train_loss: 0.0098\n",
            "34/110, train_loss: 0.0048\n",
            "35/110, train_loss: 0.0064\n",
            "36/110, train_loss: 0.0061\n",
            "37/110, train_loss: 0.0050\n",
            "38/110, train_loss: 0.0067\n",
            "39/110, train_loss: 0.0057\n",
            "40/110, train_loss: 0.0053\n",
            "41/110, train_loss: 0.0049\n",
            "42/110, train_loss: 0.0065\n",
            "43/110, train_loss: 0.0055\n",
            "44/110, train_loss: 0.0047\n",
            "45/110, train_loss: 0.0079\n",
            "46/110, train_loss: 0.0103\n",
            "47/110, train_loss: 0.0233\n",
            "48/110, train_loss: 0.0067\n",
            "49/110, train_loss: 0.0053\n",
            "50/110, train_loss: 0.0060\n",
            "51/110, train_loss: 0.0072\n",
            "52/110, train_loss: 0.0065\n",
            "53/110, train_loss: 0.0069\n",
            "54/110, train_loss: 0.0049\n",
            "55/110, train_loss: 0.0062\n",
            "56/110, train_loss: 0.0050\n",
            "57/110, train_loss: 0.0056\n",
            "58/110, train_loss: 0.0076\n",
            "59/110, train_loss: 0.0067\n",
            "60/110, train_loss: 0.0061\n",
            "61/110, train_loss: 0.0070\n",
            "62/110, train_loss: 0.0053\n",
            "63/110, train_loss: 0.0061\n",
            "64/110, train_loss: 0.0058\n",
            "65/110, train_loss: 0.0104\n",
            "66/110, train_loss: 0.0078\n",
            "67/110, train_loss: 0.0049\n",
            "68/110, train_loss: 0.0139\n",
            "69/110, train_loss: 0.0072\n",
            "70/110, train_loss: 0.0046\n",
            "71/110, train_loss: 0.0052\n",
            "72/110, train_loss: 0.0066\n",
            "73/110, train_loss: 0.0072\n",
            "74/110, train_loss: 0.0066\n",
            "75/110, train_loss: 0.0047\n",
            "76/110, train_loss: 0.0048\n",
            "77/110, train_loss: 0.0053\n",
            "78/110, train_loss: 0.0051\n",
            "79/110, train_loss: 0.0058\n",
            "80/110, train_loss: 0.0049\n",
            "81/110, train_loss: 0.0059\n",
            "82/110, train_loss: 0.0047\n",
            "83/110, train_loss: 0.0058\n",
            "84/110, train_loss: 0.0066\n",
            "85/110, train_loss: 0.0080\n",
            "86/110, train_loss: 0.0074\n",
            "87/110, train_loss: 0.0063\n",
            "88/110, train_loss: 0.0105\n",
            "89/110, train_loss: 0.0066\n",
            "90/110, train_loss: 0.0070\n",
            "91/110, train_loss: 0.0058\n",
            "92/110, train_loss: 0.0064\n",
            "93/110, train_loss: 0.0072\n",
            "94/110, train_loss: 0.0072\n",
            "95/110, train_loss: 0.0067\n",
            "96/110, train_loss: 0.0046\n",
            "97/110, train_loss: 0.0082\n",
            "98/110, train_loss: 0.0068\n",
            "99/110, train_loss: 0.0045\n",
            "100/110, train_loss: 0.0062\n",
            "101/110, train_loss: 0.0061\n",
            "102/110, train_loss: 0.0045\n",
            "103/110, train_loss: 0.0065\n",
            "104/110, train_loss: 0.0048\n",
            "105/110, train_loss: 0.0051\n",
            "106/110, train_loss: 0.0059\n",
            "107/110, train_loss: 0.0054\n",
            "108/110, train_loss: 0.0046\n",
            "109/110, train_loss: 0.0076\n",
            "110/110, train_loss: 0.0070\n",
            "epoch 89 average loss: 0.0065\n",
            "----------\n",
            "epoch 90/100\n",
            "1/110, train_loss: 0.0059\n",
            "2/110, train_loss: 0.0047\n",
            "3/110, train_loss: 0.0062\n",
            "4/110, train_loss: 0.0063\n",
            "5/110, train_loss: 0.0045\n",
            "6/110, train_loss: 0.0066\n",
            "7/110, train_loss: 0.0062\n",
            "8/110, train_loss: 0.0050\n",
            "9/110, train_loss: 0.0077\n",
            "10/110, train_loss: 0.0046\n",
            "11/110, train_loss: 0.0050\n",
            "12/110, train_loss: 0.0044\n",
            "13/110, train_loss: 0.0072\n",
            "14/110, train_loss: 0.0050\n",
            "15/110, train_loss: 0.0058\n",
            "16/110, train_loss: 0.0046\n",
            "17/110, train_loss: 0.0048\n",
            "18/110, train_loss: 0.0069\n",
            "19/110, train_loss: 0.0064\n",
            "20/110, train_loss: 0.0063\n",
            "21/110, train_loss: 0.0055\n",
            "22/110, train_loss: 0.0044\n",
            "23/110, train_loss: 0.0067\n",
            "24/110, train_loss: 0.0069\n",
            "25/110, train_loss: 0.0045\n",
            "26/110, train_loss: 0.0044\n",
            "27/110, train_loss: 0.0097\n",
            "28/110, train_loss: 0.0052\n",
            "29/110, train_loss: 0.0056\n",
            "30/110, train_loss: 0.0053\n",
            "31/110, train_loss: 0.0068\n",
            "32/110, train_loss: 0.0068\n",
            "33/110, train_loss: 0.0066\n",
            "34/110, train_loss: 0.0070\n",
            "35/110, train_loss: 0.0058\n",
            "36/110, train_loss: 0.0046\n",
            "37/110, train_loss: 0.0055\n",
            "38/110, train_loss: 0.0058\n",
            "39/110, train_loss: 0.0056\n",
            "40/110, train_loss: 0.0097\n",
            "41/110, train_loss: 0.0078\n",
            "42/110, train_loss: 0.0064\n",
            "43/110, train_loss: 0.0047\n",
            "44/110, train_loss: 0.0046\n",
            "45/110, train_loss: 0.0059\n",
            "46/110, train_loss: 0.0045\n",
            "47/110, train_loss: 0.0054\n",
            "48/110, train_loss: 0.0099\n",
            "49/110, train_loss: 0.0056\n",
            "50/110, train_loss: 0.0056\n",
            "51/110, train_loss: 0.0044\n",
            "52/110, train_loss: 0.0044\n",
            "53/110, train_loss: 0.0055\n",
            "54/110, train_loss: 0.0075\n",
            "55/110, train_loss: 0.0046\n",
            "56/110, train_loss: 0.0046\n",
            "57/110, train_loss: 0.0049\n",
            "58/110, train_loss: 0.0048\n",
            "59/110, train_loss: 0.0062\n",
            "60/110, train_loss: 0.0047\n",
            "61/110, train_loss: 0.0124\n",
            "62/110, train_loss: 0.0061\n",
            "63/110, train_loss: 0.0069\n",
            "64/110, train_loss: 0.0058\n",
            "65/110, train_loss: 0.0059\n",
            "66/110, train_loss: 0.0089\n",
            "67/110, train_loss: 0.0060\n",
            "68/110, train_loss: 0.0051\n",
            "69/110, train_loss: 0.0074\n",
            "70/110, train_loss: 0.0062\n",
            "71/110, train_loss: 0.0054\n",
            "72/110, train_loss: 0.0068\n",
            "73/110, train_loss: 0.0055\n",
            "74/110, train_loss: 0.0058\n",
            "75/110, train_loss: 0.0050\n",
            "76/110, train_loss: 0.0051\n",
            "77/110, train_loss: 0.0045\n",
            "78/110, train_loss: 0.0050\n",
            "79/110, train_loss: 0.0063\n",
            "80/110, train_loss: 0.0091\n",
            "81/110, train_loss: 0.0048\n",
            "82/110, train_loss: 0.0046\n",
            "83/110, train_loss: 0.0059\n",
            "84/110, train_loss: 0.0069\n",
            "85/110, train_loss: 0.0054\n",
            "86/110, train_loss: 0.0046\n",
            "87/110, train_loss: 0.0082\n",
            "88/110, train_loss: 0.0072\n",
            "89/110, train_loss: 0.0044\n",
            "90/110, train_loss: 0.0061\n",
            "91/110, train_loss: 0.0056\n",
            "92/110, train_loss: 0.0044\n",
            "93/110, train_loss: 0.0055\n",
            "94/110, train_loss: 0.0055\n",
            "95/110, train_loss: 0.0050\n",
            "96/110, train_loss: 0.0046\n",
            "97/110, train_loss: 0.0069\n",
            "98/110, train_loss: 0.0062\n",
            "99/110, train_loss: 0.0098\n",
            "100/110, train_loss: 0.0128\n",
            "101/110, train_loss: 0.0048\n",
            "102/110, train_loss: 0.0060\n",
            "103/110, train_loss: 0.0080\n",
            "104/110, train_loss: 0.0060\n",
            "105/110, train_loss: 0.0063\n",
            "106/110, train_loss: 0.0191\n",
            "107/110, train_loss: 0.0050\n",
            "108/110, train_loss: 0.0057\n",
            "109/110, train_loss: 0.0045\n",
            "110/110, train_loss: 0.0043\n",
            "epoch 90 average loss: 0.0061\n",
            "current epoch: 90 current accuracy: 0.6429 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 91/100\n",
            "1/110, train_loss: 0.0068\n",
            "2/110, train_loss: 0.0048\n",
            "3/110, train_loss: 0.0048\n",
            "4/110, train_loss: 0.0127\n",
            "5/110, train_loss: 0.0056\n",
            "6/110, train_loss: 0.0074\n",
            "7/110, train_loss: 0.0050\n",
            "8/110, train_loss: 0.0054\n",
            "9/110, train_loss: 0.0069\n",
            "10/110, train_loss: 0.0097\n",
            "11/110, train_loss: 0.0063\n",
            "12/110, train_loss: 0.0068\n",
            "13/110, train_loss: 0.0118\n",
            "14/110, train_loss: 0.0080\n",
            "15/110, train_loss: 0.0049\n",
            "16/110, train_loss: 0.0045\n",
            "17/110, train_loss: 0.0043\n",
            "18/110, train_loss: 0.0042\n",
            "19/110, train_loss: 0.0056\n",
            "20/110, train_loss: 0.0045\n",
            "21/110, train_loss: 0.0054\n",
            "22/110, train_loss: 0.0056\n",
            "23/110, train_loss: 0.0094\n",
            "24/110, train_loss: 0.0046\n",
            "25/110, train_loss: 0.0048\n",
            "26/110, train_loss: 0.0057\n",
            "27/110, train_loss: 0.0048\n",
            "28/110, train_loss: 0.0067\n",
            "29/110, train_loss: 0.0053\n",
            "30/110, train_loss: 0.0060\n",
            "31/110, train_loss: 0.0060\n",
            "32/110, train_loss: 0.0043\n",
            "33/110, train_loss: 0.0060\n",
            "34/110, train_loss: 0.0053\n",
            "35/110, train_loss: 0.0052\n",
            "36/110, train_loss: 0.0091\n",
            "37/110, train_loss: 0.0053\n",
            "38/110, train_loss: 0.0095\n",
            "39/110, train_loss: 0.0058\n",
            "40/110, train_loss: 0.0042\n",
            "41/110, train_loss: 0.0053\n",
            "42/110, train_loss: 0.0053\n",
            "43/110, train_loss: 0.0050\n",
            "44/110, train_loss: 0.0042\n",
            "45/110, train_loss: 0.0051\n",
            "46/110, train_loss: 0.0060\n",
            "47/110, train_loss: 0.0056\n",
            "48/110, train_loss: 0.0045\n",
            "49/110, train_loss: 0.0060\n",
            "50/110, train_loss: 0.0044\n",
            "51/110, train_loss: 0.0069\n",
            "52/110, train_loss: 0.0087\n",
            "53/110, train_loss: 0.0058\n",
            "54/110, train_loss: 0.0050\n",
            "55/110, train_loss: 0.0055\n",
            "56/110, train_loss: 0.0057\n",
            "57/110, train_loss: 0.0042\n",
            "58/110, train_loss: 0.0064\n",
            "59/110, train_loss: 0.0043\n",
            "60/110, train_loss: 0.0190\n",
            "61/110, train_loss: 0.0058\n",
            "62/110, train_loss: 0.0058\n",
            "63/110, train_loss: 0.0067\n",
            "64/110, train_loss: 0.0053\n",
            "65/110, train_loss: 0.0049\n",
            "66/110, train_loss: 0.0065\n",
            "67/110, train_loss: 0.0061\n",
            "68/110, train_loss: 0.0042\n",
            "69/110, train_loss: 0.0049\n",
            "70/110, train_loss: 0.0045\n",
            "71/110, train_loss: 0.0047\n",
            "72/110, train_loss: 0.0044\n",
            "73/110, train_loss: 0.0055\n",
            "74/110, train_loss: 0.0044\n",
            "75/110, train_loss: 0.0042\n",
            "76/110, train_loss: 0.0048\n",
            "77/110, train_loss: 0.0083\n",
            "78/110, train_loss: 0.0057\n",
            "79/110, train_loss: 0.0047\n",
            "80/110, train_loss: 0.0043\n",
            "81/110, train_loss: 0.0041\n",
            "82/110, train_loss: 0.0055\n",
            "83/110, train_loss: 0.0058\n",
            "84/110, train_loss: 0.0062\n",
            "85/110, train_loss: 0.0062\n",
            "86/110, train_loss: 0.0069\n",
            "87/110, train_loss: 0.0057\n",
            "88/110, train_loss: 0.0060\n",
            "89/110, train_loss: 0.0043\n",
            "90/110, train_loss: 0.0066\n",
            "91/110, train_loss: 0.0051\n",
            "92/110, train_loss: 0.0043\n",
            "93/110, train_loss: 0.0075\n",
            "94/110, train_loss: 0.0049\n",
            "95/110, train_loss: 0.0042\n",
            "96/110, train_loss: 0.0064\n",
            "97/110, train_loss: 0.0074\n",
            "98/110, train_loss: 0.0062\n",
            "99/110, train_loss: 0.0042\n",
            "100/110, train_loss: 0.0044\n",
            "101/110, train_loss: 0.0043\n",
            "102/110, train_loss: 0.0052\n",
            "103/110, train_loss: 0.0053\n",
            "104/110, train_loss: 0.0058\n",
            "105/110, train_loss: 0.0045\n",
            "106/110, train_loss: 0.0074\n",
            "107/110, train_loss: 0.0054\n",
            "108/110, train_loss: 0.0047\n",
            "109/110, train_loss: 0.0060\n",
            "110/110, train_loss: 0.0060\n",
            "epoch 91 average loss: 0.0059\n",
            "----------\n",
            "epoch 92/100\n",
            "1/110, train_loss: 0.0041\n",
            "2/110, train_loss: 0.0053\n",
            "3/110, train_loss: 0.0050\n",
            "4/110, train_loss: 0.0062\n",
            "5/110, train_loss: 0.0042\n",
            "6/110, train_loss: 0.0056\n",
            "7/110, train_loss: 0.0063\n",
            "8/110, train_loss: 0.0064\n",
            "9/110, train_loss: 0.0062\n",
            "10/110, train_loss: 0.0049\n",
            "11/110, train_loss: 0.0061\n",
            "12/110, train_loss: 0.0051\n",
            "13/110, train_loss: 0.0044\n",
            "14/110, train_loss: 0.0057\n",
            "15/110, train_loss: 0.0070\n",
            "16/110, train_loss: 0.0041\n",
            "17/110, train_loss: 0.0060\n",
            "18/110, train_loss: 0.0041\n",
            "19/110, train_loss: 0.0042\n",
            "20/110, train_loss: 0.0073\n",
            "21/110, train_loss: 0.0054\n",
            "22/110, train_loss: 0.0058\n",
            "23/110, train_loss: 0.0058\n",
            "24/110, train_loss: 0.0042\n",
            "25/110, train_loss: 0.0051\n",
            "26/110, train_loss: 0.0040\n",
            "27/110, train_loss: 0.0049\n",
            "28/110, train_loss: 0.0045\n",
            "29/110, train_loss: 0.0050\n",
            "30/110, train_loss: 0.0046\n",
            "31/110, train_loss: 0.0057\n",
            "32/110, train_loss: 0.0051\n",
            "33/110, train_loss: 0.0070\n",
            "34/110, train_loss: 0.0039\n",
            "35/110, train_loss: 0.0046\n",
            "36/110, train_loss: 0.0044\n",
            "37/110, train_loss: 0.0044\n",
            "38/110, train_loss: 0.0065\n",
            "39/110, train_loss: 0.0054\n",
            "40/110, train_loss: 0.0090\n",
            "41/110, train_loss: 0.0041\n",
            "42/110, train_loss: 0.0041\n",
            "43/110, train_loss: 0.0176\n",
            "44/110, train_loss: 0.0039\n",
            "45/110, train_loss: 0.0050\n",
            "46/110, train_loss: 0.0058\n",
            "47/110, train_loss: 0.0041\n",
            "48/110, train_loss: 0.0048\n",
            "49/110, train_loss: 0.0064\n",
            "50/110, train_loss: 0.0058\n",
            "51/110, train_loss: 0.0091\n",
            "52/110, train_loss: 0.0051\n",
            "53/110, train_loss: 0.0060\n",
            "54/110, train_loss: 0.0056\n",
            "55/110, train_loss: 0.0044\n",
            "56/110, train_loss: 0.0041\n",
            "57/110, train_loss: 0.0061\n",
            "58/110, train_loss: 0.0045\n",
            "59/110, train_loss: 0.0067\n",
            "60/110, train_loss: 0.0050\n",
            "61/110, train_loss: 0.0043\n",
            "62/110, train_loss: 0.0050\n",
            "63/110, train_loss: 0.0041\n",
            "64/110, train_loss: 0.0062\n",
            "65/110, train_loss: 0.0061\n",
            "66/110, train_loss: 0.0057\n",
            "67/110, train_loss: 0.0043\n",
            "68/110, train_loss: 0.0062\n",
            "69/110, train_loss: 0.0089\n",
            "70/110, train_loss: 0.0040\n",
            "71/110, train_loss: 0.0053\n",
            "72/110, train_loss: 0.0042\n",
            "73/110, train_loss: 0.0051\n",
            "74/110, train_loss: 0.0055\n",
            "75/110, train_loss: 0.0054\n",
            "76/110, train_loss: 0.0091\n",
            "77/110, train_loss: 0.0041\n",
            "78/110, train_loss: 0.0047\n",
            "79/110, train_loss: 0.0052\n",
            "80/110, train_loss: 0.0043\n",
            "81/110, train_loss: 0.0057\n",
            "82/110, train_loss: 0.0051\n",
            "83/110, train_loss: 0.0055\n",
            "84/110, train_loss: 0.0110\n",
            "85/110, train_loss: 0.0052\n",
            "86/110, train_loss: 0.0042\n",
            "87/110, train_loss: 0.0055\n",
            "88/110, train_loss: 0.0041\n",
            "89/110, train_loss: 0.0049\n",
            "90/110, train_loss: 0.0049\n",
            "91/110, train_loss: 0.0044\n",
            "92/110, train_loss: 0.0051\n",
            "93/110, train_loss: 0.0067\n",
            "94/110, train_loss: 0.0046\n",
            "95/110, train_loss: 0.0118\n",
            "96/110, train_loss: 0.0045\n",
            "97/110, train_loss: 0.0054\n",
            "98/110, train_loss: 0.0065\n",
            "99/110, train_loss: 0.0082\n",
            "100/110, train_loss: 0.0040\n",
            "101/110, train_loss: 0.0075\n",
            "102/110, train_loss: 0.0039\n",
            "103/110, train_loss: 0.0056\n",
            "104/110, train_loss: 0.0039\n",
            "105/110, train_loss: 0.0044\n",
            "106/110, train_loss: 0.0051\n",
            "107/110, train_loss: 0.0077\n",
            "108/110, train_loss: 0.0041\n",
            "109/110, train_loss: 0.0047\n",
            "110/110, train_loss: 0.0056\n",
            "epoch 92 average loss: 0.0055\n",
            "----------\n",
            "epoch 93/100\n",
            "1/110, train_loss: 0.0041\n",
            "2/110, train_loss: 0.0062\n",
            "3/110, train_loss: 0.0044\n",
            "4/110, train_loss: 0.0039\n",
            "5/110, train_loss: 0.0050\n",
            "6/110, train_loss: 0.0040\n",
            "7/110, train_loss: 0.0053\n",
            "8/110, train_loss: 0.0050\n",
            "9/110, train_loss: 0.0058\n",
            "10/110, train_loss: 0.0054\n",
            "11/110, train_loss: 0.0048\n",
            "12/110, train_loss: 0.0052\n",
            "13/110, train_loss: 0.0041\n",
            "14/110, train_loss: 0.0048\n",
            "15/110, train_loss: 0.0042\n",
            "16/110, train_loss: 0.0059\n",
            "17/110, train_loss: 0.0039\n",
            "18/110, train_loss: 0.0068\n",
            "19/110, train_loss: 0.0041\n",
            "20/110, train_loss: 0.0044\n",
            "21/110, train_loss: 0.0050\n",
            "22/110, train_loss: 0.0084\n",
            "23/110, train_loss: 0.0039\n",
            "24/110, train_loss: 0.0040\n",
            "25/110, train_loss: 0.0037\n",
            "26/110, train_loss: 0.0043\n",
            "27/110, train_loss: 0.0038\n",
            "28/110, train_loss: 0.0051\n",
            "29/110, train_loss: 0.0054\n",
            "30/110, train_loss: 0.0047\n",
            "31/110, train_loss: 0.0052\n",
            "32/110, train_loss: 0.0042\n",
            "33/110, train_loss: 0.0057\n",
            "34/110, train_loss: 0.0038\n",
            "35/110, train_loss: 0.0054\n",
            "36/110, train_loss: 0.0042\n",
            "37/110, train_loss: 0.0085\n",
            "38/110, train_loss: 0.0064\n",
            "39/110, train_loss: 0.0074\n",
            "40/110, train_loss: 0.0060\n",
            "41/110, train_loss: 0.0048\n",
            "42/110, train_loss: 0.0038\n",
            "43/110, train_loss: 0.0053\n",
            "44/110, train_loss: 0.0045\n",
            "45/110, train_loss: 0.0047\n",
            "46/110, train_loss: 0.0071\n",
            "47/110, train_loss: 0.0039\n",
            "48/110, train_loss: 0.0058\n",
            "49/110, train_loss: 0.0038\n",
            "50/110, train_loss: 0.0045\n",
            "51/110, train_loss: 0.0054\n",
            "52/110, train_loss: 0.0062\n",
            "53/110, train_loss: 0.0047\n",
            "54/110, train_loss: 0.0040\n",
            "55/110, train_loss: 0.0039\n",
            "56/110, train_loss: 0.0062\n",
            "57/110, train_loss: 0.0044\n",
            "58/110, train_loss: 0.0040\n",
            "59/110, train_loss: 0.0048\n",
            "60/110, train_loss: 0.0046\n",
            "61/110, train_loss: 0.0049\n",
            "62/110, train_loss: 0.0058\n",
            "63/110, train_loss: 0.0042\n",
            "64/110, train_loss: 0.0038\n",
            "65/110, train_loss: 0.0059\n",
            "66/110, train_loss: 0.0048\n",
            "67/110, train_loss: 0.0049\n",
            "68/110, train_loss: 0.0166\n",
            "69/110, train_loss: 0.0060\n",
            "70/110, train_loss: 0.0054\n",
            "71/110, train_loss: 0.0057\n",
            "72/110, train_loss: 0.0054\n",
            "73/110, train_loss: 0.0054\n",
            "74/110, train_loss: 0.0042\n",
            "75/110, train_loss: 0.0048\n",
            "76/110, train_loss: 0.0050\n",
            "77/110, train_loss: 0.0055\n",
            "78/110, train_loss: 0.0069\n",
            "79/110, train_loss: 0.0083\n",
            "80/110, train_loss: 0.0069\n",
            "81/110, train_loss: 0.0052\n",
            "82/110, train_loss: 0.0055\n",
            "83/110, train_loss: 0.0051\n",
            "84/110, train_loss: 0.0039\n",
            "85/110, train_loss: 0.0040\n",
            "86/110, train_loss: 0.0048\n",
            "87/110, train_loss: 0.0052\n",
            "88/110, train_loss: 0.0057\n",
            "89/110, train_loss: 0.0040\n",
            "90/110, train_loss: 0.0040\n",
            "91/110, train_loss: 0.0061\n",
            "92/110, train_loss: 0.0043\n",
            "93/110, train_loss: 0.0040\n",
            "94/110, train_loss: 0.0042\n",
            "95/110, train_loss: 0.0038\n",
            "96/110, train_loss: 0.0039\n",
            "97/110, train_loss: 0.0077\n",
            "98/110, train_loss: 0.0048\n",
            "99/110, train_loss: 0.0085\n",
            "100/110, train_loss: 0.0053\n",
            "101/110, train_loss: 0.0111\n",
            "102/110, train_loss: 0.0054\n",
            "103/110, train_loss: 0.0054\n",
            "104/110, train_loss: 0.0045\n",
            "105/110, train_loss: 0.0048\n",
            "106/110, train_loss: 0.0043\n",
            "107/110, train_loss: 0.0047\n",
            "108/110, train_loss: 0.0103\n",
            "109/110, train_loss: 0.0043\n",
            "110/110, train_loss: 0.0049\n",
            "epoch 93 average loss: 0.0053\n",
            "current epoch: 93 current accuracy: 0.7857 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 94/100\n",
            "1/110, train_loss: 0.0053\n",
            "2/110, train_loss: 0.0060\n",
            "3/110, train_loss: 0.0078\n",
            "4/110, train_loss: 0.0066\n",
            "5/110, train_loss: 0.0045\n",
            "6/110, train_loss: 0.0039\n",
            "7/110, train_loss: 0.0041\n",
            "8/110, train_loss: 0.0040\n",
            "9/110, train_loss: 0.0038\n",
            "10/110, train_loss: 0.0050\n",
            "11/110, train_loss: 0.0056\n",
            "12/110, train_loss: 0.0038\n",
            "13/110, train_loss: 0.0039\n",
            "14/110, train_loss: 0.0041\n",
            "15/110, train_loss: 0.0107\n",
            "16/110, train_loss: 0.0056\n",
            "17/110, train_loss: 0.0040\n",
            "18/110, train_loss: 0.0039\n",
            "19/110, train_loss: 0.0042\n",
            "20/110, train_loss: 0.0046\n",
            "21/110, train_loss: 0.0037\n",
            "22/110, train_loss: 0.0046\n",
            "23/110, train_loss: 0.0053\n",
            "24/110, train_loss: 0.0037\n",
            "25/110, train_loss: 0.0048\n",
            "26/110, train_loss: 0.0056\n",
            "27/110, train_loss: 0.0036\n",
            "28/110, train_loss: 0.0048\n",
            "29/110, train_loss: 0.0158\n",
            "30/110, train_loss: 0.0055\n",
            "31/110, train_loss: 0.0045\n",
            "32/110, train_loss: 0.0044\n",
            "33/110, train_loss: 0.0046\n",
            "34/110, train_loss: 0.0048\n",
            "35/110, train_loss: 0.0049\n",
            "36/110, train_loss: 0.0058\n",
            "37/110, train_loss: 0.0059\n",
            "38/110, train_loss: 0.0045\n",
            "39/110, train_loss: 0.0057\n",
            "40/110, train_loss: 0.0046\n",
            "41/110, train_loss: 0.0046\n",
            "42/110, train_loss: 0.0058\n",
            "43/110, train_loss: 0.0067\n",
            "44/110, train_loss: 0.0039\n",
            "45/110, train_loss: 0.0038\n",
            "46/110, train_loss: 0.0066\n",
            "47/110, train_loss: 0.0047\n",
            "48/110, train_loss: 0.0039\n",
            "49/110, train_loss: 0.0061\n",
            "50/110, train_loss: 0.0050\n",
            "51/110, train_loss: 0.0037\n",
            "52/110, train_loss: 0.0046\n",
            "53/110, train_loss: 0.0042\n",
            "54/110, train_loss: 0.0036\n",
            "55/110, train_loss: 0.0043\n",
            "56/110, train_loss: 0.0041\n",
            "57/110, train_loss: 0.0080\n",
            "58/110, train_loss: 0.0038\n",
            "59/110, train_loss: 0.0048\n",
            "60/110, train_loss: 0.0052\n",
            "61/110, train_loss: 0.0041\n",
            "62/110, train_loss: 0.0052\n",
            "63/110, train_loss: 0.0037\n",
            "64/110, train_loss: 0.0051\n",
            "65/110, train_loss: 0.0050\n",
            "66/110, train_loss: 0.0038\n",
            "67/110, train_loss: 0.0045\n",
            "68/110, train_loss: 0.0049\n",
            "69/110, train_loss: 0.0099\n",
            "70/110, train_loss: 0.0052\n",
            "71/110, train_loss: 0.0036\n",
            "72/110, train_loss: 0.0051\n",
            "73/110, train_loss: 0.0052\n",
            "74/110, train_loss: 0.0040\n",
            "75/110, train_loss: 0.0049\n",
            "76/110, train_loss: 0.0048\n",
            "77/110, train_loss: 0.0078\n",
            "78/110, train_loss: 0.0051\n",
            "79/110, train_loss: 0.0046\n",
            "80/110, train_loss: 0.0040\n",
            "81/110, train_loss: 0.0041\n",
            "82/110, train_loss: 0.0057\n",
            "83/110, train_loss: 0.0045\n",
            "84/110, train_loss: 0.0047\n",
            "85/110, train_loss: 0.0052\n",
            "86/110, train_loss: 0.0042\n",
            "87/110, train_loss: 0.0043\n",
            "88/110, train_loss: 0.0036\n",
            "89/110, train_loss: 0.0068\n",
            "90/110, train_loss: 0.0052\n",
            "91/110, train_loss: 0.0038\n",
            "92/110, train_loss: 0.0036\n",
            "93/110, train_loss: 0.0044\n",
            "94/110, train_loss: 0.0051\n",
            "95/110, train_loss: 0.0041\n",
            "96/110, train_loss: 0.0046\n",
            "97/110, train_loss: 0.0050\n",
            "98/110, train_loss: 0.0036\n",
            "99/110, train_loss: 0.0071\n",
            "100/110, train_loss: 0.0047\n",
            "101/110, train_loss: 0.0038\n",
            "102/110, train_loss: 0.0037\n",
            "103/110, train_loss: 0.0048\n",
            "104/110, train_loss: 0.0081\n",
            "105/110, train_loss: 0.0057\n",
            "106/110, train_loss: 0.0067\n",
            "107/110, train_loss: 0.0045\n",
            "108/110, train_loss: 0.0037\n",
            "109/110, train_loss: 0.0042\n",
            "110/110, train_loss: 0.0055\n",
            "epoch 94 average loss: 0.0050\n",
            "----------\n",
            "epoch 95/100\n",
            "1/110, train_loss: 0.0056\n",
            "2/110, train_loss: 0.0049\n",
            "3/110, train_loss: 0.0050\n",
            "4/110, train_loss: 0.0045\n",
            "5/110, train_loss: 0.0035\n",
            "6/110, train_loss: 0.0043\n",
            "7/110, train_loss: 0.0044\n",
            "8/110, train_loss: 0.0036\n",
            "9/110, train_loss: 0.0040\n",
            "10/110, train_loss: 0.0047\n",
            "11/110, train_loss: 0.0043\n",
            "12/110, train_loss: 0.0034\n",
            "13/110, train_loss: 0.0074\n",
            "14/110, train_loss: 0.0045\n",
            "15/110, train_loss: 0.0036\n",
            "16/110, train_loss: 0.0037\n",
            "17/110, train_loss: 0.0055\n",
            "18/110, train_loss: 0.0045\n",
            "19/110, train_loss: 0.0035\n",
            "20/110, train_loss: 0.0160\n",
            "21/110, train_loss: 0.0053\n",
            "22/110, train_loss: 0.0062\n",
            "23/110, train_loss: 0.0035\n",
            "24/110, train_loss: 0.0049\n",
            "25/110, train_loss: 0.0043\n",
            "26/110, train_loss: 0.0059\n",
            "27/110, train_loss: 0.0070\n",
            "28/110, train_loss: 0.0047\n",
            "29/110, train_loss: 0.0075\n",
            "30/110, train_loss: 0.0048\n",
            "31/110, train_loss: 0.0046\n",
            "32/110, train_loss: 0.0041\n",
            "33/110, train_loss: 0.0035\n",
            "34/110, train_loss: 0.0045\n",
            "35/110, train_loss: 0.0038\n",
            "36/110, train_loss: 0.0042\n",
            "37/110, train_loss: 0.0037\n",
            "38/110, train_loss: 0.0041\n",
            "39/110, train_loss: 0.0047\n",
            "40/110, train_loss: 0.0044\n",
            "41/110, train_loss: 0.0036\n",
            "42/110, train_loss: 0.0046\n",
            "43/110, train_loss: 0.0044\n",
            "44/110, train_loss: 0.0054\n",
            "45/110, train_loss: 0.0048\n",
            "46/110, train_loss: 0.0036\n",
            "47/110, train_loss: 0.0037\n",
            "48/110, train_loss: 0.0053\n",
            "49/110, train_loss: 0.0041\n",
            "50/110, train_loss: 0.0048\n",
            "51/110, train_loss: 0.0039\n",
            "52/110, train_loss: 0.0044\n",
            "53/110, train_loss: 0.0035\n",
            "54/110, train_loss: 0.0045\n",
            "55/110, train_loss: 0.0065\n",
            "56/110, train_loss: 0.0047\n",
            "57/110, train_loss: 0.0093\n",
            "58/110, train_loss: 0.0050\n",
            "59/110, train_loss: 0.0045\n",
            "60/110, train_loss: 0.0041\n",
            "61/110, train_loss: 0.0051\n",
            "62/110, train_loss: 0.0044\n",
            "63/110, train_loss: 0.0037\n",
            "64/110, train_loss: 0.0042\n",
            "65/110, train_loss: 0.0047\n",
            "66/110, train_loss: 0.0035\n",
            "67/110, train_loss: 0.0046\n",
            "68/110, train_loss: 0.0045\n",
            "69/110, train_loss: 0.0037\n",
            "70/110, train_loss: 0.0052\n",
            "71/110, train_loss: 0.0060\n",
            "72/110, train_loss: 0.0041\n",
            "73/110, train_loss: 0.0056\n",
            "74/110, train_loss: 0.0047\n",
            "75/110, train_loss: 0.0040\n",
            "76/110, train_loss: 0.0039\n",
            "77/110, train_loss: 0.0037\n",
            "78/110, train_loss: 0.0045\n",
            "79/110, train_loss: 0.0044\n",
            "80/110, train_loss: 0.0042\n",
            "81/110, train_loss: 0.0051\n",
            "82/110, train_loss: 0.0048\n",
            "83/110, train_loss: 0.0050\n",
            "84/110, train_loss: 0.0079\n",
            "85/110, train_loss: 0.0039\n",
            "86/110, train_loss: 0.0054\n",
            "87/110, train_loss: 0.0077\n",
            "88/110, train_loss: 0.0049\n",
            "89/110, train_loss: 0.0045\n",
            "90/110, train_loss: 0.0036\n",
            "91/110, train_loss: 0.0037\n",
            "92/110, train_loss: 0.0052\n",
            "93/110, train_loss: 0.0037\n",
            "94/110, train_loss: 0.0048\n",
            "95/110, train_loss: 0.0036\n",
            "96/110, train_loss: 0.0041\n",
            "97/110, train_loss: 0.0038\n",
            "98/110, train_loss: 0.0044\n",
            "99/110, train_loss: 0.0035\n",
            "100/110, train_loss: 0.0037\n",
            "101/110, train_loss: 0.0038\n",
            "102/110, train_loss: 0.0038\n",
            "103/110, train_loss: 0.0064\n",
            "104/110, train_loss: 0.0099\n",
            "105/110, train_loss: 0.0037\n",
            "106/110, train_loss: 0.0050\n",
            "107/110, train_loss: 0.0059\n",
            "108/110, train_loss: 0.0042\n",
            "109/110, train_loss: 0.0052\n",
            "110/110, train_loss: 0.0035\n",
            "epoch 95 average loss: 0.0048\n",
            "----------\n",
            "epoch 96/100\n",
            "1/110, train_loss: 0.0054\n",
            "2/110, train_loss: 0.0045\n",
            "3/110, train_loss: 0.0034\n",
            "4/110, train_loss: 0.0037\n",
            "5/110, train_loss: 0.0039\n",
            "6/110, train_loss: 0.0047\n",
            "7/110, train_loss: 0.0047\n",
            "8/110, train_loss: 0.0092\n",
            "9/110, train_loss: 0.0043\n",
            "10/110, train_loss: 0.0051\n",
            "11/110, train_loss: 0.0071\n",
            "12/110, train_loss: 0.0034\n",
            "13/110, train_loss: 0.0034\n",
            "14/110, train_loss: 0.0034\n",
            "15/110, train_loss: 0.0050\n",
            "16/110, train_loss: 0.0033\n",
            "17/110, train_loss: 0.0041\n",
            "18/110, train_loss: 0.0039\n",
            "19/110, train_loss: 0.0062\n",
            "20/110, train_loss: 0.0043\n",
            "21/110, train_loss: 0.0036\n",
            "22/110, train_loss: 0.0045\n",
            "23/110, train_loss: 0.0049\n",
            "24/110, train_loss: 0.0041\n",
            "25/110, train_loss: 0.0034\n",
            "26/110, train_loss: 0.0045\n",
            "27/110, train_loss: 0.0034\n",
            "28/110, train_loss: 0.0039\n",
            "29/110, train_loss: 0.0041\n",
            "30/110, train_loss: 0.0053\n",
            "31/110, train_loss: 0.0057\n",
            "32/110, train_loss: 0.0038\n",
            "33/110, train_loss: 0.0059\n",
            "34/110, train_loss: 0.0043\n",
            "35/110, train_loss: 0.0044\n",
            "36/110, train_loss: 0.0046\n",
            "37/110, train_loss: 0.0037\n",
            "38/110, train_loss: 0.0050\n",
            "39/110, train_loss: 0.0047\n",
            "40/110, train_loss: 0.0046\n",
            "41/110, train_loss: 0.0041\n",
            "42/110, train_loss: 0.0046\n",
            "43/110, train_loss: 0.0052\n",
            "44/110, train_loss: 0.0040\n",
            "45/110, train_loss: 0.0050\n",
            "46/110, train_loss: 0.0034\n",
            "47/110, train_loss: 0.0036\n",
            "48/110, train_loss: 0.0035\n",
            "49/110, train_loss: 0.0048\n",
            "50/110, train_loss: 0.0033\n",
            "51/110, train_loss: 0.0069\n",
            "52/110, train_loss: 0.0036\n",
            "53/110, train_loss: 0.0042\n",
            "54/110, train_loss: 0.0041\n",
            "55/110, train_loss: 0.0037\n",
            "56/110, train_loss: 0.0038\n",
            "57/110, train_loss: 0.0047\n",
            "58/110, train_loss: 0.0040\n",
            "59/110, train_loss: 0.0073\n",
            "60/110, train_loss: 0.0094\n",
            "61/110, train_loss: 0.0044\n",
            "62/110, train_loss: 0.0045\n",
            "63/110, train_loss: 0.0033\n",
            "64/110, train_loss: 0.0046\n",
            "65/110, train_loss: 0.0035\n",
            "66/110, train_loss: 0.0033\n",
            "67/110, train_loss: 0.0045\n",
            "68/110, train_loss: 0.0037\n",
            "69/110, train_loss: 0.0036\n",
            "70/110, train_loss: 0.0036\n",
            "71/110, train_loss: 0.0050\n",
            "72/110, train_loss: 0.0041\n",
            "73/110, train_loss: 0.0044\n",
            "74/110, train_loss: 0.0055\n",
            "75/110, train_loss: 0.0036\n",
            "76/110, train_loss: 0.0060\n",
            "77/110, train_loss: 0.0141\n",
            "78/110, train_loss: 0.0070\n",
            "79/110, train_loss: 0.0037\n",
            "80/110, train_loss: 0.0044\n",
            "81/110, train_loss: 0.0042\n",
            "82/110, train_loss: 0.0039\n",
            "83/110, train_loss: 0.0046\n",
            "84/110, train_loss: 0.0043\n",
            "85/110, train_loss: 0.0040\n",
            "86/110, train_loss: 0.0034\n",
            "87/110, train_loss: 0.0034\n",
            "88/110, train_loss: 0.0032\n",
            "89/110, train_loss: 0.0033\n",
            "90/110, train_loss: 0.0068\n",
            "91/110, train_loss: 0.0047\n",
            "92/110, train_loss: 0.0034\n",
            "93/110, train_loss: 0.0033\n",
            "94/110, train_loss: 0.0051\n",
            "95/110, train_loss: 0.0034\n",
            "96/110, train_loss: 0.0041\n",
            "97/110, train_loss: 0.0051\n",
            "98/110, train_loss: 0.0050\n",
            "99/110, train_loss: 0.0033\n",
            "100/110, train_loss: 0.0059\n",
            "101/110, train_loss: 0.0033\n",
            "102/110, train_loss: 0.0042\n",
            "103/110, train_loss: 0.0040\n",
            "104/110, train_loss: 0.0034\n",
            "105/110, train_loss: 0.0041\n",
            "106/110, train_loss: 0.0042\n",
            "107/110, train_loss: 0.0031\n",
            "108/110, train_loss: 0.0048\n",
            "109/110, train_loss: 0.0042\n",
            "110/110, train_loss: 0.0045\n",
            "epoch 96 average loss: 0.0045\n",
            "current epoch: 96 current accuracy: 0.7143 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 97/100\n",
            "1/110, train_loss: 0.0039\n",
            "2/110, train_loss: 0.0046\n",
            "3/110, train_loss: 0.0033\n",
            "4/110, train_loss: 0.0031\n",
            "5/110, train_loss: 0.0039\n",
            "6/110, train_loss: 0.0036\n",
            "7/110, train_loss: 0.0041\n",
            "8/110, train_loss: 0.0040\n",
            "9/110, train_loss: 0.0043\n",
            "10/110, train_loss: 0.0041\n",
            "11/110, train_loss: 0.0043\n",
            "12/110, train_loss: 0.0041\n",
            "13/110, train_loss: 0.0039\n",
            "14/110, train_loss: 0.0033\n",
            "15/110, train_loss: 0.0039\n",
            "16/110, train_loss: 0.0040\n",
            "17/110, train_loss: 0.0047\n",
            "18/110, train_loss: 0.0053\n",
            "19/110, train_loss: 0.0047\n",
            "20/110, train_loss: 0.0031\n",
            "21/110, train_loss: 0.0068\n",
            "22/110, train_loss: 0.0048\n",
            "23/110, train_loss: 0.0032\n",
            "24/110, train_loss: 0.0044\n",
            "25/110, train_loss: 0.0045\n",
            "26/110, train_loss: 0.0058\n",
            "27/110, train_loss: 0.0037\n",
            "28/110, train_loss: 0.0032\n",
            "29/110, train_loss: 0.0033\n",
            "30/110, train_loss: 0.0043\n",
            "31/110, train_loss: 0.0033\n",
            "32/110, train_loss: 0.0039\n",
            "33/110, train_loss: 0.0032\n",
            "34/110, train_loss: 0.0060\n",
            "35/110, train_loss: 0.0032\n",
            "36/110, train_loss: 0.0033\n",
            "37/110, train_loss: 0.0035\n",
            "38/110, train_loss: 0.0034\n",
            "39/110, train_loss: 0.0049\n",
            "40/110, train_loss: 0.0054\n",
            "41/110, train_loss: 0.0042\n",
            "42/110, train_loss: 0.0035\n",
            "43/110, train_loss: 0.0046\n",
            "44/110, train_loss: 0.0088\n",
            "45/110, train_loss: 0.0033\n",
            "46/110, train_loss: 0.0040\n",
            "47/110, train_loss: 0.0044\n",
            "48/110, train_loss: 0.0042\n",
            "49/110, train_loss: 0.0043\n",
            "50/110, train_loss: 0.0038\n",
            "51/110, train_loss: 0.0048\n",
            "52/110, train_loss: 0.0044\n",
            "53/110, train_loss: 0.0051\n",
            "54/110, train_loss: 0.0087\n",
            "55/110, train_loss: 0.0068\n",
            "56/110, train_loss: 0.0038\n",
            "57/110, train_loss: 0.0056\n",
            "58/110, train_loss: 0.0043\n",
            "59/110, train_loss: 0.0048\n",
            "60/110, train_loss: 0.0038\n",
            "61/110, train_loss: 0.0034\n",
            "62/110, train_loss: 0.0055\n",
            "63/110, train_loss: 0.0034\n",
            "64/110, train_loss: 0.0044\n",
            "65/110, train_loss: 0.0035\n",
            "66/110, train_loss: 0.0030\n",
            "67/110, train_loss: 0.0041\n",
            "68/110, train_loss: 0.0063\n",
            "69/110, train_loss: 0.0128\n",
            "70/110, train_loss: 0.0033\n",
            "71/110, train_loss: 0.0031\n",
            "72/110, train_loss: 0.0039\n",
            "73/110, train_loss: 0.0034\n",
            "74/110, train_loss: 0.0034\n",
            "75/110, train_loss: 0.0031\n",
            "76/110, train_loss: 0.0041\n",
            "77/110, train_loss: 0.0049\n",
            "78/110, train_loss: 0.0031\n",
            "79/110, train_loss: 0.0052\n",
            "80/110, train_loss: 0.0068\n",
            "81/110, train_loss: 0.0045\n",
            "82/110, train_loss: 0.0041\n",
            "83/110, train_loss: 0.0049\n",
            "84/110, train_loss: 0.0068\n",
            "85/110, train_loss: 0.0040\n",
            "86/110, train_loss: 0.0032\n",
            "87/110, train_loss: 0.0036\n",
            "88/110, train_loss: 0.0032\n",
            "89/110, train_loss: 0.0036\n",
            "90/110, train_loss: 0.0036\n",
            "91/110, train_loss: 0.0043\n",
            "92/110, train_loss: 0.0044\n",
            "93/110, train_loss: 0.0034\n",
            "94/110, train_loss: 0.0032\n",
            "95/110, train_loss: 0.0043\n",
            "96/110, train_loss: 0.0039\n",
            "97/110, train_loss: 0.0048\n",
            "98/110, train_loss: 0.0034\n",
            "99/110, train_loss: 0.0048\n",
            "100/110, train_loss: 0.0030\n",
            "101/110, train_loss: 0.0043\n",
            "102/110, train_loss: 0.0048\n",
            "103/110, train_loss: 0.0031\n",
            "104/110, train_loss: 0.0042\n",
            "105/110, train_loss: 0.0032\n",
            "106/110, train_loss: 0.0044\n",
            "107/110, train_loss: 0.0038\n",
            "108/110, train_loss: 0.0032\n",
            "109/110, train_loss: 0.0037\n",
            "110/110, train_loss: 0.0031\n",
            "epoch 97 average loss: 0.0043\n",
            "----------\n",
            "epoch 98/100\n",
            "1/110, train_loss: 0.0039\n",
            "2/110, train_loss: 0.0064\n",
            "3/110, train_loss: 0.0038\n",
            "4/110, train_loss: 0.0034\n",
            "5/110, train_loss: 0.0034\n",
            "6/110, train_loss: 0.0030\n",
            "7/110, train_loss: 0.0045\n",
            "8/110, train_loss: 0.0033\n",
            "9/110, train_loss: 0.0042\n",
            "10/110, train_loss: 0.0031\n",
            "11/110, train_loss: 0.0030\n",
            "12/110, train_loss: 0.0030\n",
            "13/110, train_loss: 0.0040\n",
            "14/110, train_loss: 0.0037\n",
            "15/110, train_loss: 0.0031\n",
            "16/110, train_loss: 0.0030\n",
            "17/110, train_loss: 0.0038\n",
            "18/110, train_loss: 0.0041\n",
            "19/110, train_loss: 0.0034\n",
            "20/110, train_loss: 0.0031\n",
            "21/110, train_loss: 0.0033\n",
            "22/110, train_loss: 0.0032\n",
            "23/110, train_loss: 0.0040\n",
            "24/110, train_loss: 0.0082\n",
            "25/110, train_loss: 0.0038\n",
            "26/110, train_loss: 0.0131\n",
            "27/110, train_loss: 0.0041\n",
            "28/110, train_loss: 0.0053\n",
            "29/110, train_loss: 0.0045\n",
            "30/110, train_loss: 0.0046\n",
            "31/110, train_loss: 0.0041\n",
            "32/110, train_loss: 0.0043\n",
            "33/110, train_loss: 0.0031\n",
            "34/110, train_loss: 0.0035\n",
            "35/110, train_loss: 0.0029\n",
            "36/110, train_loss: 0.0030\n",
            "37/110, train_loss: 0.0029\n",
            "38/110, train_loss: 0.0032\n",
            "39/110, train_loss: 0.0052\n",
            "40/110, train_loss: 0.0045\n",
            "41/110, train_loss: 0.0049\n",
            "42/110, train_loss: 0.0052\n",
            "43/110, train_loss: 0.0047\n",
            "44/110, train_loss: 0.0044\n",
            "45/110, train_loss: 0.0043\n",
            "46/110, train_loss: 0.0046\n",
            "47/110, train_loss: 0.0044\n",
            "48/110, train_loss: 0.0040\n",
            "49/110, train_loss: 0.0066\n",
            "50/110, train_loss: 0.0036\n",
            "51/110, train_loss: 0.0040\n",
            "52/110, train_loss: 0.0035\n",
            "53/110, train_loss: 0.0044\n",
            "54/110, train_loss: 0.0030\n",
            "55/110, train_loss: 0.0028\n",
            "56/110, train_loss: 0.0057\n",
            "57/110, train_loss: 0.0047\n",
            "58/110, train_loss: 0.0030\n",
            "59/110, train_loss: 0.0030\n",
            "60/110, train_loss: 0.0030\n",
            "61/110, train_loss: 0.0036\n",
            "62/110, train_loss: 0.0030\n",
            "63/110, train_loss: 0.0042\n",
            "64/110, train_loss: 0.0051\n",
            "65/110, train_loss: 0.0046\n",
            "66/110, train_loss: 0.0029\n",
            "67/110, train_loss: 0.0046\n",
            "68/110, train_loss: 0.0033\n",
            "69/110, train_loss: 0.0028\n",
            "70/110, train_loss: 0.0031\n",
            "71/110, train_loss: 0.0032\n",
            "72/110, train_loss: 0.0036\n",
            "73/110, train_loss: 0.0045\n",
            "74/110, train_loss: 0.0049\n",
            "75/110, train_loss: 0.0061\n",
            "76/110, train_loss: 0.0030\n",
            "77/110, train_loss: 0.0031\n",
            "78/110, train_loss: 0.0037\n",
            "79/110, train_loss: 0.0046\n",
            "80/110, train_loss: 0.0032\n",
            "81/110, train_loss: 0.0064\n",
            "82/110, train_loss: 0.0038\n",
            "83/110, train_loss: 0.0033\n",
            "84/110, train_loss: 0.0040\n",
            "85/110, train_loss: 0.0030\n",
            "86/110, train_loss: 0.0040\n",
            "87/110, train_loss: 0.0039\n",
            "88/110, train_loss: 0.0035\n",
            "89/110, train_loss: 0.0057\n",
            "90/110, train_loss: 0.0037\n",
            "91/110, train_loss: 0.0050\n",
            "92/110, train_loss: 0.0083\n",
            "93/110, train_loss: 0.0041\n",
            "94/110, train_loss: 0.0039\n",
            "95/110, train_loss: 0.0031\n",
            "96/110, train_loss: 0.0029\n",
            "97/110, train_loss: 0.0037\n",
            "98/110, train_loss: 0.0034\n",
            "99/110, train_loss: 0.0039\n",
            "100/110, train_loss: 0.0046\n",
            "101/110, train_loss: 0.0042\n",
            "102/110, train_loss: 0.0042\n",
            "103/110, train_loss: 0.0043\n",
            "104/110, train_loss: 0.0063\n",
            "105/110, train_loss: 0.0048\n",
            "106/110, train_loss: 0.0029\n",
            "107/110, train_loss: 0.0036\n",
            "108/110, train_loss: 0.0038\n",
            "109/110, train_loss: 0.0034\n",
            "110/110, train_loss: 0.0028\n",
            "epoch 98 average loss: 0.0041\n",
            "----------\n",
            "epoch 99/100\n",
            "1/110, train_loss: 0.0053\n",
            "2/110, train_loss: 0.0044\n",
            "3/110, train_loss: 0.0029\n",
            "4/110, train_loss: 0.0029\n",
            "5/110, train_loss: 0.0030\n",
            "6/110, train_loss: 0.0044\n",
            "7/110, train_loss: 0.0039\n",
            "8/110, train_loss: 0.0040\n",
            "9/110, train_loss: 0.0038\n",
            "10/110, train_loss: 0.0035\n",
            "11/110, train_loss: 0.0032\n",
            "12/110, train_loss: 0.0040\n",
            "13/110, train_loss: 0.0038\n",
            "14/110, train_loss: 0.0029\n",
            "15/110, train_loss: 0.0035\n",
            "16/110, train_loss: 0.0030\n",
            "17/110, train_loss: 0.0051\n",
            "18/110, train_loss: 0.0028\n",
            "19/110, train_loss: 0.0037\n",
            "20/110, train_loss: 0.0043\n",
            "21/110, train_loss: 0.0035\n",
            "22/110, train_loss: 0.0029\n",
            "23/110, train_loss: 0.0031\n",
            "24/110, train_loss: 0.0035\n",
            "25/110, train_loss: 0.0028\n",
            "26/110, train_loss: 0.0041\n",
            "27/110, train_loss: 0.0036\n",
            "28/110, train_loss: 0.0029\n",
            "29/110, train_loss: 0.0035\n",
            "30/110, train_loss: 0.0029\n",
            "31/110, train_loss: 0.0060\n",
            "32/110, train_loss: 0.0040\n",
            "33/110, train_loss: 0.0032\n",
            "34/110, train_loss: 0.0032\n",
            "35/110, train_loss: 0.0040\n",
            "36/110, train_loss: 0.0031\n",
            "37/110, train_loss: 0.0040\n",
            "38/110, train_loss: 0.0044\n",
            "39/110, train_loss: 0.0037\n",
            "40/110, train_loss: 0.0034\n",
            "41/110, train_loss: 0.0117\n",
            "42/110, train_loss: 0.0049\n",
            "43/110, train_loss: 0.0030\n",
            "44/110, train_loss: 0.0029\n",
            "45/110, train_loss: 0.0042\n",
            "46/110, train_loss: 0.0033\n",
            "47/110, train_loss: 0.0040\n",
            "48/110, train_loss: 0.0036\n",
            "49/110, train_loss: 0.0040\n",
            "50/110, train_loss: 0.0045\n",
            "51/110, train_loss: 0.0037\n",
            "52/110, train_loss: 0.0034\n",
            "53/110, train_loss: 0.0039\n",
            "54/110, train_loss: 0.0057\n",
            "55/110, train_loss: 0.0039\n",
            "56/110, train_loss: 0.0033\n",
            "57/110, train_loss: 0.0038\n",
            "58/110, train_loss: 0.0046\n",
            "59/110, train_loss: 0.0033\n",
            "60/110, train_loss: 0.0032\n",
            "61/110, train_loss: 0.0028\n",
            "62/110, train_loss: 0.0035\n",
            "63/110, train_loss: 0.0028\n",
            "64/110, train_loss: 0.0051\n",
            "65/110, train_loss: 0.0046\n",
            "66/110, train_loss: 0.0032\n",
            "67/110, train_loss: 0.0039\n",
            "68/110, train_loss: 0.0029\n",
            "69/110, train_loss: 0.0028\n",
            "70/110, train_loss: 0.0028\n",
            "71/110, train_loss: 0.0035\n",
            "72/110, train_loss: 0.0032\n",
            "73/110, train_loss: 0.0039\n",
            "74/110, train_loss: 0.0027\n",
            "75/110, train_loss: 0.0045\n",
            "76/110, train_loss: 0.0028\n",
            "77/110, train_loss: 0.0037\n",
            "78/110, train_loss: 0.0060\n",
            "79/110, train_loss: 0.0029\n",
            "80/110, train_loss: 0.0047\n",
            "81/110, train_loss: 0.0042\n",
            "82/110, train_loss: 0.0035\n",
            "83/110, train_loss: 0.0054\n",
            "84/110, train_loss: 0.0029\n",
            "85/110, train_loss: 0.0030\n",
            "86/110, train_loss: 0.0036\n",
            "87/110, train_loss: 0.0037\n",
            "88/110, train_loss: 0.0031\n",
            "89/110, train_loss: 0.0078\n",
            "90/110, train_loss: 0.0042\n",
            "91/110, train_loss: 0.0039\n",
            "92/110, train_loss: 0.0036\n",
            "93/110, train_loss: 0.0030\n",
            "94/110, train_loss: 0.0034\n",
            "95/110, train_loss: 0.0031\n",
            "96/110, train_loss: 0.0037\n",
            "97/110, train_loss: 0.0035\n",
            "98/110, train_loss: 0.0029\n",
            "99/110, train_loss: 0.0028\n",
            "100/110, train_loss: 0.0043\n",
            "101/110, train_loss: 0.0043\n",
            "102/110, train_loss: 0.0040\n",
            "103/110, train_loss: 0.0029\n",
            "104/110, train_loss: 0.0028\n",
            "105/110, train_loss: 0.0061\n",
            "106/110, train_loss: 0.0060\n",
            "107/110, train_loss: 0.0078\n",
            "108/110, train_loss: 0.0039\n",
            "109/110, train_loss: 0.0041\n",
            "110/110, train_loss: 0.0042\n",
            "epoch 99 average loss: 0.0039\n",
            "current epoch: 99 current accuracy: 0.7857 best accuracy: 0.9286 at epoch 33\n",
            "----------\n",
            "epoch 100/100\n",
            "1/110, train_loss: 0.0031\n",
            "2/110, train_loss: 0.0035\n",
            "3/110, train_loss: 0.0042\n",
            "4/110, train_loss: 0.0027\n",
            "5/110, train_loss: 0.0031\n",
            "6/110, train_loss: 0.0049\n",
            "7/110, train_loss: 0.0051\n",
            "8/110, train_loss: 0.0057\n",
            "9/110, train_loss: 0.0034\n",
            "10/110, train_loss: 0.0050\n",
            "11/110, train_loss: 0.0040\n",
            "12/110, train_loss: 0.0029\n",
            "13/110, train_loss: 0.0038\n",
            "14/110, train_loss: 0.0047\n",
            "15/110, train_loss: 0.0029\n",
            "16/110, train_loss: 0.0028\n",
            "17/110, train_loss: 0.0053\n",
            "18/110, train_loss: 0.0028\n",
            "19/110, train_loss: 0.0039\n",
            "20/110, train_loss: 0.0037\n",
            "21/110, train_loss: 0.0028\n",
            "22/110, train_loss: 0.0035\n",
            "23/110, train_loss: 0.0036\n",
            "24/110, train_loss: 0.0028\n",
            "25/110, train_loss: 0.0028\n",
            "26/110, train_loss: 0.0039\n",
            "27/110, train_loss: 0.0034\n",
            "28/110, train_loss: 0.0038\n",
            "29/110, train_loss: 0.0036\n",
            "30/110, train_loss: 0.0038\n",
            "31/110, train_loss: 0.0036\n",
            "32/110, train_loss: 0.0035\n",
            "33/110, train_loss: 0.0036\n",
            "34/110, train_loss: 0.0037\n",
            "35/110, train_loss: 0.0028\n",
            "36/110, train_loss: 0.0060\n",
            "37/110, train_loss: 0.0040\n",
            "38/110, train_loss: 0.0032\n",
            "39/110, train_loss: 0.0031\n",
            "40/110, train_loss: 0.0043\n",
            "41/110, train_loss: 0.0029\n",
            "42/110, train_loss: 0.0043\n",
            "43/110, train_loss: 0.0035\n",
            "44/110, train_loss: 0.0033\n",
            "45/110, train_loss: 0.0028\n",
            "46/110, train_loss: 0.0033\n",
            "47/110, train_loss: 0.0041\n",
            "48/110, train_loss: 0.0037\n",
            "49/110, train_loss: 0.0036\n",
            "50/110, train_loss: 0.0032\n",
            "51/110, train_loss: 0.0034\n",
            "52/110, train_loss: 0.0034\n",
            "53/110, train_loss: 0.0030\n",
            "54/110, train_loss: 0.0037\n",
            "55/110, train_loss: 0.0027\n",
            "56/110, train_loss: 0.0033\n",
            "57/110, train_loss: 0.0029\n",
            "58/110, train_loss: 0.0034\n",
            "59/110, train_loss: 0.0030\n",
            "60/110, train_loss: 0.0030\n",
            "61/110, train_loss: 0.0028\n",
            "62/110, train_loss: 0.0034\n",
            "63/110, train_loss: 0.0033\n",
            "64/110, train_loss: 0.0027\n",
            "65/110, train_loss: 0.0040\n",
            "66/110, train_loss: 0.0037\n",
            "67/110, train_loss: 0.0034\n",
            "68/110, train_loss: 0.0072\n",
            "69/110, train_loss: 0.0048\n",
            "70/110, train_loss: 0.0030\n",
            "71/110, train_loss: 0.0040\n",
            "72/110, train_loss: 0.0041\n",
            "73/110, train_loss: 0.0032\n",
            "74/110, train_loss: 0.0031\n",
            "75/110, train_loss: 0.0059\n",
            "76/110, train_loss: 0.0042\n",
            "77/110, train_loss: 0.0030\n",
            "78/110, train_loss: 0.0032\n",
            "79/110, train_loss: 0.0040\n",
            "80/110, train_loss: 0.0038\n",
            "81/110, train_loss: 0.0107\n",
            "82/110, train_loss: 0.0029\n",
            "83/110, train_loss: 0.0026\n",
            "84/110, train_loss: 0.0027\n",
            "85/110, train_loss: 0.0027\n",
            "86/110, train_loss: 0.0045\n",
            "87/110, train_loss: 0.0037\n",
            "88/110, train_loss: 0.0028\n",
            "89/110, train_loss: 0.0033\n",
            "90/110, train_loss: 0.0038\n",
            "91/110, train_loss: 0.0031\n",
            "92/110, train_loss: 0.0031\n",
            "93/110, train_loss: 0.0029\n",
            "94/110, train_loss: 0.0058\n",
            "95/110, train_loss: 0.0078\n",
            "96/110, train_loss: 0.0027\n",
            "97/110, train_loss: 0.0033\n",
            "98/110, train_loss: 0.0028\n",
            "99/110, train_loss: 0.0038\n",
            "100/110, train_loss: 0.0043\n",
            "101/110, train_loss: 0.0034\n",
            "102/110, train_loss: 0.0028\n",
            "103/110, train_loss: 0.0034\n",
            "104/110, train_loss: 0.0037\n",
            "105/110, train_loss: 0.0034\n",
            "106/110, train_loss: 0.0027\n",
            "107/110, train_loss: 0.0026\n",
            "108/110, train_loss: 0.0037\n",
            "109/110, train_loss: 0.0029\n",
            "110/110, train_loss: 0.0042\n",
            "epoch 100 average loss: 0.0037\n",
            "train completed, best_metric: 0.9286 at epoch: 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIsk3v3gKTrB"
      },
      "source": [
        "**Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "-LyP68KcHELg",
        "outputId": "7c972c97-15c7-40a8-db48-a838631606b7"
      },
      "source": [
        "from enum import Enum\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "class Diagnosis(Enum):\n",
        "    Liver_Cirrhosis = 0\n",
        "    Lymphoma = 1\n",
        "    \n",
        "\n",
        "%matplotlib inline\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Spleen_AI/best_metric_model_classification3d_array.pth\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "    y = torch.tensor([], dtype=torch.long, device=device)\n",
        "\n",
        "    for val_data in val_loader:\n",
        "        val_images, val_labels = val_data[0].to(\n",
        "            device), val_data[1].to(device),\n",
        "\n",
        "        outputs = model(val_images)\n",
        "        y_pred = torch.cat([y_pred, outputs.argmax(dim=1)], dim=0)\n",
        "        y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "print(classification_report(\n",
        "    y.cpu().numpy(),\n",
        "    y_pred.cpu().numpy(),\n",
        "    target_names=[d.name for d in Diagnosis]))\n",
        "\n",
        "cm = confusion_matrix (\n",
        "    y.cpu().numpy(),\n",
        "    y_pred.cpu().numpy(),\n",
        "    normalize='true',\n",
        ")\n",
        "cmm = ConfusionMatrixMetric (include_background=True, metric_name=[\"sensitivity\",\"specificity\",\"negative predictive value\"])\n",
        "\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels=[d.name for d in Diagnosis],\n",
        ")\n",
        "disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Liver_Cirrhosis       1.00      0.50      0.67         2\n",
            "       Lymphoma       0.92      1.00      0.96        12\n",
            "\n",
            "       accuracy                           0.93        14\n",
            "      macro avg       0.96      0.75      0.81        14\n",
            "   weighted avg       0.93      0.93      0.92        14\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f373f534850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm0LXsvlgp_N"
      },
      "source": [
        "files = [{\"img\": img} for img in images]\n",
        "post_transforms = Compose([\n",
        "        #Activationsd(keys=\"pred\", sigmoid=True),\n",
        "        #AsDiscreted(keys=\"pred\", threshold_values=True),\n",
        "        Invertd(\n",
        "            keys=\"y_pred\",  # invert the `pred` data field, also support multiple fields\n",
        "            transform=train_transforms,\n",
        "            loader=val_loader,\n",
        "            orig_keys=\"files\",  # get the previously applied pre_transforms information on the `img` data field,\n",
        "                              # then invert `pred` based on this information. we can use same info\n",
        "                              # for multiple fields, also support different orig_keys for different fields\n",
        "            #meta_keys=\"pred_meta_dict\",  # key field to save inverted meta data, every item maps to `keys`\n",
        "            #orig_meta_keys=\"img_meta_dict\",  # get the meta data from `img_meta_dict` field when inverting,\n",
        "                                             # for example, may need the `affine` to invert `Spacingd` transform,\n",
        "                                             # multiple fields can use the same meta data to invert\n",
        "            #meta_key_postfix=\"meta_dict\",  # if `meta_keys=None`, use \"{keys}_{meta_key_postfix}\" as the meta key,\n",
        "                                           # if `orig_meta_keys=None`, use \"{orig_keys}_{meta_key_postfix}\",\n",
        "                                           # otherwise, no need this arg during inverting\n",
        "            nearest_interp=True,  # change to use \"nearest\" mode in interpolation when inverting\n",
        "            to_tensor=True,  # convert to PyTorch Tensor after inverting\n",
        "        ),\n",
        "        #SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"./out\", output_postfix=\"seg\", resample=False),\n",
        "    ])\n",
        "\n",
        "test_ds = ImageDataset(\n",
        "    image_files=files, labels=labels, transform=post_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4)\n",
        "itera = iter(test_loader)\n",
        "\n",
        "\n",
        "def get_next_im():\n",
        "    test_data = next(itera)\n",
        "    return test_data[0].to(device), test_data[1].unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "def plot_occlusion_heatmap(im, heatmap):\n",
        "    plt.subplots(1, 2)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(np.squeeze(im.cpu()))\n",
        "    plt.colorbar()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(heatmap)\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "vfFYizJOg1TG",
        "outputId": "435d1952-82b6-4658-fae4-8d047c4abdd1"
      },
      "source": [
        "# Get a random image and its corresponding label\n",
        "img, label = get_next_im()\n",
        "\n",
        "# Get the occlusion sensitivity map\n",
        "occ_sens = monai.visualize.OcclusionSensitivity(\n",
        "    nn_module=model, mask_size=12, n_batch=10, stride=12)\n",
        "# Get the CAM\n",
        "cam = monai.visualize.GradCAM(\n",
        "    nn_module=model, target_layers=\"class_layers.relu\"\n",
        ")\n",
        "# Only get a single slice to save time.\n",
        "# For the other dimensions (channel, width, height), use\n",
        "# -1 to use 0 and img.shape[x]-1 for min and max, respectively\n",
        "depth_slice = img.shape[2] // 2\n",
        "\n",
        "occ_sens_b_box = [-1, -1, depth_slice, depth_slice, -1, -1, -1, -1]\n",
        "\n",
        "occ_result, _ = occ_sens(x=img, b_box=occ_sens_b_box)\n",
        "occ_result = occ_result[..., label.item()]\n",
        "cam_result = cam(x=img, class_idx=None)\n",
        "cam_result = cam_result[..., depth_slice]\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(25, 15), facecolor='white')\n",
        "\n",
        "for i, im in enumerate([img[:, :, depth_slice, ...], occ_result, cam_result]):\n",
        "    cmap = 'gray' if i == 0 else 'jet'\n",
        "    ax = axes[i]\n",
        "    if isinstance(im, torch.Tensor):\n",
        "        im = im.cpu().detach()    \n",
        "    #im_show = ax.imshow(im[0][0], cmap=cmap)\n",
        "    im_show = ax.imshow(np.squeeze(im[0][0]), cmap=cmap)\n",
        "    ax.axis('off')\n",
        "    fig.colorbar(im_show, ax=ax)\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e9a9acb978e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get a random image and its corresponding label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_im\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get the occlusion sensitivity map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m occ_sens = monai.visualize.OcclusionSensitivity(\n",
            "\u001b[0;32m<ipython-input-40-57f4f754abc3>\u001b[0m in \u001b[0;36mget_next_im\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_next_im\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitera\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/monai/data/image_dataset.py\", line 102, in __getitem__\n    img = self.loader(self.image_files[index])\n  File \"/usr/local/lib/python3.7/dist-packages/monai/transforms/io/array.py\", line 163, in __call__\n    img = reader.read(filename)\n  File \"/usr/local/lib/python3.7/dist-packages/monai/data/image_reader.py\", line 196, in read\n    img_.append(itk.imread(name, **kwargs_))\n  File \"/usr/local/lib/python3.7/dist-packages/itkExtras.py\", line 645, in imread\n    reader = TemplateReaderType.New(**kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/itkTemplate.py\", line 469, in New\n    return self._NewImageReader(itk.ImageFileReader, False, 'FileName', *args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/itkTemplate.py\", line 552, in _NewImageReader\n    raise RuntimeError(\"Could not create IO object for reading file %s\" % inputFileName + msg)\nRuntimeError: Could not create IO object for reading file img\nThe file doesn't exist. \nFilename = img\n"
          ]
        }
      ]
    }
  ]
}