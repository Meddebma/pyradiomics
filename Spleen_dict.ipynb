{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spleen_dict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KxRs6swO8JXLsiB10CDnz6j-SluROoN9",
      "authorship_tag": "ABX9TyOGs4M4GlKdRgHapYrbvFMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meddebma/pyradiomics/blob/master/Spleen_dict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8xY60j1gxdX",
        "outputId": "643a1849-2bd1-41de-c3b7-f52038225c48"
      },
      "source": [
        "%pip install monai==0.3.0\n",
        "#%pip install git+https://github.com/Project-MONAI/MONAI#egg=MONAI\n",
        "%pip install 'monai[all]'\n",
        "%pip install pytorch-ignite\n",
        "%pip install nibabel==3.2.0\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "from glob import glob\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import monai\n",
        "from monai.data import create_test_image_3d, list_data_collate\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    AsChannelFirstd,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadNiftid,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    CropForegroundd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    ScaleIntensityRanged,\n",
        "    RandRotate90d,\n",
        "    ScaleIntensityd,\n",
        "    ToTensord,\n",
        "    AddChanneld,\n",
        "    KeepLargestConnectedComponent, \n",
        "    LabelToContour\n",
        ")\n",
        "from monai.losses import DiceLoss\n",
        "from monai.metrics import compute_meandice\n",
        "from monai.networks.layers import Norm\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.visualize import plot_2d_or_3d_image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting monai==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/47/29473afdd2a90e54b8b11429f8d36b41a74d6d37371ebb50e4de74f42d10/monai-0.3.0-202010042353-py3-none-any.whl (298kB)\n",
            "\r\u001b[K     |█                               | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 10.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 92kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 122kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 133kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 143kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 153kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 163kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 174kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 184kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 194kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 204kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 215kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 225kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 235kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 245kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 256kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 266kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 276kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 286kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 296kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from monai==0.3.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from monai==0.3.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai==0.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai==0.3.0) (0.8)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-0.3.0\n",
            "Requirement already satisfied: monai[all] in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from monai[all]) (1.18.5)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from monai[all]) (1.7.0+cu101)\n",
            "Requirement already satisfied: gdown>=3.6.4; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (3.6.4)\n",
            "Requirement already satisfied: nibabel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (3.0.2)\n",
            "Requirement already satisfied: tensorboard; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (2.3.0)\n",
            "Collecting tqdm>=4.47.0; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/54/115f0c28a61d56674c3a5e05c46d6c3523ad196e1dcd3e2d8b119026df36/tqdm-4.54.1-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (7.0.0)\n",
            "Requirement already satisfied: torchvision; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (0.8.1+cu101)\n",
            "Collecting pytorch-ignite==0.4.2; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/98/0a5b83d82ff245d3de5f09808fb80ff0ed03f6b10933979e6018b1dd0eaa/pytorch_ignite-0.4.2-py2.py3-none-any.whl (175kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 19.2MB/s \n",
            "\u001b[?25hCollecting itk; extra == \"all\"\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/b8/4bd9403620225697b69f288b68ab2d2faa5cc0a0fbc073399bc08a1509bd/itk-5.1.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: scikit-image>=0.14.2; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (0.16.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai[all]) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai[all]) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai[all]) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown>=3.6.4; extra == \"all\"->monai[all]) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown>=3.6.4; extra == \"all\"->monai[all]) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (50.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (0.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (0.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.33.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (3.12.4)\n",
            "Collecting itk-segmentation==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/2d/c51d512e334fd0e2a6158d0626b419ca46cfb6ff8692f8392ca0f6ace30f/itk_segmentation-5.1.2-cp36-cp36m-manylinux1_x86_64.whl (10.3MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3MB 27.6MB/s \n",
            "\u001b[?25hCollecting itk-io==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/6f/d5c48de0399d79ca07c9ed104e4ba292be45533f106a8787a3527b4da69e/itk_io-5.1.2-cp36-cp36m-manylinux1_x86_64.whl (14.0MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0MB 246kB/s \n",
            "\u001b[?25hCollecting itk-core==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/d3/db008ae02fa843b6282a85391b98be8ed97ade8735df1c2071831123a9d4/itk_core-5.1.2-cp36-cp36m-manylinux1_x86_64.whl (50.1MB)\n",
            "\u001b[K     |████████████████████████████████| 50.1MB 63kB/s \n",
            "\u001b[?25hCollecting itk-registration==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/bf/887404bade70466dc5ed1b535c10d9b5941d866cec5e78837bf1632944e4/itk_registration-5.1.2-cp36-cp36m-manylinux1_x86_64.whl (14.4MB)\n",
            "\u001b[K     |████████████████████████████████| 14.4MB 257kB/s \n",
            "\u001b[?25hCollecting itk-numerics==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/75/b08bb69d33ac1e957cbeb37bb0b5632119ac22d40743405013eea618c8bb/itk_numerics-5.1.2-cp36-cp36m-manylinux1_x86_64.whl (36.3MB)\n",
            "\u001b[K     |████████████████████████████████| 36.3MB 95kB/s \n",
            "\u001b[?25hCollecting itk-filtering==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/56/0335bc9c601a9653d8630b92347da60e6843a26f7999ba4d325549f5f159/itk_filtering-5.1.2-cp36-cp36m-manylinux1_x86_64.whl (68.0MB)\n",
            "\u001b[K     |████████████████████████████████| 68.0MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (2.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (1.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard; extra == \"all\"->monai[all]) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"all\"->monai[all]) (1.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard; extra == \"all\"->monai[all]) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"all\"->monai[all]) (3.1.0)\n",
            "Installing collected packages: tqdm, pytorch-ignite, itk-core, itk-numerics, itk-filtering, itk-segmentation, itk-io, itk-registration, itk\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed itk-5.1.2 itk-core-5.1.2 itk-filtering-5.1.2 itk-io-5.1.2 itk-numerics-5.1.2 itk-registration-5.1.2 itk-segmentation-5.1.2 pytorch-ignite-0.4.2 tqdm-4.54.1\n",
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Collecting nibabel==3.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/7f/d3c29792fae50ef4f1f8f87af8a94d5d9fe76550b86ebcf8a251110169d8/nibabel-3.2.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 21.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from nibabel==3.2.0) (1.18.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from nibabel==3.2.0) (20.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->nibabel==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->nibabel==3.2.0) (1.15.0)\n",
            "Installing collected packages: nibabel\n",
            "  Found existing installation: nibabel 3.0.2\n",
            "    Uninstalling nibabel-3.0.2:\n",
            "      Successfully uninstalled nibabel-3.0.2\n",
            "Successfully installed nibabel-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7aBb3wvhao1"
      },
      "source": [
        "\n",
        "\n",
        "# Import Data and Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MugHh3Fhjnm",
        "outputId": "079b98ae-a60c-4697-e5b1-d07ab651a770"
      },
      "source": [
        "root= \"/content/drive/My Drive/Task09_Spleen/\"\n",
        "images = sorted(glob(os.path.join(root, \"imagesTr\",\"*.nii.gz\")))\n",
        "segs = sorted(glob(os.path.join(root, \"labelsTr\", \"*.nii.gz\")))\n",
        "\n",
        "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\n",
        "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]\n",
        "print (len(images))\n",
        "print (len(segs))\n",
        "\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadNiftid(keys=[\"img\", \"seg\"]),\n",
        "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
        "        Spacingd(keys=[\"img\", \"seg\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"img\", \"seg\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"img\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
        "        RandCropByPosNegLabeld(\n",
        "            keys=[\"img\", \"seg\"],\n",
        "            label_key=\"seg\",\n",
        "            spatial_size=(96, 96, 96),\n",
        "            pos=1,\n",
        "            neg=1,\n",
        "            num_samples=4,\n",
        "            image_key=\"img\",\n",
        "            image_threshold=0,\n",
        "        ),\n",
        "        # user can also add other random transforms\n",
        "        # RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=1.0, spatial_size=(96, 96, 96),\n",
        "        #             rotate_range=(0, 0, np.pi/15), scale_range=(0.1, 0.1, 0.1)),\n",
        "        ToTensord(keys=[\"img\", \"seg\"]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadNiftid(keys=[\"img\", \"seg\"]),\n",
        "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
        "        Spacingd(keys=[\"img\", \"seg\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"img\", \"seg\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"img\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
        "        ToTensord(keys=[\"img\", \"seg\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# define dataset, data loader\n",
        "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
        "check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
        "check_data = monai.utils.misc.first(check_loader)\n",
        "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
        "\n",
        "    # create a training data loader\n",
        "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
        "train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=2,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        collate_fn=list_data_collate,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    # create a validation data loader\n",
        "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41\n",
            "41\n",
            "torch.Size([8, 1, 96, 96, 96]) torch.Size([8, 1, 96, 96, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIsBtJ1iCjV"
      },
      "source": [
        "# Create Model (UNET)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B19i3mL1iLAL"
      },
      "source": [
        "# create UNet, DiceLoss and Adam optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = monai.networks.nets.UNet(\n",
        "        dimensions=3,\n",
        "        in_channels=1,\n",
        "        out_channels=1,\n",
        "        channels=(16, 32, 64, 128, 256),\n",
        "        strides=(2, 2, 2, 2),\n",
        "        num_res_units=2,\n",
        "    ).to(device)\n",
        "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_pT2JIQqkhB"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "jP6BTEQkzUyc",
        "outputId": "65449e1b-5176-459d-c362-a04bd463f6a5"
      },
      "source": [
        "val_interval = 2\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = list()\n",
        "metric_values = list()\n",
        "writer = SummaryWriter()\n",
        "for epoch in range(5):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{5}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_len = len(train_ds) // train_loader.batch_size\n",
        "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                metric_sum = 0.0\n",
        "                metric_count = 0\n",
        "                val_images = None\n",
        "                val_labels = None\n",
        "                val_outputs = None\n",
        "                for val_data in val_loader:\n",
        "                    val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
        "                    roi_size = (96, 96, 96)\n",
        "                    sw_batch_size = 4\n",
        "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
        "                    val_outputs = post_trans(val_outputs)\n",
        "                    value, _ = dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                    metric_count += len(value)\n",
        "                    metric_sum += value.item() * len(value)\n",
        "                metric = metric_sum / metric_count\n",
        "                metric_values.append(metric)\n",
        "                if metric > best_metric:\n",
        "                    best_metric = metric\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), \"best_metric_model_segmentation3d_dict.pth\")\n",
        "                    print(\"saved new best metric model\")\n",
        "                print(\n",
        "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
        "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
        "                    )\n",
        "                )\n",
        "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
        "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
        "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
        "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
        "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "writer.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "epoch 1/5\n",
            "1/10, train_loss: 0.9326\n",
            "2/10, train_loss: 0.8809\n",
            "3/10, train_loss: 0.9259\n",
            "4/10, train_loss: 0.9467\n",
            "5/10, train_loss: 0.8414\n",
            "6/10, train_loss: 0.9327\n",
            "7/10, train_loss: 0.9758\n",
            "8/10, train_loss: 0.9417\n",
            "9/10, train_loss: 0.9362\n",
            "10/10, train_loss: 0.8649\n",
            "epoch 1 average loss: 0.9179\n",
            "----------\n",
            "epoch 2/5\n",
            "1/10, train_loss: 0.8246\n",
            "2/10, train_loss: 0.8822\n",
            "3/10, train_loss: 0.8926\n",
            "4/10, train_loss: 0.9259\n",
            "5/10, train_loss: 0.9587\n",
            "6/10, train_loss: 0.9139\n",
            "7/10, train_loss: 0.9315\n",
            "8/10, train_loss: 0.8317\n",
            "9/10, train_loss: 0.9348\n",
            "10/10, train_loss: 0.9483\n",
            "epoch 2 average loss: 0.9044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6170c070439a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mmetric_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mmetric_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    }
  ]
}