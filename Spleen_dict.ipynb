{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spleen_dict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KxRs6swO8JXLsiB10CDnz6j-SluROoN9",
      "authorship_tag": "ABX9TyP7FH7ebaM5tmSqg+tw1NkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meddebma/pyradiomics/blob/master/Spleen_dict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8xY60j1gxdX",
        "outputId": "eb6bd732-dce7-47a7-8ebe-1382cc43aa16"
      },
      "source": [
        "%pip install git+https://github.com/Project-MONAI/MONAI#egg=MONAI\n",
        "#pip install monai==0.3.0\n",
        "#%pip install git+https://github.com/Project-MONAI/MONAI#egg=MONAI\n",
        "%pip install 'monai[all]'\n",
        "%pip install pytorch-ignite\n",
        "%pip install nibabel==3.2.0\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "from glob import glob\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import monai\n",
        "from monai.data import create_test_image_3d, list_data_collate\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    AsChannelFirstd,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadNiftid,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    CropForegroundd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    ScaleIntensityRanged,\n",
        "    RandRotate90d,\n",
        "    ScaleIntensityd,\n",
        "    ToTensord,\n",
        "    AddChanneld,\n",
        "    KeepLargestConnectedComponent, \n",
        "    LabelToContour\n",
        ")\n",
        "from monai.losses import DiceLoss\n",
        "from monai.metrics import compute_meandice\n",
        "from monai.networks.layers import Norm\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.visualize import plot_2d_or_3d_image"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: MONAI from git+https://github.com/Project-MONAI/MONAI#egg=MONAI in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from MONAI) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from MONAI) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->MONAI) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->MONAI) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->MONAI) (0.8)\n",
            "Requirement already satisfied: monai[all] in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from monai[all]) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from monai[all]) (1.18.5)\n",
            "Requirement already satisfied: gdown>=3.6.4; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (3.6.4)\n",
            "Requirement already satisfied: nibabel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (3.2.0)\n",
            "Requirement already satisfied: pillow; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (7.0.0)\n",
            "Requirement already satisfied: tensorboard; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (2.3.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (0.16.2)\n",
            "Requirement already satisfied: tqdm>=4.47.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (4.54.1)\n",
            "Requirement already satisfied: torchvision; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (0.8.1+cu101)\n",
            "Requirement already satisfied: pytorch-ignite==0.4.2; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (0.4.2)\n",
            "Requirement already satisfied: itk; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from monai[all]) (5.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai[all]) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai[all]) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->monai[all]) (0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown>=3.6.4; extra == \"all\"->monai[all]) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown>=3.6.4; extra == \"all\"->monai[all]) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from nibabel; extra == \"all\"->monai[all]) (20.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (0.4.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (0.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"all\"->monai[all]) (1.7.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2; extra == \"all\"->monai[all]) (1.4.1)\n",
            "Requirement already satisfied: itk-registration==5.1.2 in /usr/local/lib/python3.6/dist-packages (from itk; extra == \"all\"->monai[all]) (5.1.2)\n",
            "Requirement already satisfied: itk-filtering==5.1.2 in /usr/local/lib/python3.6/dist-packages (from itk; extra == \"all\"->monai[all]) (5.1.2)\n",
            "Requirement already satisfied: itk-segmentation==5.1.2 in /usr/local/lib/python3.6/dist-packages (from itk; extra == \"all\"->monai[all]) (5.1.2)\n",
            "Requirement already satisfied: itk-numerics==5.1.2 in /usr/local/lib/python3.6/dist-packages (from itk; extra == \"all\"->monai[all]) (5.1.2)\n",
            "Requirement already satisfied: itk-core==5.1.2 in /usr/local/lib/python3.6/dist-packages (from itk; extra == \"all\"->monai[all]) (5.1.2)\n",
            "Requirement already satisfied: itk-io==5.1.2 in /usr/local/lib/python3.6/dist-packages (from itk; extra == \"all\"->monai[all]) (5.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown>=3.6.4; extra == \"all\"->monai[all]) (2020.11.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->nibabel; extra == \"all\"->monai[all]) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard; extra == \"all\"->monai[all]) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"all\"->monai[all]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2; extra == \"all\"->monai[all]) (4.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard; extra == \"all\"->monai[all]) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"all\"->monai[all]) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard; extra == \"all\"->monai[all]) (0.4.8)\n",
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Requirement already satisfied: nibabel==3.2.0 in /usr/local/lib/python3.6/dist-packages (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from nibabel==3.2.0) (1.18.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from nibabel==3.2.0) (20.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->nibabel==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->nibabel==3.2.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7aBb3wvhao1"
      },
      "source": [
        "\n",
        "\n",
        "# Import Data and Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MugHh3Fhjnm",
        "outputId": "313633ef-16d9-4317-e6ef-e8b31f75798b"
      },
      "source": [
        "root= \"/content/drive/My Drive/Task09_Spleen/\"\n",
        "images = sorted(glob(os.path.join(root, \"imagesTr\",\"*.nii.gz\")))\n",
        "segs = sorted(glob(os.path.join(root, \"labelsTr\", \"*.nii.gz\")))\n",
        "\n",
        "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\n",
        "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]\n",
        "print (len(images))\n",
        "print (len(segs))\n",
        "\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadNiftid(keys=[\"img\", \"seg\"]),\n",
        "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
        "        Spacingd(keys=[\"img\", \"seg\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"img\", \"seg\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"img\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
        "        RandCropByPosNegLabeld(\n",
        "            keys=[\"img\", \"seg\"],\n",
        "            label_key=\"seg\",\n",
        "            spatial_size=(96, 96, 96),\n",
        "            pos=1,\n",
        "            neg=1,\n",
        "            num_samples=4,\n",
        "            image_key=\"img\",\n",
        "            image_threshold=0,\n",
        "        ),\n",
        "        # user can also add other random transforms\n",
        "        # RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=1.0, spatial_size=(96, 96, 96),\n",
        "        #             rotate_range=(0, 0, np.pi/15), scale_range=(0.1, 0.1, 0.1)),\n",
        "        ToTensord(keys=[\"img\", \"seg\"]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadNiftid(keys=[\"img\", \"seg\"]),\n",
        "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
        "        Spacingd(keys=[\"img\", \"seg\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"img\", \"seg\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"img\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"img\", \"seg\"], source_key=\"img\"),\n",
        "        ToTensord(keys=[\"img\", \"seg\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# define dataset, data loader\n",
        "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
        "check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
        "check_data = monai.utils.misc.first(check_loader)\n",
        "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
        "\n",
        "    # create a training data loader\n",
        "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
        "train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=2,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        collate_fn=list_data_collate,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    # create a validation data loader\n",
        "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41\n",
            "41\n",
            "torch.Size([8, 1, 96, 96, 96]) torch.Size([8, 1, 96, 96, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIsBtJ1iCjV"
      },
      "source": [
        "# Create Model (UNET)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B19i3mL1iLAL"
      },
      "source": [
        "# create UNet, DiceLoss and Adam optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = monai.networks.nets.UNet(\n",
        "        dimensions=3,\n",
        "        in_channels=1,\n",
        "        out_channels=1,\n",
        "        channels=(16, 32, 64, 128, 256),\n",
        "        strides=(2, 2, 2, 2),\n",
        "        num_res_units=2,\n",
        "    ).to(device)\n",
        "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_pT2JIQqkhB"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "jP6BTEQkzUyc",
        "outputId": "381fb7b4-56a7-4d32-f9e1-6798b45717f3"
      },
      "source": [
        "val_interval = 2\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = list()\n",
        "metric_values = list()\n",
        "writer = SummaryWriter()\n",
        "for epoch in range(5):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{5}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_len = len(train_ds) // train_loader.batch_size\n",
        "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                metric_sum = 0.0\n",
        "                metric_count = 0\n",
        "                val_images = None\n",
        "                val_labels = None\n",
        "                val_outputs = None\n",
        "                for val_data in val_loader:\n",
        "                    val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
        "                    roi_size = (96, 96, 96)\n",
        "                    sw_batch_size = 4\n",
        "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
        "                    val_outputs = post_trans(val_outputs)\n",
        "                    value, _ = dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                    metric_count += len(value)\n",
        "                    metric_sum += value.item() * len(value)\n",
        "                metric = metric_sum / metric_count\n",
        "                metric_values.append(metric)\n",
        "                if metric > best_metric:\n",
        "                    best_metric = metric\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), \"best_metric_model_segmentation3d_dict.pth\")\n",
        "                    print(\"saved new best metric model\")\n",
        "                print(\n",
        "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
        "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
        "                    )\n",
        "                )\n",
        "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
        "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
        "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
        "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
        "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "writer.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "epoch 1/5\n",
            "1/10, train_loss: 0.9752\n",
            "2/10, train_loss: 0.9662\n",
            "3/10, train_loss: 0.9767\n",
            "4/10, train_loss: 0.9447\n",
            "5/10, train_loss: 0.8629\n",
            "6/10, train_loss: 0.9310\n",
            "7/10, train_loss: 0.9057\n",
            "8/10, train_loss: 0.8681\n",
            "9/10, train_loss: 0.8662\n",
            "10/10, train_loss: 0.8858\n",
            "epoch 1 average loss: 0.9183\n",
            "----------\n",
            "epoch 2/5\n",
            "1/10, train_loss: 0.9648\n",
            "2/10, train_loss: 0.9296\n",
            "3/10, train_loss: 0.9504\n",
            "4/10, train_loss: 0.9616\n",
            "5/10, train_loss: 0.8899\n",
            "6/10, train_loss: 0.8126\n",
            "7/10, train_loss: 0.8574\n",
            "8/10, train_loss: 0.8784\n",
            "9/10, train_loss: 0.8575\n",
            "10/10, train_loss: 0.8194\n",
            "epoch 2 average loss: 0.8922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6170c070439a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mmetric_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mmetric_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    }
  ]
}