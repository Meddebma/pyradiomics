{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D Segmentation_eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1RtZZ2TJjmhvABH4gvjYObBYuq_jkdewp",
      "authorship_tag": "ABX9TyNCTFQYgR7ksUCVs1FKiTP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meddebma/pyradiomics/blob/master/3D_Segmentation_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltF1K3dyrHpd"
      },
      "source": [
        "**Setup environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8RlsQ_Sqvdf"
      },
      "source": [
        "%pip install \"monai--weekly[nibabel, skimage, pillow, tensorboard, gdown, ignite, torchvision, itk, tqdm, lmdb, psutil]\"\n",
        "%pip install matplotlib\n",
        "%pip install pytorch-lightning\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eNkIclYrV7T",
        "outputId": "0bf98378-56e2-4a4a-a365-349fc7a007b9"
      },
      "source": [
        "# Copyright 2020 MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "from monai.utils import set_determinism\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    AddChanneld,\n",
        "    Activationsd,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    AsDiscreted,\n",
        "    RandCropByPosNegLabeld,\n",
        "    ScaleIntensityRanged,\n",
        "    Invertd,\n",
        "    Spacingd,\n",
        "    LabelToContour,\n",
        "    KeepLargestConnectedComponent,\n",
        "    ToTensord,\n",
        "    AsDiscreted,\n",
        "    EnsureChannelFirstd,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    Resized,\n",
        "    SaveImaged,\n",
        "    ScaleIntensityd,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import compute_meandice, compute_roc_auc\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, list_data_collate\n",
        "from monai.config import print_config\n",
        "from monai.apps import download_and_extract\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import seaborn as sns \n",
        "\n",
        "\n",
        "\n",
        "print_config()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MONAI version: 0.6.dev2126\n",
            "Numpy version: 1.19.5\n",
            "Pytorch version: 1.9.0+cu102\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
            "MONAI rev id: 2ad54662de25e9a964c33327f7f2f178655573ef\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.4\n",
            "Nibabel version: 3.0.2\n",
            "scikit-image version: 0.16.2\n",
            "Pillow version: 7.1.2\n",
            "Tensorboard version: 2.4.1\n",
            "gdown version: 3.6.4\n",
            "TorchVision version: 0.10.0+cu102\n",
            "ITK version: 5.1.2\n",
            "tqdm version: 4.61.1\n",
            "lmdb version: 0.99\n",
            "psutil version: 5.4.8\n",
            "pandas version: 1.1.5\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yxyr2Wwrg-e",
        "outputId": "59741ab9-4b49-43d1-9f55-579ebe5ab938"
      },
      "source": [
        "ima_dir= \"/content/drive/MyDrive/Spleen_AI/Projekt2t\"\n",
        "\n",
        "images = sorted(glob(os.path.join(ima_dir, \"*.nii.gz\")))\n",
        "labels = sorted(glob(os.path.join(ima_dir, \"*.nii.gz\")))\n",
        "\n",
        "test = [{\"image\": image_name, \"label\": label_name}\n",
        "            for image_name, label_name in zip(images, labels)]\n",
        "val_transforms = Compose(\n",
        "            [\n",
        "                LoadImaged(keys=[\"image\", \"label\"]),\n",
        "                AddChanneld(keys=[\"image\", \"label\"]),\n",
        "                Spacingd(\n",
        "                    keys=[\"image\", \"label\"],\n",
        "                    pixdim=(1.5, 1.5, 2.0),\n",
        "                    mode=(\"bilinear\", \"nearest\"),\n",
        "                ),\n",
        "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"PLI\"),\n",
        "                ScaleIntensityRanged(\n",
        "                    keys=[\"image\"], a_min=-57, a_max=164,\n",
        "                    b_min=0.0, b_max=1.0, clip=True,\n",
        "                ),\n",
        "                CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "                ToTensord(keys=[\"image\", \"label\"]),\n",
        "            ]\n",
        "        ) \n",
        "val_ds = CacheDataset(\n",
        "            data=test, transform=val_transforms,\n",
        "            cache_rate=1.0, num_workers=2,\n",
        "        )\n",
        "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=1, num_workers=2)\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.transforms import Activations, AddChannel, AsDiscrete, Compose, ScaleIntensity, ToTensor\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold_values=True), KeepLargestConnectedComponent(applied_labels=[1])])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset: 100%|██████████| 23/23 [01:09<00:00,  3.02s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQttUi_InYHQ",
        "outputId": "f7939671-b280-496e-d2ca-04bc6b84946b"
      },
      "source": [
        "print(val_data[\"image_meta_dict\"]['filename_or_obj'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/Spleen_AI/Projekt2ß/12633486.nii.gz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBzflB0Q9luJ"
      },
      "source": [
        "from monai.metrics import get_confusion_matrix, compute_hausdorff_distance\n",
        "from monai.data import NiftiSaver\n",
        "device = torch.device(\"cuda:0\")\n",
        "model =     UNet(\n",
        "            dimensions=3,\n",
        "            in_channels=1,\n",
        "            out_channels=2,\n",
        "            channels=(16, 32, 64, 128, 256),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            num_res_units=2,\n",
        "            ).to(device)\n",
        "#loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "device = torch.device(\"cuda:0\")\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Spleen_AI/best_metric_model_ch_500.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "        metric_sum = 0.0\n",
        "        metric_count = 0\n",
        "        saver = NiftiSaver(output_dir=\"/content/drive/MyDrive/Spleen_AI/Projekt2t/Segmentation\")\n",
        "        for val_data in val_loader:\n",
        " #define sliding window size and batch size for windows inference\n",
        "            val_images, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n",
        "            val_data[\"pred\"] = sliding_window_inference(inputs=val_images, roi_size=(96, 96, 96), sw_batch_size=4, predictor=model)\n",
        "            # execute post transforms to invert spatial transforms and save to NIfTI files\n",
        "            post_trans(val_data[\"pred\"])\n",
        "            roi_size = (96, 96, 96)\n",
        "            sw_batch_size = 4\n",
        "            val_outputs = sliding_window_inference(val_data[\"image\"].to(device), roi_size, sw_batch_size, model)\n",
        "            val_outputs = post_trans(val_outputs)\n",
        "            shape=val_images.shape\n",
        "            vols = [(b[:,1]==1).sum() for b in val_outputs]\n",
        "            value = compute_meandice(\n",
        "            y_pred=val_outputs,\n",
        "            y=val_labels,\n",
        "            include_background=False)\n",
        "            #print(val_data[\"image_meta_dict\"])\n",
        "          \n",
        "            conf = get_confusion_matrix(y_pred=val_outputs, y=val_labels, include_background=False)\n",
        "            hausdorff = compute_hausdorff_distance(y_pred=val_outputs, y=val_labels, include_background=False)\n",
        "            metric_count += len(value)\n",
        "            metric_sum += value.item() * len(value)\n",
        "            #print(f\"val_loss:\", loss)\n",
        "            print(f\"val_dice:\", value)\n",
        "            print(f\"Confusion Matrix:\", conf)\n",
        "            print(f\"Hausdorff:\",hausdorff)\n",
        "            print(f\"Shape:\", shape)\n",
        "            print(f\"Volume:\", vols, f\"mm3\")\n",
        "            #print(f\"y_pred:\",val_outputs)\n",
        "            #print(f\"y:\", val_labels)\n",
        "            \n",
        "            plt.figure(\"check\", (18, 6))\n",
        "            plt.subplot(1, 5, 1)\n",
        "            plt.title(f\"image\")\n",
        "            plt.imshow(val_data[\"image\"][0, 0, :, :, 25], cmap=\"gray\")\n",
        "            plt.subplot(1, 5, 2)\n",
        "            plt.title(f\"label\")\n",
        "            plt.imshow(val_data[\"label\"][0, 0, :, :, 25])\n",
        "            plt.subplot(1, 5, 3)\n",
        "            plt.title(f\"output\")\n",
        "            plt.imshow(torch.argmax(\n",
        "            val_outputs, dim=1).detach().cpu()[0, :, :, 25])\n",
        "            plt.subplot(1, 5, 4)\n",
        "            plt.title(f\"contour\")\n",
        "            argmax = AsDiscrete(argmax=True)(val_outputs)\n",
        "            largest = KeepLargestConnectedComponent(applied_labels=[1])(argmax)\n",
        "            contour = LabelToContour()(largest) \n",
        "            plt.imshow(contour.detach().cpu()[0, 0, :, :, 25],cmap=\"gray\")\n",
        "            plt.subplot(1, 5, 5)\n",
        "            plt.title(f\"map image\")\n",
        "            map_image = contour + val_images\n",
        "            plt.imshow(map_image.detach().cpu()[0, 0, :, :, 25], cmap=\"gray\")\n",
        "            plt.show()\n",
        "            saver.save_batch(val_outputs, val_data[\"image_meta_dict\"])\n",
        "        metric = metric_sum / metric_count\n",
        "        print(\"evaluation metric:\", metric)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}